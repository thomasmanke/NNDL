<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.33">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Thomas Manke">
<meta name="dcterms.date" content="2025-09-05">

<title>Image Classification – Neural Networks and Deep Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-59898bd1c6b9d2bb783127feaa000c76.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-d329e753491efaeac79c98c4b193a686.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-59898bd1c6b9d2bb783127feaa000c76.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-ced0475e70959dfb81820bb49685eb32.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-79cdac72355b6842798e3400025574c4.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../site_libs/bootstrap/bootstrap-ced0475e70959dfb81820bb49685eb32.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Neural Networks and Deep Learning</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-lectures" role="link" data-bs-toggle="dropdown" aria-expanded="false">
      <i class="bi bi-book" role="img">
</i> 
 <span class="menu-text">Lectures</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-lectures">    
        <li>
    <a class="dropdown-item" href="../../lectures/01_MachineLearning/index.html">
 <span class="dropdown-text">01 Machine Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../lectures/02_NeuralNetworks/index.html">
 <span class="dropdown-text">02 Neural Networks</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../lectures/03_ConvolutionalNeuralNetworks/index.html">
 <span class="dropdown-text">03 Convolutional Neural Networks</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../lectures/04_GenerativeModels/index.html">
 <span class="dropdown-text">04 Generative Models</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../projects/index.html"> <i class="bi bi-bricks" role="img">
</i> 
<span class="menu-text">Projects</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../help/index.html"> <i class="bi bi-question-circle" role="img">
</i> 
<span class="menu-text">Help</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../general/Chalkboard.html"> <i class="bi bi-clipboard-fill" role="img">
</i> 
<span class="menu-text">Chalkboard</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/thomasmanke/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#goal" id="toc-goal" class="nav-link active" data-scroll-target="#goal">Goal</a></li>
  <li><a href="#repetitions" id="toc-repetitions" class="nav-link" data-scroll-target="#repetitions">Repetitions</a></li>
  <li><a href="#new-items" id="toc-new-items" class="nav-link" data-scroll-target="#new-items">New items</a></li>
  <li><a href="#get-packages" id="toc-get-packages" class="nav-link" data-scroll-target="#get-packages">Get Packages</a></li>
  <li><a href="#get-data-mnist" id="toc-get-data-mnist" class="nav-link" data-scroll-target="#get-data-mnist">Get Data: MNIST</a>
  <ul class="collapse">
  <li><a href="#background" id="toc-background" class="nav-link" data-scroll-target="#background">Background</a></li>
  <li><a href="#test-and-training-sets" id="toc-test-and-training-sets" class="nav-link" data-scroll-target="#test-and-training-sets">Test and Training Sets</a></li>
  <li><a href="#data-transformations" id="toc-data-transformations" class="nav-link" data-scroll-target="#data-transformations">Data Transformations</a></li>
  <li><a href="#data-inspection" id="toc-data-inspection" class="nav-link" data-scroll-target="#data-inspection">Data Inspection</a></li>
  <li><a href="#stratified-sampling" id="toc-stratified-sampling" class="nav-link" data-scroll-target="#stratified-sampling">Stratified sampling</a></li>
  <li><a href="#train_test_split-alternative" id="toc-train_test_split-alternative" class="nav-link" data-scroll-target="#train_test_split-alternative"><code>train_test_split</code> alternative</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  <li><a href="#goal-repeat" id="toc-goal-repeat" class="nav-link" data-scroll-target="#goal-repeat">Goal Repeat</a></li>
  </ul></li>
  <li><a href="#data-loading" id="toc-data-loading" class="nav-link" data-scroll-target="#data-loading">Data Loading</a></li>
  <li><a href="#define-model" id="toc-define-model" class="nav-link" data-scroll-target="#define-model">Define Model</a>
  <ul class="collapse">
  <li><a href="#rectified-linear-unit" id="toc-rectified-linear-unit" class="nav-link" data-scroll-target="#rectified-linear-unit">Rectified Linear Unit</a></li>
  </ul></li>
  <li><a href="#summarize-model" id="toc-summarize-model" class="nav-link" data-scroll-target="#summarize-model">Summarize Model</a></li>
  <li><a href="#define-loss-function-and-optimizer" id="toc-define-loss-function-and-optimizer" class="nav-link" data-scroll-target="#define-loss-function-and-optimizer">Define Loss Function and Optimizer</a>
  <ul class="collapse">
  <li><a href="#adam-optimizer" id="toc-adam-optimizer" class="nav-link" data-scroll-target="#adam-optimizer">Adam Optimizer</a></li>
  </ul></li>
  <li><a href="#train-model" id="toc-train-model" class="nav-link" data-scroll-target="#train-model">Train Model</a></li>
  <li><a href="#save-model" id="toc-save-model" class="nav-link" data-scroll-target="#save-model">Save Model</a></li>
  <li><a href="#load-model" id="toc-load-model" class="nav-link" data-scroll-target="#load-model">Load Model</a></li>
  <li><a href="#evaluate-training" id="toc-evaluate-training" class="nav-link" data-scroll-target="#evaluate-training">Evaluate Training</a></li>
  <li><a href="#test-model" id="toc-test-model" class="nav-link" data-scroll-target="#test-model">Test Model</a></li>
  <li><a href="#task-for-home" id="toc-task-for-home" class="nav-link" data-scroll-target="#task-for-home">Task for home</a></li>
  <li><a href="#load-own-image" id="toc-load-own-image" class="nav-link" data-scroll-target="#load-own-image">Load own image</a></li>
  <li><a href="#summary-1" id="toc-summary-1" class="nav-link" data-scroll-target="#summary-1">Summary</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-page-left" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Image Classification</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta column-page-left">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Thomas Manke </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">September 5, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="goal" class="level2">
<h2 class="anchored" data-anchor-id="goal">Goal</h2>
<p>Given many images and their labels, train a neural network to predict the label of a new image (c.f human learning).</p>
</section>
<section id="repetitions" class="level2">
<h2 class="anchored" data-anchor-id="repetitions">Repetitions</h2>
<ul>
<li>Define Model &amp; Optimization Strategy</li>
<li>Fit Model</li>
<li>Monitor Fitting</li>
<li>Evaluate Training</li>
</ul>
</section>
<section id="new-items" class="level2">
<h2 class="anchored" data-anchor-id="new-items">New items</h2>
<ul>
<li>Data Splitting: Train &amp; Test</li>
<li>How to handle images: data structure</li>
</ul>
</section>
<section id="get-packages" class="level2">
<h2 class="anchored" data-anchor-id="get-packages">Get Packages</h2>
<div id="get_packages" class="cell" data-execution_count="1">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets, transforms</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, random_split, Subset</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lecture_utils.helper <span class="im">import</span> plot_cm, detect_device</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> detect_device()</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'torch-version: '</span>, torch.__version__)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'device: '</span>, device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>torch-version:  2.7.1
device:  mps</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Use GPU if available
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Google Colab: <span class="math inline">\(\to\)</span> Change Runtime …</li>
<li>Kaggle: <span class="math inline">\(\to\)</span> Accelerator (GPU T4)</li>
</ul>
</div>
</div>
</section>
<section id="get-data-mnist" class="level2">
<h2 class="anchored" data-anchor-id="get-data-mnist">Get Data: MNIST</h2>
<section id="background" class="level3">
<h3 class="anchored" data-anchor-id="background">Background</h3>
<p>Many famous datasets can be found here:</p>
<ul>
<li><a href="https://docs.pytorch.org/vision/main/datasets.html" target="_blank"><span class="citation" data-cites="pytorch">@pytorch</span> datasets</a></li>
<li><a href="https://keras.io/api/datasets" target="_blank"><span class="citation" data-cites="keras">@keras</span> datasets</a></li>
</ul>
<p>In the following we will focus on squared images of handwritten digits. They have also been annotated (labeled). For historical background see here: <a href="https://en.wikipedia.org/wiki/MNIST_database" target="_blank">wikipedia</a></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://upload.wikimedia.org/wikipedia/commons/b/b1/MNIST_dataset_example.png" class="img-fluid figure-img" target="_blank"></p>
<figcaption>Examples from MNIST handwritten digits.</figcaption>
</figure>
</div>
<ul>
<li>the challenge</li>
<li>highly structured data</li>
<li>data collection</li>
<li>human error rate</li>
<li>LeCun (Bell Labs, Facebook/Meta, Turing Award 2018)</li>
</ul>
</section>
<section id="test-and-training-sets" class="level3">
<h3 class="anchored" data-anchor-id="test-and-training-sets">Test and Training Sets</h3>
<p>For models with many parameters there is a real danger of <strong>overfitting</strong>, i.e.&nbsp;learning the specifics of one set of samples rather than generalizable rules.</p>
<p>For performance evaluation it is crucial to retain an independent (but representative) <strong>test data set</strong> that it is never used for fitting. For MNIST we can obtain both train and test data from torchvision.dataset (63 MB)</p>
<div id="get_data" class="cell" data-execution_count="2">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># define data transformation. toTensor() also includes division by 255!  </span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([transforms.ToTensor()]) </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>full_train <span class="op">=</span> datasets.MNIST(root<span class="op">=</span><span class="st">'./data'</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>test_data  <span class="op">=</span> datasets.MNIST(root<span class="op">=</span><span class="st">'./data'</span>, train<span class="op">=</span><span class="va">False</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="data-transformations" class="level3">
<h3 class="anchored" data-anchor-id="data-transformations">Data Transformations</h3>
<p><strong>Alert:</strong> Usually many more steps are necessary to prepare data for analysis: reading, reformating, filtering, shuffeling, transformation, normalization.</p>
<p>This can take up a significant amount of time and it is important to do so consistently for train and test data.</p>
<p>The transformation to pytorch tensor is minimal, but notice that this also includes an implicit normalization of images <span class="math inline">\([0, 255]\)</span> (integer) <span class="math inline">\(\to [0,1]\)</span> (float). This will be done automatically and systematically whenever we access <code>full_train</code> or <code>test_data</code>, but the data set still contains the row data.</p>
</section>
<section id="data-inspection" class="level3">
<h3 class="anchored" data-anchor-id="data-inspection">Data Inspection</h3>
<div id="cell-data_exploration" class="cell" data-execution_count="3">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> show_ascii_arr(arr):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> row <span class="kw">in</span> arr:</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>      <span class="bu">print</span>(<span class="st">" "</span>.join(<span class="ss">f"</span><span class="sc">{</span>val<span class="sc">:3d}</span><span class="ss">"</span> <span class="cf">for</span> val <span class="kw">in</span> row))</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co"># accessing all *unnormalized* data</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>X,y <span class="op">=</span> full_train.data, full_train.targets</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'full_train:'</span>, <span class="bu">type</span>(full_train))</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'X:'</span>, <span class="bu">type</span>(X), X.shape, X.<span class="bu">min</span>(), X.<span class="bu">max</span>())</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'y:'</span>, <span class="bu">type</span>(y), y.shape)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co"># ... as ascii</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>show_ascii_arr(X[<span class="dv">0</span>])</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="co"># ... as grey-scale image</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>plt.imshow(X[<span class="dv">0</span>], cmap<span class="op">=</span><span class="st">"grey"</span>)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>plt.title(y[<span class="dv">0</span>])</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>full_train: &lt;class 'torchvision.datasets.mnist.MNIST'&gt;
X: &lt;class 'torch.Tensor'&gt; torch.Size([60000, 28, 28]) tensor(0, dtype=torch.uint8) tensor(255, dtype=torch.uint8)
y: &lt;class 'torch.Tensor'&gt; torch.Size([60000])
  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255 247 127   0   0   0   0
  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0
  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82  82  56  39   0   0   0   0   0
  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0
  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154   0   0   0   0   0   0   0   0   0   0
  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0   0   0
  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0   0   0   0   0   0   0   0   0   0   0
  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0   0   0   0   0
  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1   0   0   0   0   0   0   0   0   0   0
  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0   0   0   0   0   0   0
  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0
  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187   0   0   0   0   0   0   0   0
  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0
  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253 253 207   2   0   0   0   0   0   0   0
  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0   0   0
  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201  78   0   0   0   0   0   0   0   0   0
  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0   0   0   0   0
  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0   0   0   0   0   0   0   0   0   0   0
  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0   0   0   0   0   0   0
  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="05_ImageClassification_files/figure-html/data_exploration-output-2.png" id="data_exploration" width="415" height="431" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question
</div>
</div>
<div class="callout-body-container callout-body">
<p>How many samples and how many features does the MNIST training set have?</p>
</div>
</div>
<p>Notice: usually we access only subsets (by index or DataLoader) those will be transformed as specified in transform()</p>
<div id="cell-normalized_data" class="cell" data-execution_count="4">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>X,y <span class="op">=</span> full_train[<span class="dv">0</span>]</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>plt.imshow(X[<span class="dv">0</span>], cmap<span class="op">=</span><span class="st">"grey"</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>title<span class="op">=</span><span class="ss">f"label=</span><span class="sc">{</span>y<span class="sc">}</span><span class="ss"> (min=</span><span class="sc">{</span>X<span class="sc">.</span><span class="bu">min</span>()<span class="sc">}</span><span class="ss">, max=</span><span class="sc">{</span>X<span class="sc">.</span><span class="bu">max</span>()<span class="sc">}</span><span class="ss">)"</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>plt.title(title)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="05_ImageClassification_files/figure-html/normalized_data-output-1.png" id="normalized_data" width="415" height="431" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Above we obtained train and test directly with <code>torchvision.datasets</code>.</p>
<p>But sometimes we need addtional subsets from the train data (e.g.&nbsp;<em>validation data</em>) This can be done as follows</p>
<div id="validation_split" class="cell" data-execution_count="5">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> random_split</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co"># keep 80% for training</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>fract <span class="op">=</span> <span class="fl">0.8</span> </span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="co"># define lengths</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>train_len <span class="op">=</span> <span class="bu">int</span>(fract <span class="op">*</span> <span class="bu">len</span>(full_train))</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>val_len <span class="op">=</span> <span class="bu">len</span>(full_train) <span class="op">-</span> train_len</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="co"># define split</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> random_split(full_train, [train_len, val_len])</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'train:'</span>, <span class="bu">len</span>(train_ds))</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'val:'</span>, <span class="bu">len</span>(val_ds))</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> val_ds[<span class="dv">0</span>]</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'X:'</span>, X.shape, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>train: 48000
val: 12000
X: torch.Size([1, 28, 28]) 7</code></pre>
</div>
</div>
</section>
<section id="stratified-sampling" class="level3">
<h3 class="anchored" data-anchor-id="stratified-sampling">Stratified sampling</h3>
<p>A slightly more complicated scenario may occur if the classes (encoded by targets) are not well balanced.</p>
<p>In this case we need to ensure that the subsampled data respects those proportions, since the validation (and test) data should be representative This is called “stratification” and can be obtained with help of scikit-learn.</p>
<p>See here for stratified partitioning: <a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html" target="_blank">StratifiedShuffleSplit()</a></p>
<div id="stratified_split" class="cell" data-execution_count="6">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> StratifiedShuffleSplit</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Subset</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Use targets directly from dataset</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>targets <span class="op">=</span> full_train.targets.numpy()</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>sss <span class="op">=</span> StratifiedShuffleSplit(n_splits<span class="op">=</span><span class="dv">1</span>, train_size<span class="op">=</span>fract, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="co"># sss.split() returns an iterator</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>train_idx, val_idx <span class="op">=</span> <span class="bu">next</span>(sss.split(np.zeros(<span class="bu">len</span>(targets)), targets))</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>train_ds <span class="op">=</span> Subset(full_train, train_idx)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>val_ds   <span class="op">=</span> Subset(full_train, val_idx)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'train:'</span>, <span class="bu">len</span>(train_ds))</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'val:'</span>, <span class="bu">len</span>(val_ds))</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Sanity check - label frequencies</span></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>train_labels <span class="op">=</span> train_ds.dataset.targets[train_ds.indices]</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>train_counts <span class="op">=</span> torch.bincount(train_labels)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>train_freq <span class="op">=</span> train_counts <span class="op">/</span> train_counts.<span class="bu">sum</span>()</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>val_labels <span class="op">=</span> val_ds.dataset.targets[val_ds.indices]</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>val_counts <span class="op">=</span> torch.bincount(val_labels)</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>val_freq <span class="op">=</span> val_counts <span class="op">/</span> val_counts.<span class="bu">sum</span>()</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(train_freq)</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(val_freq)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>train: 48000
val: 12000
tensor([0.0987, 0.1124, 0.0993, 0.1022, 0.0974, 0.0904, 0.0986, 0.1044, 0.0975,
        0.0991])
tensor([0.0988, 0.1123, 0.0993, 0.1022, 0.0973, 0.0903, 0.0987, 0.1044, 0.0975,
        0.0992])</code></pre>
</div>
</div>
</section>
<section id="train_test_split-alternative" class="level3">
<h3 class="anchored" data-anchor-id="train_test_split-alternative"><code>train_test_split</code> alternative</h3>
<p>Below is a frequently used method from scikit-learn. It is shown here only for reference. But notice that it requires several conversions and normalizations that we’ll need track carefully.</p>
<div id="sklearn_train_test_split" class="cell" data-execution_count="7">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> TensorDataset</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>fract <span class="op">=</span> <span class="fl">0.8</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># convert from tensors to numpy</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> full_train.data.numpy()</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> full_train.targets.numpy()</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="co"># convenient implementation of stratification</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>X_train, X_val, y_train, y_val <span class="op">=</span> train_test_split(X, y, train_size<span class="op">=</span>fract, stratify<span class="op">=</span>y)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="co"># convert back to tensors</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>train_ds <span class="op">=</span> TensorDataset(torch.tensor(X_train[:, <span class="va">None</span>]<span class="op">/</span><span class="fl">255.</span>, dtype<span class="op">=</span>torch.float32),</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>                                          torch.tensor(y_train, dtype<span class="op">=</span>torch.<span class="bu">long</span>))</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>val_ds   <span class="op">=</span> TensorDataset(torch.tensor(X_val[:, <span class="va">None</span>]<span class="op">/</span><span class="fl">255.</span>, dtype<span class="op">=</span>torch.float32),</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>                                          torch.tensor(y_val, dtype<span class="op">=</span>torch.<span class="bu">long</span>))</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>test_ds  <span class="op">=</span> TensorDataset(test_data.data[:, <span class="va">None</span>]<span class="op">/</span><span class="fl">255.</span>, test_data.targets)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary</h3>
<p>In most machine learinng application we want to have a data split</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/train_test_split.png" class="img-fluid figure-img"></p>
<figcaption>Train-Validation-Test Split. The fractions shown are common, but arbitrary.</figcaption>
</figure>
</div>
</section>
<section id="goal-repeat" class="level3">
<h3 class="anchored" data-anchor-id="goal-repeat">Goal Repeat</h3>
<p>Build a predictor of labels for hand-written digits.</p>
<div id="cell-PCA" class="cell" data-execution_count="8">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>n_sub <span class="op">=</span> <span class="dv">500</span> <span class="co"># define a subset of digits for speed</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co"># flattening a tensor to get [samples x features]</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>X_sub <span class="op">=</span> full_train.data[:n_sub].flatten(start_dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>y_sub <span class="op">=</span> full_train.targets[:n_sub]</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'X: '</span>, X_sub.shape)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>X_pca <span class="op">=</span> PCA(n_components <span class="op">=</span> <span class="dv">2</span>).fit_transform(X_sub)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Scores: '</span>,X_pca.shape)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> plt.get_cmap(<span class="st">'tab10'</span>)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>plt.scatter( X_pca[:,<span class="dv">0</span>], X_pca[:,<span class="dv">1</span>] , c<span class="op">=</span>y_sub, cmap<span class="op">=</span>cm)</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'PCA of MNIST'</span>)</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>X:  torch.Size([500, 784])
Scores:  (500, 2)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="05_ImageClassification_files/figure-html/pca-output-2.png" id="pca" width="553" height="431" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="data-loading" class="level2">
<h2 class="anchored" data-anchor-id="data-loading">Data Loading</h2>
<p>Rather than accessing samples per index we frequently want to load batches of a certain sizes into memory for further analysis. Really large data sets may not even fit into memory, so it is useful to define <code>DataLoaders</code> that get data only in batches inot memory.</p>
<div id="data_loader" class="cell" data-execution_count="9">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(train_ds, batch_size<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>val_loader   <span class="op">=</span> DataLoader(val_ds, batch_size<span class="op">=</span><span class="dv">64</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>test_loader  <span class="op">=</span> DataLoader(test_data, batch_size<span class="op">=</span><span class="dv">64</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"number of train_batches: "</span>, <span class="bu">len</span>(train_loader))</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"number of test_batches:  "</span>, <span class="bu">len</span>(test_loader))</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Data Loaders are used a iterator - they return batches of X,y tuples</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>X,y <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(train_loader))</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'X batch: '</span>, X.shape)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'y batch: '</span>, y.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>number of train_batches:  750
number of test_batches:   157
X batch:  torch.Size([64, 1, 28, 28])
y batch:  torch.Size([64])</code></pre>
</div>
</div>
</section>
<section id="define-model" class="level2">
<h2 class="anchored" data-anchor-id="define-model">Define Model</h2>
<section id="rectified-linear-unit" class="level3">
<h3 class="anchored" data-anchor-id="rectified-linear-unit">Rectified Linear Unit</h3>
<p>Basic Non-linearity</p>
<div id="model_define" class="cell" data-execution_count="10">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MNISTModel(nn.Module):</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.flatten <span class="op">=</span> nn.Flatten()</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(<span class="dv">28</span><span class="op">*</span><span class="dv">28</span>, <span class="dv">128</span>)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc2 <span class="op">=</span> nn.Linear(<span class="dv">128</span>, <span class="dv">10</span>)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.flatten(x)</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.fc1(x)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.relu(x)</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> <span class="va">self</span>.fc2(x)</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> logits</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="model_create" class="cell" data-execution_count="11">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> MNISTModel().to(device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
<section id="summarize-model" class="level2">
<h2 class="anchored" data-anchor-id="summarize-model">Summarize Model</h2>
<div id="cell-model_summary" class="cell" data-execution_count="12">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchinfo <span class="im">import</span> summary</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>summary(model, input_size<span class="op">=</span>(<span class="dv">1000</span>, <span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span>), device<span class="op">=</span>device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="model_summary" class="cell-output cell-output-display" data-execution_count="11">
<pre><code>==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
MNISTModel                               [1000, 10]                --
├─Flatten: 1-1                           [1000, 784]               --
├─Linear: 1-2                            [1000, 128]               100,480
├─Linear: 1-3                            [1000, 10]                1,290
==========================================================================================
Total params: 101,770
Trainable params: 101,770
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 101.77
==========================================================================================
Input size (MB): 3.14
Forward/backward pass size (MB): 1.10
Params size (MB): 0.41
Estimated Total Size (MB): 4.65
==========================================================================================</code></pre>
</div>
</div>
</section>
<section id="define-loss-function-and-optimizer" class="level2">
<h2 class="anchored" data-anchor-id="define-loss-function-and-optimizer">Define Loss Function and Optimizer</h2>
<section id="adam-optimizer" class="level3">
<h3 class="anchored" data-anchor-id="adam-optimizer">Adam Optimizer</h3>
<p>Reference: DP Kingma et al.&nbsp;2014. Adam: A method for Stochasitic Optimization. 200k+ citations !!!</p>
<p>Don’t get stuck in local minima <span class="math inline">\(\to\)</span> adaptive learning rates</p>
<div id="loss_optimizer" class="cell" data-execution_count="13">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># return sum losses over batch</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>loss_function <span class="op">=</span> nn.CrossEntropyLoss(reduction<span class="op">=</span><span class="st">"sum"</span>) </span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.Adam(model.parameters())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
<section id="train-model" class="level2">
<h2 class="anchored" data-anchor-id="train-model">Train Model</h2>
<div id="train_model" class="cell" data-execution_count="14">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_model(model, train_loader, val_loader, epochs<span class="op">=</span><span class="dv">25</span>):</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    history <span class="op">=</span> {<span class="st">'loss'</span>: [], <span class="st">'val_loss'</span>: []}</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>        <span class="co"># training</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>        model.train()</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># loop over all train data (in batches given by train_loader)</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> xb, yb <span class="kw">in</span> train_loader:</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>            xb, yb <span class="op">=</span> xb.to(device), yb.to(device)</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>            logits <span class="op">=</span> model(xb)</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_function(logits, yb) <span class="co"># total loss for batch</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()            <span class="co"># set gradients to 0</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>            loss.backward()                  <span class="co"># calculate gradients with backprop</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>            optimizer.step()                 <span class="co"># parameter update</span></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>            total_loss <span class="op">+=</span> loss.item()        <span class="co"># cumulative loss over all batches</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># average train_loss per sample</span></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>        train_loss <span class="op">=</span> total_loss <span class="op">/</span> <span class="bu">len</span>(train_loader.dataset)</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Validation</span></span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># switch off gradient calculation</span></span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> xb, yb <span class="kw">in</span> val_loader:</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>                xb, yb <span class="op">=</span> xb.to(device), yb.to(device)</span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>                logits <span class="op">=</span> model(xb)</span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>                loss <span class="op">=</span> loss_function(logits, yb)</span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>                total_loss <span class="op">+=</span> loss.item() </span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>        val_loss <span class="op">=</span> total_loss <span class="op">/</span> <span class="bu">len</span>(val_loader.dataset)</span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">'loss'</span>].append(train_loss)</span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">'val_loss'</span>].append(val_loss)</span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">: train_loss=</span><span class="sc">{</span>train_loss<span class="sc">:.4f}</span><span class="ss">, val_loss=</span><span class="sc">{</span>val_loss<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> history</span>
<span id="cb21-39"><a href="#cb21-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-40"><a href="#cb21-40" aria-hidden="true" tabindex="-1"></a>hist <span class="op">=</span> train_model(model, train_loader, val_loader, epochs<span class="op">=</span><span class="dv">20</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1: train_loss=0.3853, val_loss=0.2311
Epoch 2: train_loss=0.1840, val_loss=0.1639
Epoch 3: train_loss=0.1263, val_loss=0.1325
Epoch 4: train_loss=0.0968, val_loss=0.1099
Epoch 5: train_loss=0.0760, val_loss=0.1035
Epoch 6: train_loss=0.0619, val_loss=0.0976
Epoch 7: train_loss=0.0511, val_loss=0.0917
Epoch 8: train_loss=0.0423, val_loss=0.0918
Epoch 9: train_loss=0.0338, val_loss=0.0896
Epoch 10: train_loss=0.0277, val_loss=0.0880
Epoch 11: train_loss=0.0239, val_loss=0.0869
Epoch 12: train_loss=0.0188, val_loss=0.0955
Epoch 13: train_loss=0.0152, val_loss=0.0916
Epoch 14: train_loss=0.0136, val_loss=0.0939
Epoch 15: train_loss=0.0116, val_loss=0.0967
Epoch 16: train_loss=0.0091, val_loss=0.0949
Epoch 17: train_loss=0.0084, val_loss=0.1144
Epoch 18: train_loss=0.0075, val_loss=0.0992
Epoch 19: train_loss=0.0057, val_loss=0.1231
Epoch 20: train_loss=0.0060, val_loss=0.1042</code></pre>
</div>
</div>
</section>
<section id="save-model" class="level2">
<h2 class="anchored" data-anchor-id="save-model">Save Model</h2>
<div id="save_model" class="cell" data-execution_count="15">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>outdir <span class="op">=</span> <span class="st">"output"</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>os.makedirs(outdir, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>torch.save(model.state_dict(), <span class="ss">f'</span><span class="sc">{</span>outdir<span class="sc">}</span><span class="ss">/mnist_model.pt'</span>)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>torch.save(hist, <span class="ss">f"</span><span class="sc">{</span>outdir<span class="sc">}</span><span class="ss">/mnist_history.pt"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="load-model" class="level2">
<h2 class="anchored" data-anchor-id="load-model">Load Model</h2>
<div id="load_model" class="cell" data-execution_count="16">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>outdir <span class="op">=</span> <span class="st">"output"</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> MNISTModel().to(device)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>tdict <span class="op">=</span> torch.load(<span class="ss">f"</span><span class="sc">{</span>outdir<span class="sc">}</span><span class="ss">/mnist_model.pt"</span>, map_location<span class="op">=</span>device)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>model.load_state_dict(tdict)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>hist <span class="op">=</span> torch.load(<span class="ss">f"</span><span class="sc">{</span>outdir<span class="sc">}</span><span class="ss">/mnist_history.pt"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="evaluate-training" class="level2">
<h2 class="anchored" data-anchor-id="evaluate-training">Evaluate Training</h2>
<div id="cell-evaluate_training" class="cell" data-execution_count="17">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_fit_history(hist, name<span class="op">=</span><span class="st">'loss'</span>, test_score<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> name <span class="kw">not</span> <span class="kw">in</span> hist:</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss"> not found in history"</span>)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>    plt.plot(hist[name], label<span class="op">=</span><span class="st">'train'</span>)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    val_name <span class="op">=</span> <span class="st">'val_'</span> <span class="op">+</span> name</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> val_name <span class="kw">in</span> hist:</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>        plt.plot(hist[val_name], label<span class="op">=</span><span class="st">'valid'</span>)</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> test_score <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>        plt.axhline(test_score, color<span class="op">=</span><span class="st">'green'</span>, linestyle<span class="op">=</span><span class="st">'-.'</span>, label<span class="op">=</span><span class="st">'test'</span>)</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(name)</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>plot_fit_history(hist, <span class="st">'loss'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="05_ImageClassification_files/figure-html/evaluate_training-output-1.png" id="evaluate_training" width="597" height="431" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Repeat
</div>
</div>
<div class="callout-body-container callout-body">
<p>In principle the steps can be repeated to improve the model (decrease the training loss) or to speedup the training.</p>
<ul>
<li>increasing number of neurons or layers</li>
<li>work with regularization techniques or data augmentation</li>
<li>change learning algorithm or learning rate</li>
<li>adjust hyperparameters</li>
</ul>
<p>! But never show the model the test data until the end !</p>
</div>
</div>
</section>
<section id="test-model" class="level2">
<h2 class="anchored" data-anchor-id="test-model">Test Model</h2>
<p>In principle we can test all test samples (10,000) at once. This is conceptually simpler, but it does requires more care with proper transformations (normalizations) which are run when accessing batches. So in this case we have to normalize by hand</p>
<div id="cell-test_all" class="cell" data-execution_count="18">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># notice that we need to normalize explicitly</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> test_data.data.to(device) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> test_data.targets.to(device)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X.shape)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>  all_logits <span class="op">=</span> model(X)</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>  loss <span class="op">=</span> loss_function(all_logits, y)</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>all_true <span class="op">=</span> y.detach().cpu()</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>test_loss <span class="op">=</span> loss.cpu() <span class="op">/</span> <span class="bu">len</span>(X)</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>plot_fit_history(hist, <span class="st">'loss'</span>, test_loss)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([10000, 28, 28])</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="05_ImageClassification_files/figure-html/test_all-output-2.png" id="test_all" width="597" height="431" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>… more commonly batches are also used over test samples, but this requires some collection</p>
<div id="test_batches" class="cell" data-execution_count="19">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate on test</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>all_logits <span class="op">=</span> []</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>all_true <span class="op">=</span> []</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> xb, yb <span class="kw">in</span> test_loader:</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>        xb, yb <span class="op">=</span> xb.to(device), yb.to(device)</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> model(xb)</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_function(logits, yb)</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># collect total_loss, predicted logits and true labels yb</span></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">+=</span> loss.item()</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>        all_logits.append(logits.cpu())</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>        all_true.append(yb.cpu())</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>test_loss <span class="op">=</span> total_loss <span class="op">/</span> <span class="bu">len</span>(test_loader.dataset) <span class="co"># mean test loss</span></span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>all_logits <span class="op">=</span> torch.cat(all_logits)</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>all_true <span class="op">=</span> torch.cat(all_true)</span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a>plot_fit_history(hist, <span class="st">'loss'</span>, test_loss)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-confusion_matrix" class="cell" data-execution_count="20">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>all_preds <span class="op">=</span> all_logits.argmax(dim<span class="op">=</span><span class="dv">1</span>).detach().cpu()</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(all_true.numpy(), all_preds.numpy())</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="co">#print(cm)</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>plot_cm(cm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="05_ImageClassification_files/figure-html/confusion_matrix-output-1.png" id="confusion_matrix" width="513" height="449" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="task-for-home" class="level2">
<h2 class="anchored" data-anchor-id="task-for-home">Task for home</h2>
<ul>
<li><p>Repeat the above, but with the ReLU switch off. Tru to increase the number of nodes or layers</p></li>
<li><p>Reality check: scan your own handwritten digit and submit it to your trained model. Pay attention to proper normalization and black/white encoding. Does it work?</p></li>
</ul>
</section>
<section id="load-own-image" class="level2">
<h2 class="anchored" data-anchor-id="load-own-image">Load own image</h2>
<div id="cell-load_own_image" class="cell" data-execution_count="21">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> TensorDataset</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>img_size <span class="op">=</span> test_data.data[<span class="dv">0</span>].shape</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>jpg_path <span class="op">=</span> <span class="st">"images/ANN_Digit3.jpg"</span></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a><span class="co"># convert to greyscale (L=luminance)</span></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> Image.<span class="bu">open</span>(jpg_path).convert(<span class="st">"L"</span>).resize(img_size)</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>img_tensor <span class="op">=</span> transform(img) <span class="co"># transform to tensor</span></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>img_tensor <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> img_tensor <span class="co"># swap black and white</span></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>img_tensor <span class="op">=</span> img_tensor.unsqueeze(<span class="dv">0</span>)</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(img_tensor.shape)</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>plt.imshow(img_tensor[<span class="dv">0</span>][<span class="dv">0</span>], cmap<span class="op">=</span><span class="st">"grey"</span>)</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([1, 1, 28, 28])</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="05_ImageClassification_files/figure-html/load_own_image-output-2.png" id="load_own_image" width="415" height="411" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-predict_own_image" class="cell" data-execution_count="22">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="co"># predict logits</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> model(img_tensor.to(device))</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'logits = '</span>, logits.detach().cpu().numpy())</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a><span class="co"># convert to probabilities</span></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>probs <span class="op">=</span> F.softmax(logits, dim<span class="op">=</span><span class="dv">1</span>).detach().cpu().numpy()[<span class="dv">0</span>]</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">4</span>))</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>plt.bar(<span class="bu">range</span>(<span class="dv">10</span>), probs)</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Digit"</span>)</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Probability"</span>)</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>plt.xticks(<span class="bu">range</span>(<span class="dv">10</span>))</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Model probabilities for each digit"</span>)</span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>logits =  [[-9.476369  -2.5490894 -2.6994314  3.277071  -3.6264172 -0.784245
  -6.6809206 -6.64236    0.3123123 -1.4218341]]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="05_ImageClassification_files/figure-html/predict_own_image-output-2.png" id="predict_own_image" width="663" height="376" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="summary-1" class="level2">
<h2 class="anchored" data-anchor-id="summary-1">Summary</h2>
<ul>
<li>new data: images as flattened feature vectors</li>
<li>highly structured data (unrealistic)</li>
<li>Consistent use of Data Transformation &amp; Data Loading</li>
<li>Train-Validation-Test split (with balancing)</li>
<li>Importance of non-linearity (<span class="math inline">\(\to\)</span> RELU)</li>
<li>repetiton: model definition and parameter count</li>
</ul>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb34" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> Image Classification</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="an">jupyter:</span><span class="co"> pytorch</span></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a><span class="fu">## Goal</span></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>Given many images and their labels, train a neural network to predict the label of a new image (c.f human learning).</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a><span class="fu">## Repetitions</span></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Define Model &amp; Optimization Strategy</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Fit Model</span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Monitor Fitting</span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Evaluate Training </span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a><span class="fu">## New items</span></span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Data Splitting: Train &amp; Test</span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>How to handle images: data structure</span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a><span class="fu">## Get Packages</span></span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-25"><a href="#cb34-25" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-26"><a href="#cb34-26" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: get_packages</span></span>
<span id="cb34-27"><a href="#cb34-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-28"><a href="#cb34-28" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb34-29"><a href="#cb34-29" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb34-30"><a href="#cb34-30" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb34-31"><a href="#cb34-31" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb34-32"><a href="#cb34-32" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets, transforms</span>
<span id="cb34-33"><a href="#cb34-33" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, random_split, Subset</span>
<span id="cb34-34"><a href="#cb34-34" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb34-35"><a href="#cb34-35" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb34-36"><a href="#cb34-36" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb34-37"><a href="#cb34-37" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb34-38"><a href="#cb34-38" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb34-39"><a href="#cb34-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-40"><a href="#cb34-40" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lecture_utils.helper <span class="im">import</span> plot_cm, detect_device</span>
<span id="cb34-41"><a href="#cb34-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-42"><a href="#cb34-42" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> detect_device()</span>
<span id="cb34-43"><a href="#cb34-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-44"><a href="#cb34-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'torch-version: '</span>, torch.__version__)</span>
<span id="cb34-45"><a href="#cb34-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'device: '</span>, device)</span>
<span id="cb34-46"><a href="#cb34-46" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-47"><a href="#cb34-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-48"><a href="#cb34-48" aria-hidden="true" tabindex="-1"></a>::: callout-tip</span>
<span id="cb34-49"><a href="#cb34-49" aria-hidden="true" tabindex="-1"></a><span class="fu">### Use GPU if available</span></span>
<span id="cb34-50"><a href="#cb34-50" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Google Colab: $\to$ Change Runtime ...</span>
<span id="cb34-51"><a href="#cb34-51" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Kaggle: $\to$ Accelerator (GPU T4)</span>
<span id="cb34-52"><a href="#cb34-52" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb34-53"><a href="#cb34-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-54"><a href="#cb34-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-55"><a href="#cb34-55" aria-hidden="true" tabindex="-1"></a><span class="fu">## Get Data: MNIST</span></span>
<span id="cb34-56"><a href="#cb34-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-57"><a href="#cb34-57" aria-hidden="true" tabindex="-1"></a><span class="fu">### Background</span></span>
<span id="cb34-58"><a href="#cb34-58" aria-hidden="true" tabindex="-1"></a>Many famous datasets can be found here:</span>
<span id="cb34-59"><a href="#cb34-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-60"><a href="#cb34-60" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">@pytorch datasets</span><span class="co">](https://docs.pytorch.org/vision/main/datasets.html)</span>{target="_blank"}</span>
<span id="cb34-61"><a href="#cb34-61" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">@keras datasets</span><span class="co">](https://keras.io/api/datasets)</span>{target="_blank"}</span>
<span id="cb34-62"><a href="#cb34-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-63"><a href="#cb34-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-64"><a href="#cb34-64" aria-hidden="true" tabindex="-1"></a>In the following we will focus on squared images of handwritten digits. They have also been annotated (labeled). For historical background see here: <span class="co">[</span><span class="ot">wikipedia</span><span class="co">](https://en.wikipedia.org/wiki/MNIST_database)</span>{target="_blank"}</span>
<span id="cb34-65"><a href="#cb34-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-66"><a href="#cb34-66" aria-hidden="true" tabindex="-1"></a><span class="al">![Examples from MNIST handwritten digits.](https://upload.wikimedia.org/wikipedia/commons/b/b1/MNIST_dataset_example.png)</span>{target="_blank"}</span>
<span id="cb34-67"><a href="#cb34-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-68"><a href="#cb34-68" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the challenge</span>
<span id="cb34-69"><a href="#cb34-69" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>highly structured data</span>
<span id="cb34-70"><a href="#cb34-70" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>data collection</span>
<span id="cb34-71"><a href="#cb34-71" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>human error rate</span>
<span id="cb34-72"><a href="#cb34-72" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>LeCun (Bell Labs, Facebook/Meta, Turing Award 2018)</span>
<span id="cb34-73"><a href="#cb34-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-74"><a href="#cb34-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-75"><a href="#cb34-75" aria-hidden="true" tabindex="-1"></a><span class="fu">### Test and Training Sets</span></span>
<span id="cb34-76"><a href="#cb34-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-77"><a href="#cb34-77" aria-hidden="true" tabindex="-1"></a>For models with many parameters there is a real danger of **overfitting**, i.e. learning the specifics of one set of samples rather than generalizable rules.</span>
<span id="cb34-78"><a href="#cb34-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-79"><a href="#cb34-79" aria-hidden="true" tabindex="-1"></a>For performance evaluation it is crucial to retain an independent (but representative) **test data set** that it is never used for fitting. For MNIST we can obtain both train and test data from torchvision.dataset (63 MB)</span>
<span id="cb34-80"><a href="#cb34-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-83"><a href="#cb34-83" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-84"><a href="#cb34-84" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: get_data</span></span>
<span id="cb34-85"><a href="#cb34-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-86"><a href="#cb34-86" aria-hidden="true" tabindex="-1"></a><span class="co"># define data transformation. toTensor() also includes division by 255!  </span></span>
<span id="cb34-87"><a href="#cb34-87" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([transforms.ToTensor()]) </span>
<span id="cb34-88"><a href="#cb34-88" aria-hidden="true" tabindex="-1"></a>full_train <span class="op">=</span> datasets.MNIST(root<span class="op">=</span><span class="st">'./data'</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb34-89"><a href="#cb34-89" aria-hidden="true" tabindex="-1"></a>test_data  <span class="op">=</span> datasets.MNIST(root<span class="op">=</span><span class="st">'./data'</span>, train<span class="op">=</span><span class="va">False</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb34-90"><a href="#cb34-90" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-91"><a href="#cb34-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-92"><a href="#cb34-92" aria-hidden="true" tabindex="-1"></a><span class="fu">### Data Transformations</span></span>
<span id="cb34-93"><a href="#cb34-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-94"><a href="#cb34-94" aria-hidden="true" tabindex="-1"></a>**Alert:** Usually many more steps are necessary to prepare data for analysis:</span>
<span id="cb34-95"><a href="#cb34-95" aria-hidden="true" tabindex="-1"></a>reading, reformating, filtering, shuffeling, transformation, normalization. </span>
<span id="cb34-96"><a href="#cb34-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-97"><a href="#cb34-97" aria-hidden="true" tabindex="-1"></a>This can take up a significant amount of time and it is important to do so consistently for train and test data.</span>
<span id="cb34-98"><a href="#cb34-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-99"><a href="#cb34-99" aria-hidden="true" tabindex="-1"></a>The transformation to pytorch tensor is minimal, but notice that this also includes an implicit</span>
<span id="cb34-100"><a href="#cb34-100" aria-hidden="true" tabindex="-1"></a>normalization of images $<span class="co">[</span><span class="ot">0, 255</span><span class="co">]</span>$ (integer) $\to <span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$ (float). This will be done automatically</span>
<span id="cb34-101"><a href="#cb34-101" aria-hidden="true" tabindex="-1"></a>and systematically whenever we access <span class="in">`full_train`</span> or <span class="in">`test_data`</span>, but the data set still contains the row data.</span>
<span id="cb34-102"><a href="#cb34-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-103"><a href="#cb34-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-104"><a href="#cb34-104" aria-hidden="true" tabindex="-1"></a><span class="fu">### Data Inspection</span></span>
<span id="cb34-107"><a href="#cb34-107" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-108"><a href="#cb34-108" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: data_exploration</span></span>
<span id="cb34-109"><a href="#cb34-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-110"><a href="#cb34-110" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> show_ascii_arr(arr):</span>
<span id="cb34-111"><a href="#cb34-111" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> row <span class="kw">in</span> arr:</span>
<span id="cb34-112"><a href="#cb34-112" aria-hidden="true" tabindex="-1"></a>      <span class="bu">print</span>(<span class="st">" "</span>.join(<span class="ss">f"</span><span class="sc">{</span>val<span class="sc">:3d}</span><span class="ss">"</span> <span class="cf">for</span> val <span class="kw">in</span> row))</span>
<span id="cb34-113"><a href="#cb34-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-114"><a href="#cb34-114" aria-hidden="true" tabindex="-1"></a><span class="co"># accessing all *unnormalized* data</span></span>
<span id="cb34-115"><a href="#cb34-115" aria-hidden="true" tabindex="-1"></a>X,y <span class="op">=</span> full_train.data, full_train.targets</span>
<span id="cb34-116"><a href="#cb34-116" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'full_train:'</span>, <span class="bu">type</span>(full_train))</span>
<span id="cb34-117"><a href="#cb34-117" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'X:'</span>, <span class="bu">type</span>(X), X.shape, X.<span class="bu">min</span>(), X.<span class="bu">max</span>())</span>
<span id="cb34-118"><a href="#cb34-118" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'y:'</span>, <span class="bu">type</span>(y), y.shape)</span>
<span id="cb34-119"><a href="#cb34-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-120"><a href="#cb34-120" aria-hidden="true" tabindex="-1"></a><span class="co"># ... as ascii</span></span>
<span id="cb34-121"><a href="#cb34-121" aria-hidden="true" tabindex="-1"></a>show_ascii_arr(X[<span class="dv">0</span>])</span>
<span id="cb34-122"><a href="#cb34-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-123"><a href="#cb34-123" aria-hidden="true" tabindex="-1"></a><span class="co"># ... as grey-scale image</span></span>
<span id="cb34-124"><a href="#cb34-124" aria-hidden="true" tabindex="-1"></a>plt.imshow(X[<span class="dv">0</span>], cmap<span class="op">=</span><span class="st">"grey"</span>)</span>
<span id="cb34-125"><a href="#cb34-125" aria-hidden="true" tabindex="-1"></a>plt.title(y[<span class="dv">0</span>])</span>
<span id="cb34-126"><a href="#cb34-126" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb34-127"><a href="#cb34-127" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-128"><a href="#cb34-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-129"><a href="#cb34-129" aria-hidden="true" tabindex="-1"></a>::: callout-important</span>
<span id="cb34-130"><a href="#cb34-130" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Question</span></span>
<span id="cb34-131"><a href="#cb34-131" aria-hidden="true" tabindex="-1"></a>How many samples and how many features does the MNIST training set have?</span>
<span id="cb34-132"><a href="#cb34-132" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb34-133"><a href="#cb34-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-134"><a href="#cb34-134" aria-hidden="true" tabindex="-1"></a>Notice: usually we access only subsets (by index or DataLoader) </span>
<span id="cb34-135"><a href="#cb34-135" aria-hidden="true" tabindex="-1"></a>those will be transformed as specified in transform()</span>
<span id="cb34-136"><a href="#cb34-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-139"><a href="#cb34-139" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-140"><a href="#cb34-140" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: normalized_data</span></span>
<span id="cb34-141"><a href="#cb34-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-142"><a href="#cb34-142" aria-hidden="true" tabindex="-1"></a>X,y <span class="op">=</span> full_train[<span class="dv">0</span>]</span>
<span id="cb34-143"><a href="#cb34-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-144"><a href="#cb34-144" aria-hidden="true" tabindex="-1"></a>plt.imshow(X[<span class="dv">0</span>], cmap<span class="op">=</span><span class="st">"grey"</span>)</span>
<span id="cb34-145"><a href="#cb34-145" aria-hidden="true" tabindex="-1"></a>title<span class="op">=</span><span class="ss">f"label=</span><span class="sc">{</span>y<span class="sc">}</span><span class="ss"> (min=</span><span class="sc">{</span>X<span class="sc">.</span><span class="bu">min</span>()<span class="sc">}</span><span class="ss">, max=</span><span class="sc">{</span>X<span class="sc">.</span><span class="bu">max</span>()<span class="sc">}</span><span class="ss">)"</span></span>
<span id="cb34-146"><a href="#cb34-146" aria-hidden="true" tabindex="-1"></a>plt.title(title)</span>
<span id="cb34-147"><a href="#cb34-147" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb34-148"><a href="#cb34-148" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-149"><a href="#cb34-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-150"><a href="#cb34-150" aria-hidden="true" tabindex="-1"></a>Above we obtained train and test directly with <span class="in">`torchvision.datasets`</span>. </span>
<span id="cb34-151"><a href="#cb34-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-152"><a href="#cb34-152" aria-hidden="true" tabindex="-1"></a>But sometimes we need addtional subsets from the train data (e.g. *validation data*)</span>
<span id="cb34-153"><a href="#cb34-153" aria-hidden="true" tabindex="-1"></a>This can be done as follows</span>
<span id="cb34-154"><a href="#cb34-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-157"><a href="#cb34-157" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-158"><a href="#cb34-158" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: validation_split</span></span>
<span id="cb34-159"><a href="#cb34-159" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> random_split</span>
<span id="cb34-160"><a href="#cb34-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-161"><a href="#cb34-161" aria-hidden="true" tabindex="-1"></a><span class="co"># keep 80% for training</span></span>
<span id="cb34-162"><a href="#cb34-162" aria-hidden="true" tabindex="-1"></a>fract <span class="op">=</span> <span class="fl">0.8</span> </span>
<span id="cb34-163"><a href="#cb34-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-164"><a href="#cb34-164" aria-hidden="true" tabindex="-1"></a><span class="co"># define lengths</span></span>
<span id="cb34-165"><a href="#cb34-165" aria-hidden="true" tabindex="-1"></a>train_len <span class="op">=</span> <span class="bu">int</span>(fract <span class="op">*</span> <span class="bu">len</span>(full_train))</span>
<span id="cb34-166"><a href="#cb34-166" aria-hidden="true" tabindex="-1"></a>val_len <span class="op">=</span> <span class="bu">len</span>(full_train) <span class="op">-</span> train_len</span>
<span id="cb34-167"><a href="#cb34-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-168"><a href="#cb34-168" aria-hidden="true" tabindex="-1"></a><span class="co"># define split</span></span>
<span id="cb34-169"><a href="#cb34-169" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> random_split(full_train, [train_len, val_len])</span>
<span id="cb34-170"><a href="#cb34-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-171"><a href="#cb34-171" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect</span></span>
<span id="cb34-172"><a href="#cb34-172" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'train:'</span>, <span class="bu">len</span>(train_ds))</span>
<span id="cb34-173"><a href="#cb34-173" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'val:'</span>, <span class="bu">len</span>(val_ds))</span>
<span id="cb34-174"><a href="#cb34-174" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> val_ds[<span class="dv">0</span>]</span>
<span id="cb34-175"><a href="#cb34-175" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'X:'</span>, X.shape, y)</span>
<span id="cb34-176"><a href="#cb34-176" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-177"><a href="#cb34-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-178"><a href="#cb34-178" aria-hidden="true" tabindex="-1"></a><span class="fu">### Stratified sampling</span></span>
<span id="cb34-179"><a href="#cb34-179" aria-hidden="true" tabindex="-1"></a>A slightly more complicated scenario may occur if the classes (encoded by targets) are not well balanced. </span>
<span id="cb34-180"><a href="#cb34-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-181"><a href="#cb34-181" aria-hidden="true" tabindex="-1"></a>In this case we need to ensure that the subsampled data respects those proportions,</span>
<span id="cb34-182"><a href="#cb34-182" aria-hidden="true" tabindex="-1"></a>since the validation (and test) data should be representative </span>
<span id="cb34-183"><a href="#cb34-183" aria-hidden="true" tabindex="-1"></a>This is called "stratification" and can be obtained with help of scikit-learn.</span>
<span id="cb34-184"><a href="#cb34-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-185"><a href="#cb34-185" aria-hidden="true" tabindex="-1"></a>See here for stratified partitioning:</span>
<span id="cb34-186"><a href="#cb34-186" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">StratifiedShuffleSplit()</span><span class="co">](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html)</span>{target="_blank"}</span>
<span id="cb34-187"><a href="#cb34-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-190"><a href="#cb34-190" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-191"><a href="#cb34-191" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: stratified_split</span></span>
<span id="cb34-192"><a href="#cb34-192" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> StratifiedShuffleSplit</span>
<span id="cb34-193"><a href="#cb34-193" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Subset</span>
<span id="cb34-194"><a href="#cb34-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-195"><a href="#cb34-195" aria-hidden="true" tabindex="-1"></a><span class="co"># Use targets directly from dataset</span></span>
<span id="cb34-196"><a href="#cb34-196" aria-hidden="true" tabindex="-1"></a>targets <span class="op">=</span> full_train.targets.numpy()</span>
<span id="cb34-197"><a href="#cb34-197" aria-hidden="true" tabindex="-1"></a>sss <span class="op">=</span> StratifiedShuffleSplit(n_splits<span class="op">=</span><span class="dv">1</span>, train_size<span class="op">=</span>fract, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb34-198"><a href="#cb34-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-199"><a href="#cb34-199" aria-hidden="true" tabindex="-1"></a><span class="co"># sss.split() returns an iterator</span></span>
<span id="cb34-200"><a href="#cb34-200" aria-hidden="true" tabindex="-1"></a>train_idx, val_idx <span class="op">=</span> <span class="bu">next</span>(sss.split(np.zeros(<span class="bu">len</span>(targets)), targets))</span>
<span id="cb34-201"><a href="#cb34-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-202"><a href="#cb34-202" aria-hidden="true" tabindex="-1"></a>train_ds <span class="op">=</span> Subset(full_train, train_idx)</span>
<span id="cb34-203"><a href="#cb34-203" aria-hidden="true" tabindex="-1"></a>val_ds   <span class="op">=</span> Subset(full_train, val_idx)</span>
<span id="cb34-204"><a href="#cb34-204" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'train:'</span>, <span class="bu">len</span>(train_ds))</span>
<span id="cb34-205"><a href="#cb34-205" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'val:'</span>, <span class="bu">len</span>(val_ds))</span>
<span id="cb34-206"><a href="#cb34-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-207"><a href="#cb34-207" aria-hidden="true" tabindex="-1"></a><span class="co"># Sanity check - label frequencies</span></span>
<span id="cb34-208"><a href="#cb34-208" aria-hidden="true" tabindex="-1"></a>train_labels <span class="op">=</span> train_ds.dataset.targets[train_ds.indices]</span>
<span id="cb34-209"><a href="#cb34-209" aria-hidden="true" tabindex="-1"></a>train_counts <span class="op">=</span> torch.bincount(train_labels)</span>
<span id="cb34-210"><a href="#cb34-210" aria-hidden="true" tabindex="-1"></a>train_freq <span class="op">=</span> train_counts <span class="op">/</span> train_counts.<span class="bu">sum</span>()</span>
<span id="cb34-211"><a href="#cb34-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-212"><a href="#cb34-212" aria-hidden="true" tabindex="-1"></a>val_labels <span class="op">=</span> val_ds.dataset.targets[val_ds.indices]</span>
<span id="cb34-213"><a href="#cb34-213" aria-hidden="true" tabindex="-1"></a>val_counts <span class="op">=</span> torch.bincount(val_labels)</span>
<span id="cb34-214"><a href="#cb34-214" aria-hidden="true" tabindex="-1"></a>val_freq <span class="op">=</span> val_counts <span class="op">/</span> val_counts.<span class="bu">sum</span>()</span>
<span id="cb34-215"><a href="#cb34-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-216"><a href="#cb34-216" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(train_freq)</span>
<span id="cb34-217"><a href="#cb34-217" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(val_freq)</span>
<span id="cb34-218"><a href="#cb34-218" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-219"><a href="#cb34-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-220"><a href="#cb34-220" aria-hidden="true" tabindex="-1"></a><span class="fu">### `train_test_split` alternative</span></span>
<span id="cb34-221"><a href="#cb34-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-222"><a href="#cb34-222" aria-hidden="true" tabindex="-1"></a>Below is a frequently used method from scikit-learn. </span>
<span id="cb34-223"><a href="#cb34-223" aria-hidden="true" tabindex="-1"></a>It is shown here only for reference. </span>
<span id="cb34-224"><a href="#cb34-224" aria-hidden="true" tabindex="-1"></a>But notice that it requires several conversions and normalizations that we'll need track carefully.</span>
<span id="cb34-227"><a href="#cb34-227" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-228"><a href="#cb34-228" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: sklearn_train_test_split</span></span>
<span id="cb34-229"><a href="#cb34-229" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb34-230"><a href="#cb34-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-231"><a href="#cb34-231" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb34-232"><a href="#cb34-232" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> TensorDataset</span>
<span id="cb34-233"><a href="#cb34-233" aria-hidden="true" tabindex="-1"></a>fract <span class="op">=</span> <span class="fl">0.8</span></span>
<span id="cb34-234"><a href="#cb34-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-235"><a href="#cb34-235" aria-hidden="true" tabindex="-1"></a><span class="co"># convert from tensors to numpy</span></span>
<span id="cb34-236"><a href="#cb34-236" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> full_train.data.numpy()</span>
<span id="cb34-237"><a href="#cb34-237" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> full_train.targets.numpy()</span>
<span id="cb34-238"><a href="#cb34-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-239"><a href="#cb34-239" aria-hidden="true" tabindex="-1"></a><span class="co"># convenient implementation of stratification</span></span>
<span id="cb34-240"><a href="#cb34-240" aria-hidden="true" tabindex="-1"></a>X_train, X_val, y_train, y_val <span class="op">=</span> train_test_split(X, y, train_size<span class="op">=</span>fract, stratify<span class="op">=</span>y)</span>
<span id="cb34-241"><a href="#cb34-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-242"><a href="#cb34-242" aria-hidden="true" tabindex="-1"></a><span class="co"># convert back to tensors</span></span>
<span id="cb34-243"><a href="#cb34-243" aria-hidden="true" tabindex="-1"></a>train_ds <span class="op">=</span> TensorDataset(torch.tensor(X_train[:, <span class="va">None</span>]<span class="op">/</span><span class="fl">255.</span>, dtype<span class="op">=</span>torch.float32),</span>
<span id="cb34-244"><a href="#cb34-244" aria-hidden="true" tabindex="-1"></a>                                          torch.tensor(y_train, dtype<span class="op">=</span>torch.<span class="bu">long</span>))</span>
<span id="cb34-245"><a href="#cb34-245" aria-hidden="true" tabindex="-1"></a>val_ds   <span class="op">=</span> TensorDataset(torch.tensor(X_val[:, <span class="va">None</span>]<span class="op">/</span><span class="fl">255.</span>, dtype<span class="op">=</span>torch.float32),</span>
<span id="cb34-246"><a href="#cb34-246" aria-hidden="true" tabindex="-1"></a>                                          torch.tensor(y_val, dtype<span class="op">=</span>torch.<span class="bu">long</span>))</span>
<span id="cb34-247"><a href="#cb34-247" aria-hidden="true" tabindex="-1"></a>test_ds  <span class="op">=</span> TensorDataset(test_data.data[:, <span class="va">None</span>]<span class="op">/</span><span class="fl">255.</span>, test_data.targets)</span>
<span id="cb34-248"><a href="#cb34-248" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-249"><a href="#cb34-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-250"><a href="#cb34-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-251"><a href="#cb34-251" aria-hidden="true" tabindex="-1"></a><span class="fu">### Summary</span></span>
<span id="cb34-252"><a href="#cb34-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-253"><a href="#cb34-253" aria-hidden="true" tabindex="-1"></a>In most machine learinng application we want to have a data split </span>
<span id="cb34-254"><a href="#cb34-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-255"><a href="#cb34-255" aria-hidden="true" tabindex="-1"></a><span class="al">![Train-Validation-Test Split. The fractions shown are common, but arbitrary.](images/train_test_split.png)</span></span>
<span id="cb34-256"><a href="#cb34-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-257"><a href="#cb34-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-258"><a href="#cb34-258" aria-hidden="true" tabindex="-1"></a><span class="fu">### Goal Repeat</span></span>
<span id="cb34-259"><a href="#cb34-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-260"><a href="#cb34-260" aria-hidden="true" tabindex="-1"></a>Build a predictor of labels for hand-written digits.</span>
<span id="cb34-263"><a href="#cb34-263" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-264"><a href="#cb34-264" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: PCA</span></span>
<span id="cb34-265"><a href="#cb34-265" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb34-266"><a href="#cb34-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-267"><a href="#cb34-267" aria-hidden="true" tabindex="-1"></a>n_sub <span class="op">=</span> <span class="dv">500</span> <span class="co"># define a subset of digits for speed</span></span>
<span id="cb34-268"><a href="#cb34-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-269"><a href="#cb34-269" aria-hidden="true" tabindex="-1"></a><span class="co"># flattening a tensor to get [samples x features]</span></span>
<span id="cb34-270"><a href="#cb34-270" aria-hidden="true" tabindex="-1"></a>X_sub <span class="op">=</span> full_train.data[:n_sub].flatten(start_dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb34-271"><a href="#cb34-271" aria-hidden="true" tabindex="-1"></a>y_sub <span class="op">=</span> full_train.targets[:n_sub]</span>
<span id="cb34-272"><a href="#cb34-272" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'X: '</span>, X_sub.shape)</span>
<span id="cb34-273"><a href="#cb34-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-274"><a href="#cb34-274" aria-hidden="true" tabindex="-1"></a>X_pca <span class="op">=</span> PCA(n_components <span class="op">=</span> <span class="dv">2</span>).fit_transform(X_sub)</span>
<span id="cb34-275"><a href="#cb34-275" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Scores: '</span>,X_pca.shape)</span>
<span id="cb34-276"><a href="#cb34-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-277"><a href="#cb34-277" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> plt.get_cmap(<span class="st">'tab10'</span>)</span>
<span id="cb34-278"><a href="#cb34-278" aria-hidden="true" tabindex="-1"></a>plt.scatter( X_pca[:,<span class="dv">0</span>], X_pca[:,<span class="dv">1</span>] , c<span class="op">=</span>y_sub, cmap<span class="op">=</span>cm)</span>
<span id="cb34-279"><a href="#cb34-279" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'PCA of MNIST'</span>)</span>
<span id="cb34-280"><a href="#cb34-280" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb34-281"><a href="#cb34-281" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb34-282"><a href="#cb34-282" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-283"><a href="#cb34-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-284"><a href="#cb34-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-285"><a href="#cb34-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-286"><a href="#cb34-286" aria-hidden="true" tabindex="-1"></a><span class="fu">## Data Loading</span></span>
<span id="cb34-287"><a href="#cb34-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-288"><a href="#cb34-288" aria-hidden="true" tabindex="-1"></a>Rather than accessing samples per index we frequently want to load batches of a certain sizes</span>
<span id="cb34-289"><a href="#cb34-289" aria-hidden="true" tabindex="-1"></a>into memory for further analysis. Really large data sets may not even fit into memory, so it is useful</span>
<span id="cb34-290"><a href="#cb34-290" aria-hidden="true" tabindex="-1"></a>to define <span class="in">`DataLoaders`</span> that get data only in batches inot memory.</span>
<span id="cb34-293"><a href="#cb34-293" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-294"><a href="#cb34-294" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: data_loader</span></span>
<span id="cb34-295"><a href="#cb34-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-296"><a href="#cb34-296" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(train_ds, batch_size<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb34-297"><a href="#cb34-297" aria-hidden="true" tabindex="-1"></a>val_loader   <span class="op">=</span> DataLoader(val_ds, batch_size<span class="op">=</span><span class="dv">64</span>)</span>
<span id="cb34-298"><a href="#cb34-298" aria-hidden="true" tabindex="-1"></a>test_loader  <span class="op">=</span> DataLoader(test_data, batch_size<span class="op">=</span><span class="dv">64</span>)</span>
<span id="cb34-299"><a href="#cb34-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-300"><a href="#cb34-300" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"number of train_batches: "</span>, <span class="bu">len</span>(train_loader))</span>
<span id="cb34-301"><a href="#cb34-301" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"number of test_batches:  "</span>, <span class="bu">len</span>(test_loader))</span>
<span id="cb34-302"><a href="#cb34-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-303"><a href="#cb34-303" aria-hidden="true" tabindex="-1"></a><span class="co"># Data Loaders are used a iterator - they return batches of X,y tuples</span></span>
<span id="cb34-304"><a href="#cb34-304" aria-hidden="true" tabindex="-1"></a>X,y <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(train_loader))</span>
<span id="cb34-305"><a href="#cb34-305" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'X batch: '</span>, X.shape)</span>
<span id="cb34-306"><a href="#cb34-306" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'y batch: '</span>, y.shape)</span>
<span id="cb34-307"><a href="#cb34-307" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-308"><a href="#cb34-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-309"><a href="#cb34-309" aria-hidden="true" tabindex="-1"></a><span class="fu">## Define Model</span></span>
<span id="cb34-310"><a href="#cb34-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-311"><a href="#cb34-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-312"><a href="#cb34-312" aria-hidden="true" tabindex="-1"></a><span class="fu">### Rectified Linear Unit</span></span>
<span id="cb34-313"><a href="#cb34-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-314"><a href="#cb34-314" aria-hidden="true" tabindex="-1"></a>Basic Non-linearity</span>
<span id="cb34-315"><a href="#cb34-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-318"><a href="#cb34-318" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-319"><a href="#cb34-319" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: model_define</span></span>
<span id="cb34-320"><a href="#cb34-320" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MNISTModel(nn.Module):</span>
<span id="cb34-321"><a href="#cb34-321" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb34-322"><a href="#cb34-322" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb34-323"><a href="#cb34-323" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.flatten <span class="op">=</span> nn.Flatten()</span>
<span id="cb34-324"><a href="#cb34-324" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(<span class="dv">28</span><span class="op">*</span><span class="dv">28</span>, <span class="dv">128</span>)</span>
<span id="cb34-325"><a href="#cb34-325" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc2 <span class="op">=</span> nn.Linear(<span class="dv">128</span>, <span class="dv">10</span>)</span>
<span id="cb34-326"><a href="#cb34-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-327"><a href="#cb34-327" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb34-328"><a href="#cb34-328" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.flatten(x)</span>
<span id="cb34-329"><a href="#cb34-329" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.fc1(x)</span>
<span id="cb34-330"><a href="#cb34-330" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.relu(x)</span>
<span id="cb34-331"><a href="#cb34-331" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> <span class="va">self</span>.fc2(x)</span>
<span id="cb34-332"><a href="#cb34-332" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> logits</span>
<span id="cb34-333"><a href="#cb34-333" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-334"><a href="#cb34-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-337"><a href="#cb34-337" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-338"><a href="#cb34-338" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: model_create</span></span>
<span id="cb34-339"><a href="#cb34-339" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> MNISTModel().to(device)</span>
<span id="cb34-340"><a href="#cb34-340" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-341"><a href="#cb34-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-342"><a href="#cb34-342" aria-hidden="true" tabindex="-1"></a><span class="fu">## Summarize Model</span></span>
<span id="cb34-345"><a href="#cb34-345" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-346"><a href="#cb34-346" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: model_summary</span></span>
<span id="cb34-347"><a href="#cb34-347" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchinfo <span class="im">import</span> summary</span>
<span id="cb34-348"><a href="#cb34-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-349"><a href="#cb34-349" aria-hidden="true" tabindex="-1"></a>summary(model, input_size<span class="op">=</span>(<span class="dv">1000</span>, <span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span>), device<span class="op">=</span>device)</span>
<span id="cb34-350"><a href="#cb34-350" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-351"><a href="#cb34-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-352"><a href="#cb34-352" aria-hidden="true" tabindex="-1"></a><span class="fu">## Define Loss Function and Optimizer</span></span>
<span id="cb34-353"><a href="#cb34-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-354"><a href="#cb34-354" aria-hidden="true" tabindex="-1"></a><span class="fu">### Adam Optimizer</span></span>
<span id="cb34-355"><a href="#cb34-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-356"><a href="#cb34-356" aria-hidden="true" tabindex="-1"></a>Reference: DP Kingma et al. 2014. Adam: A method for Stochasitic Optimization. 200k+ citations !!!</span>
<span id="cb34-357"><a href="#cb34-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-358"><a href="#cb34-358" aria-hidden="true" tabindex="-1"></a>Don't get stuck in local minima $\to$ adaptive learning rates</span>
<span id="cb34-359"><a href="#cb34-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-360"><a href="#cb34-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-363"><a href="#cb34-363" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-364"><a href="#cb34-364" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: loss_optimizer</span></span>
<span id="cb34-365"><a href="#cb34-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-366"><a href="#cb34-366" aria-hidden="true" tabindex="-1"></a><span class="co"># return sum losses over batch</span></span>
<span id="cb34-367"><a href="#cb34-367" aria-hidden="true" tabindex="-1"></a>loss_function <span class="op">=</span> nn.CrossEntropyLoss(reduction<span class="op">=</span><span class="st">"sum"</span>) </span>
<span id="cb34-368"><a href="#cb34-368" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.Adam(model.parameters())</span>
<span id="cb34-369"><a href="#cb34-369" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-370"><a href="#cb34-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-371"><a href="#cb34-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-372"><a href="#cb34-372" aria-hidden="true" tabindex="-1"></a><span class="fu">## Train Model</span></span>
<span id="cb34-375"><a href="#cb34-375" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-376"><a href="#cb34-376" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: train_model</span></span>
<span id="cb34-377"><a href="#cb34-377" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_model(model, train_loader, val_loader, epochs<span class="op">=</span><span class="dv">25</span>):</span>
<span id="cb34-378"><a href="#cb34-378" aria-hidden="true" tabindex="-1"></a>    history <span class="op">=</span> {<span class="st">'loss'</span>: [], <span class="st">'val_loss'</span>: []}</span>
<span id="cb34-379"><a href="#cb34-379" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb34-380"><a href="#cb34-380" aria-hidden="true" tabindex="-1"></a>        <span class="co"># training</span></span>
<span id="cb34-381"><a href="#cb34-381" aria-hidden="true" tabindex="-1"></a>        model.train()</span>
<span id="cb34-382"><a href="#cb34-382" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb34-383"><a href="#cb34-383" aria-hidden="true" tabindex="-1"></a>        <span class="co"># loop over all train data (in batches given by train_loader)</span></span>
<span id="cb34-384"><a href="#cb34-384" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> xb, yb <span class="kw">in</span> train_loader:</span>
<span id="cb34-385"><a href="#cb34-385" aria-hidden="true" tabindex="-1"></a>            xb, yb <span class="op">=</span> xb.to(device), yb.to(device)</span>
<span id="cb34-386"><a href="#cb34-386" aria-hidden="true" tabindex="-1"></a>            logits <span class="op">=</span> model(xb)</span>
<span id="cb34-387"><a href="#cb34-387" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_function(logits, yb) <span class="co"># total loss for batch</span></span>
<span id="cb34-388"><a href="#cb34-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-389"><a href="#cb34-389" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()            <span class="co"># set gradients to 0</span></span>
<span id="cb34-390"><a href="#cb34-390" aria-hidden="true" tabindex="-1"></a>            loss.backward()                  <span class="co"># calculate gradients with backprop</span></span>
<span id="cb34-391"><a href="#cb34-391" aria-hidden="true" tabindex="-1"></a>            optimizer.step()                 <span class="co"># parameter update</span></span>
<span id="cb34-392"><a href="#cb34-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-393"><a href="#cb34-393" aria-hidden="true" tabindex="-1"></a>            total_loss <span class="op">+=</span> loss.item()        <span class="co"># cumulative loss over all batches</span></span>
<span id="cb34-394"><a href="#cb34-394" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb34-395"><a href="#cb34-395" aria-hidden="true" tabindex="-1"></a>        <span class="co"># average train_loss per sample</span></span>
<span id="cb34-396"><a href="#cb34-396" aria-hidden="true" tabindex="-1"></a>        train_loss <span class="op">=</span> total_loss <span class="op">/</span> <span class="bu">len</span>(train_loader.dataset)</span>
<span id="cb34-397"><a href="#cb34-397" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb34-398"><a href="#cb34-398" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Validation</span></span>
<span id="cb34-399"><a href="#cb34-399" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()</span>
<span id="cb34-400"><a href="#cb34-400" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb34-401"><a href="#cb34-401" aria-hidden="true" tabindex="-1"></a>        <span class="co"># switch off gradient calculation</span></span>
<span id="cb34-402"><a href="#cb34-402" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb34-403"><a href="#cb34-403" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> xb, yb <span class="kw">in</span> val_loader:</span>
<span id="cb34-404"><a href="#cb34-404" aria-hidden="true" tabindex="-1"></a>                xb, yb <span class="op">=</span> xb.to(device), yb.to(device)</span>
<span id="cb34-405"><a href="#cb34-405" aria-hidden="true" tabindex="-1"></a>                logits <span class="op">=</span> model(xb)</span>
<span id="cb34-406"><a href="#cb34-406" aria-hidden="true" tabindex="-1"></a>                loss <span class="op">=</span> loss_function(logits, yb)</span>
<span id="cb34-407"><a href="#cb34-407" aria-hidden="true" tabindex="-1"></a>                total_loss <span class="op">+=</span> loss.item() </span>
<span id="cb34-408"><a href="#cb34-408" aria-hidden="true" tabindex="-1"></a>        val_loss <span class="op">=</span> total_loss <span class="op">/</span> <span class="bu">len</span>(val_loader.dataset)</span>
<span id="cb34-409"><a href="#cb34-409" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb34-410"><a href="#cb34-410" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">'loss'</span>].append(train_loss)</span>
<span id="cb34-411"><a href="#cb34-411" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">'val_loss'</span>].append(val_loss)</span>
<span id="cb34-412"><a href="#cb34-412" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb34-413"><a href="#cb34-413" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">: train_loss=</span><span class="sc">{</span>train_loss<span class="sc">:.4f}</span><span class="ss">, val_loss=</span><span class="sc">{</span>val_loss<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb34-414"><a href="#cb34-414" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> history</span>
<span id="cb34-415"><a href="#cb34-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-416"><a href="#cb34-416" aria-hidden="true" tabindex="-1"></a>hist <span class="op">=</span> train_model(model, train_loader, val_loader, epochs<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb34-417"><a href="#cb34-417" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-418"><a href="#cb34-418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-419"><a href="#cb34-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-420"><a href="#cb34-420" aria-hidden="true" tabindex="-1"></a><span class="fu">## Save Model</span></span>
<span id="cb34-423"><a href="#cb34-423" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-424"><a href="#cb34-424" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: save_model</span></span>
<span id="cb34-425"><a href="#cb34-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-426"><a href="#cb34-426" aria-hidden="true" tabindex="-1"></a>outdir <span class="op">=</span> <span class="st">"output"</span></span>
<span id="cb34-427"><a href="#cb34-427" aria-hidden="true" tabindex="-1"></a>os.makedirs(outdir, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb34-428"><a href="#cb34-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-429"><a href="#cb34-429" aria-hidden="true" tabindex="-1"></a>torch.save(model.state_dict(), <span class="ss">f'</span><span class="sc">{</span>outdir<span class="sc">}</span><span class="ss">/mnist_model.pt'</span>)</span>
<span id="cb34-430"><a href="#cb34-430" aria-hidden="true" tabindex="-1"></a>torch.save(hist, <span class="ss">f"</span><span class="sc">{</span>outdir<span class="sc">}</span><span class="ss">/mnist_history.pt"</span>)</span>
<span id="cb34-431"><a href="#cb34-431" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-432"><a href="#cb34-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-433"><a href="#cb34-433" aria-hidden="true" tabindex="-1"></a><span class="fu">## Load Model</span></span>
<span id="cb34-436"><a href="#cb34-436" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-437"><a href="#cb34-437" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: load_model</span></span>
<span id="cb34-438"><a href="#cb34-438" aria-hidden="true" tabindex="-1"></a>outdir <span class="op">=</span> <span class="st">"output"</span></span>
<span id="cb34-439"><a href="#cb34-439" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> MNISTModel().to(device)</span>
<span id="cb34-440"><a href="#cb34-440" aria-hidden="true" tabindex="-1"></a>tdict <span class="op">=</span> torch.load(<span class="ss">f"</span><span class="sc">{</span>outdir<span class="sc">}</span><span class="ss">/mnist_model.pt"</span>, map_location<span class="op">=</span>device)</span>
<span id="cb34-441"><a href="#cb34-441" aria-hidden="true" tabindex="-1"></a>model.load_state_dict(tdict)</span>
<span id="cb34-442"><a href="#cb34-442" aria-hidden="true" tabindex="-1"></a>hist <span class="op">=</span> torch.load(<span class="ss">f"</span><span class="sc">{</span>outdir<span class="sc">}</span><span class="ss">/mnist_history.pt"</span>)</span>
<span id="cb34-443"><a href="#cb34-443" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-444"><a href="#cb34-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-445"><a href="#cb34-445" aria-hidden="true" tabindex="-1"></a><span class="fu">## Evaluate Training</span></span>
<span id="cb34-448"><a href="#cb34-448" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-449"><a href="#cb34-449" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: evaluate_training</span></span>
<span id="cb34-450"><a href="#cb34-450" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_fit_history(hist, name<span class="op">=</span><span class="st">'loss'</span>, test_score<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb34-451"><a href="#cb34-451" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> name <span class="kw">not</span> <span class="kw">in</span> hist:</span>
<span id="cb34-452"><a href="#cb34-452" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss"> not found in history"</span>)</span>
<span id="cb34-453"><a href="#cb34-453" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span></span>
<span id="cb34-454"><a href="#cb34-454" aria-hidden="true" tabindex="-1"></a>    plt.plot(hist[name], label<span class="op">=</span><span class="st">'train'</span>)</span>
<span id="cb34-455"><a href="#cb34-455" aria-hidden="true" tabindex="-1"></a>    val_name <span class="op">=</span> <span class="st">'val_'</span> <span class="op">+</span> name</span>
<span id="cb34-456"><a href="#cb34-456" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> val_name <span class="kw">in</span> hist:</span>
<span id="cb34-457"><a href="#cb34-457" aria-hidden="true" tabindex="-1"></a>        plt.plot(hist[val_name], label<span class="op">=</span><span class="st">'valid'</span>)</span>
<span id="cb34-458"><a href="#cb34-458" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> test_score <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb34-459"><a href="#cb34-459" aria-hidden="true" tabindex="-1"></a>        plt.axhline(test_score, color<span class="op">=</span><span class="st">'green'</span>, linestyle<span class="op">=</span><span class="st">'-.'</span>, label<span class="op">=</span><span class="st">'test'</span>)</span>
<span id="cb34-460"><a href="#cb34-460" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb34-461"><a href="#cb34-461" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(name)</span>
<span id="cb34-462"><a href="#cb34-462" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb34-463"><a href="#cb34-463" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb34-464"><a href="#cb34-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-465"><a href="#cb34-465" aria-hidden="true" tabindex="-1"></a>plot_fit_history(hist, <span class="st">'loss'</span>)</span>
<span id="cb34-466"><a href="#cb34-466" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-467"><a href="#cb34-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-468"><a href="#cb34-468" aria-hidden="true" tabindex="-1"></a>::: callout-important</span>
<span id="cb34-469"><a href="#cb34-469" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Repeat</span></span>
<span id="cb34-470"><a href="#cb34-470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-471"><a href="#cb34-471" aria-hidden="true" tabindex="-1"></a>In principle the steps can be repeated to improve the model</span>
<span id="cb34-472"><a href="#cb34-472" aria-hidden="true" tabindex="-1"></a>(decrease the training loss) or to speedup the training.</span>
<span id="cb34-473"><a href="#cb34-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-474"><a href="#cb34-474" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>increasing number of neurons or layers</span>
<span id="cb34-475"><a href="#cb34-475" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>work with regularization techniques or data augmentation</span>
<span id="cb34-476"><a href="#cb34-476" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>change learning algorithm or learning rate</span>
<span id="cb34-477"><a href="#cb34-477" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>adjust hyperparameters</span>
<span id="cb34-478"><a href="#cb34-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-479"><a href="#cb34-479" aria-hidden="true" tabindex="-1"></a>! But never show the model the test data until the end !</span>
<span id="cb34-480"><a href="#cb34-480" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb34-481"><a href="#cb34-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-482"><a href="#cb34-482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-483"><a href="#cb34-483" aria-hidden="true" tabindex="-1"></a><span class="fu">## Test Model</span></span>
<span id="cb34-484"><a href="#cb34-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-485"><a href="#cb34-485" aria-hidden="true" tabindex="-1"></a>In principle we can test all test samples (10,000) at once.</span>
<span id="cb34-486"><a href="#cb34-486" aria-hidden="true" tabindex="-1"></a>This is conceptually simpler, but it does requires more care with proper transformations (normalizations)</span>
<span id="cb34-487"><a href="#cb34-487" aria-hidden="true" tabindex="-1"></a>which are run when accessing batches. So in this case we have to normalize by hand</span>
<span id="cb34-490"><a href="#cb34-490" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-491"><a href="#cb34-491" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: test_all</span></span>
<span id="cb34-492"><a href="#cb34-492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-493"><a href="#cb34-493" aria-hidden="true" tabindex="-1"></a><span class="co"># notice that we need to normalize explicitly</span></span>
<span id="cb34-494"><a href="#cb34-494" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> test_data.data.to(device) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb34-495"><a href="#cb34-495" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> test_data.targets.to(device)</span>
<span id="cb34-496"><a href="#cb34-496" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X.shape)</span>
<span id="cb34-497"><a href="#cb34-497" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb34-498"><a href="#cb34-498" aria-hidden="true" tabindex="-1"></a>  all_logits <span class="op">=</span> model(X)</span>
<span id="cb34-499"><a href="#cb34-499" aria-hidden="true" tabindex="-1"></a>  loss <span class="op">=</span> loss_function(all_logits, y)</span>
<span id="cb34-500"><a href="#cb34-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-501"><a href="#cb34-501" aria-hidden="true" tabindex="-1"></a>all_true <span class="op">=</span> y.detach().cpu()</span>
<span id="cb34-502"><a href="#cb34-502" aria-hidden="true" tabindex="-1"></a>test_loss <span class="op">=</span> loss.cpu() <span class="op">/</span> <span class="bu">len</span>(X)</span>
<span id="cb34-503"><a href="#cb34-503" aria-hidden="true" tabindex="-1"></a>plot_fit_history(hist, <span class="st">'loss'</span>, test_loss)</span>
<span id="cb34-504"><a href="#cb34-504" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-505"><a href="#cb34-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-506"><a href="#cb34-506" aria-hidden="true" tabindex="-1"></a>... more commonly batches are also used over test samples, but this requires some</span>
<span id="cb34-507"><a href="#cb34-507" aria-hidden="true" tabindex="-1"></a>collection</span>
<span id="cb34-510"><a href="#cb34-510" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-511"><a href="#cb34-511" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: test_batches</span></span>
<span id="cb34-512"><a href="#cb34-512" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb34-513"><a href="#cb34-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-514"><a href="#cb34-514" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate on test</span></span>
<span id="cb34-515"><a href="#cb34-515" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb34-516"><a href="#cb34-516" aria-hidden="true" tabindex="-1"></a>total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb34-517"><a href="#cb34-517" aria-hidden="true" tabindex="-1"></a>all_logits <span class="op">=</span> []</span>
<span id="cb34-518"><a href="#cb34-518" aria-hidden="true" tabindex="-1"></a>all_true <span class="op">=</span> []</span>
<span id="cb34-519"><a href="#cb34-519" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb34-520"><a href="#cb34-520" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> xb, yb <span class="kw">in</span> test_loader:</span>
<span id="cb34-521"><a href="#cb34-521" aria-hidden="true" tabindex="-1"></a>        xb, yb <span class="op">=</span> xb.to(device), yb.to(device)</span>
<span id="cb34-522"><a href="#cb34-522" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> model(xb)</span>
<span id="cb34-523"><a href="#cb34-523" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_function(logits, yb)</span>
<span id="cb34-524"><a href="#cb34-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-525"><a href="#cb34-525" aria-hidden="true" tabindex="-1"></a>        <span class="co"># collect total_loss, predicted logits and true labels yb</span></span>
<span id="cb34-526"><a href="#cb34-526" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">+=</span> loss.item()</span>
<span id="cb34-527"><a href="#cb34-527" aria-hidden="true" tabindex="-1"></a>        all_logits.append(logits.cpu())</span>
<span id="cb34-528"><a href="#cb34-528" aria-hidden="true" tabindex="-1"></a>        all_true.append(yb.cpu())</span>
<span id="cb34-529"><a href="#cb34-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-530"><a href="#cb34-530" aria-hidden="true" tabindex="-1"></a>test_loss <span class="op">=</span> total_loss <span class="op">/</span> <span class="bu">len</span>(test_loader.dataset) <span class="co"># mean test loss</span></span>
<span id="cb34-531"><a href="#cb34-531" aria-hidden="true" tabindex="-1"></a>all_logits <span class="op">=</span> torch.cat(all_logits)</span>
<span id="cb34-532"><a href="#cb34-532" aria-hidden="true" tabindex="-1"></a>all_true <span class="op">=</span> torch.cat(all_true)</span>
<span id="cb34-533"><a href="#cb34-533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-534"><a href="#cb34-534" aria-hidden="true" tabindex="-1"></a>plot_fit_history(hist, <span class="st">'loss'</span>, test_loss)</span>
<span id="cb34-535"><a href="#cb34-535" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-536"><a href="#cb34-536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-537"><a href="#cb34-537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-540"><a href="#cb34-540" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-541"><a href="#cb34-541" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: confusion_matrix</span></span>
<span id="cb34-542"><a href="#cb34-542" aria-hidden="true" tabindex="-1"></a>all_preds <span class="op">=</span> all_logits.argmax(dim<span class="op">=</span><span class="dv">1</span>).detach().cpu()</span>
<span id="cb34-543"><a href="#cb34-543" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(all_true.numpy(), all_preds.numpy())</span>
<span id="cb34-544"><a href="#cb34-544" aria-hidden="true" tabindex="-1"></a><span class="co">#print(cm)</span></span>
<span id="cb34-545"><a href="#cb34-545" aria-hidden="true" tabindex="-1"></a>plot_cm(cm)</span>
<span id="cb34-546"><a href="#cb34-546" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-547"><a href="#cb34-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-548"><a href="#cb34-548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-549"><a href="#cb34-549" aria-hidden="true" tabindex="-1"></a><span class="fu">## Task for home</span></span>
<span id="cb34-550"><a href="#cb34-550" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-551"><a href="#cb34-551" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Repeat the above, but with the ReLU switch off. Tru to increase the number of nodes or layers</span>
<span id="cb34-552"><a href="#cb34-552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-553"><a href="#cb34-553" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Reality check: scan your own handwritten digit and submit it to your trained model. Pay attention to proper normalization and black/white encoding. Does it work?</span>
<span id="cb34-554"><a href="#cb34-554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-555"><a href="#cb34-555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-556"><a href="#cb34-556" aria-hidden="true" tabindex="-1"></a><span class="fu">## Load own image</span></span>
<span id="cb34-557"><a href="#cb34-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-560"><a href="#cb34-560" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-561"><a href="#cb34-561" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: load_own_image</span></span>
<span id="cb34-562"><a href="#cb34-562" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb34-563"><a href="#cb34-563" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb34-564"><a href="#cb34-564" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> TensorDataset</span>
<span id="cb34-565"><a href="#cb34-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-566"><a href="#cb34-566" aria-hidden="true" tabindex="-1"></a>img_size <span class="op">=</span> test_data.data[<span class="dv">0</span>].shape</span>
<span id="cb34-567"><a href="#cb34-567" aria-hidden="true" tabindex="-1"></a>jpg_path <span class="op">=</span> <span class="st">"images/ANN_Digit3.jpg"</span></span>
<span id="cb34-568"><a href="#cb34-568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-569"><a href="#cb34-569" aria-hidden="true" tabindex="-1"></a><span class="co"># convert to greyscale (L=luminance)</span></span>
<span id="cb34-570"><a href="#cb34-570" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> Image.<span class="bu">open</span>(jpg_path).convert(<span class="st">"L"</span>).resize(img_size)</span>
<span id="cb34-571"><a href="#cb34-571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-572"><a href="#cb34-572" aria-hidden="true" tabindex="-1"></a>img_tensor <span class="op">=</span> transform(img) <span class="co"># transform to tensor</span></span>
<span id="cb34-573"><a href="#cb34-573" aria-hidden="true" tabindex="-1"></a>img_tensor <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> img_tensor <span class="co"># swap black and white</span></span>
<span id="cb34-574"><a href="#cb34-574" aria-hidden="true" tabindex="-1"></a>img_tensor <span class="op">=</span> img_tensor.unsqueeze(<span class="dv">0</span>)</span>
<span id="cb34-575"><a href="#cb34-575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-576"><a href="#cb34-576" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(img_tensor.shape)</span>
<span id="cb34-577"><a href="#cb34-577" aria-hidden="true" tabindex="-1"></a>plt.imshow(img_tensor[<span class="dv">0</span>][<span class="dv">0</span>], cmap<span class="op">=</span><span class="st">"grey"</span>)</span>
<span id="cb34-578"><a href="#cb34-578" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb34-579"><a href="#cb34-579" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-580"><a href="#cb34-580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-583"><a href="#cb34-583" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-584"><a href="#cb34-584" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: predict_own_image</span></span>
<span id="cb34-585"><a href="#cb34-585" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb34-586"><a href="#cb34-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-587"><a href="#cb34-587" aria-hidden="true" tabindex="-1"></a><span class="co"># predict logits</span></span>
<span id="cb34-588"><a href="#cb34-588" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> model(img_tensor.to(device))</span>
<span id="cb34-589"><a href="#cb34-589" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'logits = '</span>, logits.detach().cpu().numpy())</span>
<span id="cb34-590"><a href="#cb34-590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-591"><a href="#cb34-591" aria-hidden="true" tabindex="-1"></a><span class="co"># convert to probabilities</span></span>
<span id="cb34-592"><a href="#cb34-592" aria-hidden="true" tabindex="-1"></a>probs <span class="op">=</span> F.softmax(logits, dim<span class="op">=</span><span class="dv">1</span>).detach().cpu().numpy()[<span class="dv">0</span>]</span>
<span id="cb34-593"><a href="#cb34-593" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-594"><a href="#cb34-594" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">4</span>))</span>
<span id="cb34-595"><a href="#cb34-595" aria-hidden="true" tabindex="-1"></a>plt.bar(<span class="bu">range</span>(<span class="dv">10</span>), probs)</span>
<span id="cb34-596"><a href="#cb34-596" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Digit"</span>)</span>
<span id="cb34-597"><a href="#cb34-597" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Probability"</span>)</span>
<span id="cb34-598"><a href="#cb34-598" aria-hidden="true" tabindex="-1"></a>plt.xticks(<span class="bu">range</span>(<span class="dv">10</span>))</span>
<span id="cb34-599"><a href="#cb34-599" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Model probabilities for each digit"</span>)</span>
<span id="cb34-600"><a href="#cb34-600" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb34-601"><a href="#cb34-601" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-602"><a href="#cb34-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-603"><a href="#cb34-603" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-604"><a href="#cb34-604" aria-hidden="true" tabindex="-1"></a><span class="fu">## Summary</span></span>
<span id="cb34-605"><a href="#cb34-605" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-606"><a href="#cb34-606" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>new data: images as flattened feature vectors</span>
<span id="cb34-607"><a href="#cb34-607" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>highly structured data (unrealistic)</span>
<span id="cb34-608"><a href="#cb34-608" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Consistent use of Data Transformation &amp; Data Loading</span>
<span id="cb34-609"><a href="#cb34-609" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Train-Validation-Test split (with balancing)</span>
<span id="cb34-610"><a href="#cb34-610" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Importance of non-linearity ($\to$ RELU)</span>
<span id="cb34-611"><a href="#cb34-611" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>repetiton: model definition and parameter count</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Made with Quatro</p>
</div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="../../general/about.html">
<p>About</p>
</a>
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/thomasmanke/blog">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>