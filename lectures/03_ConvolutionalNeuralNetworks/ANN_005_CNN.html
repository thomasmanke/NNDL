<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.33">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Thomas Manke">
<meta name="dcterms.date" content="2025-11-30">
<meta name="description" content="bringing spatial structure to neural networks">

<title>Convolutional Neural Networks â€“ Neural Networks and Deep Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-59898bd1c6b9d2bb783127feaa000c76.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-d329e753491efaeac79c98c4b193a686.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-59898bd1c6b9d2bb783127feaa000c76.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-ced0475e70959dfb81820bb49685eb32.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-79cdac72355b6842798e3400025574c4.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../site_libs/bootstrap/bootstrap-ced0475e70959dfb81820bb49685eb32.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Neural Networks and Deep Learning</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-lectures" role="link" data-bs-toggle="dropdown" aria-expanded="false">
      <i class="bi bi-book" role="img">
</i> 
 <span class="menu-text">Lectures</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-lectures">    
        <li>
    <a class="dropdown-item" href="../../lectures/01_MachineLearning/index.html">
 <span class="dropdown-text">01 Machine Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../lectures/02_NeuralNetworks/index.html">
 <span class="dropdown-text">02 Neural Networks</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../lectures/03_ConvolutionalNeuralNetworks/index.html">
 <span class="dropdown-text">03 Convolutional Neural Networks</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../lectures/04_GenerativeModels/index.html">
 <span class="dropdown-text">04 Generative Models</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../projects/index.html"> <i class="bi bi-bricks" role="img">
</i> 
<span class="menu-text">Projects</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../help/index.html"> <i class="bi bi-question-circle" role="img">
</i> 
<span class="menu-text">Help</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../general/Chalkboard.html"> <i class="bi bi-clipboard-fill" role="img">
</i> 
<span class="menu-text">Chalkboard</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/thomasmanke/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#review" id="toc-review" class="nav-link active" data-scroll-target="#review">Review</a></li>
  <li><a href="#another-classical-dataset-cifar-10" id="toc-another-classical-dataset-cifar-10" class="nav-link" data-scroll-target="#another-classical-dataset-cifar-10">Another classical dataset: CIFAR-10</a></li>
  <li><a href="#data-access" id="toc-data-access" class="nav-link" data-scroll-target="#data-access">Data Access</a></li>
  <li><a href="#explore" id="toc-explore" class="nav-link" data-scroll-target="#explore">Explore</a></li>
  <li><a href="#discussion-challenges" id="toc-discussion-challenges" class="nav-link" data-scroll-target="#discussion-challenges">Discussion: Challenges ?</a></li>
  <li><a href="#why-not-add-more-layers" id="toc-why-not-add-more-layers" class="nav-link" data-scroll-target="#why-not-add-more-layers">Why not add more layers ?</a></li>
  <li><a href="#the-idea" id="toc-the-idea" class="nav-link" data-scroll-target="#the-idea">The idea</a></li>
  <li><a href="#convolutions" id="toc-convolutions" class="nav-link" data-scroll-target="#convolutions">Convolutions</a>
  <ul class="collapse">
  <li><a href="#d-conv" id="toc-d-conv" class="nav-link" data-scroll-target="#d-conv">1D Conv</a></li>
  <li><a href="#d-conv-1" id="toc-d-conv-1" class="nav-link" data-scroll-target="#d-conv-1">2D Conv</a></li>
  </ul></li>
  <li><a href="#convolutional-neural-networks-cnn" id="toc-convolutional-neural-networks-cnn" class="nav-link" data-scroll-target="#convolutional-neural-networks-cnn">Convolutional Neural Networks (CNN)</a></li>
  <li><a href="#new-layers-filters-and-pools" id="toc-new-layers-filters-and-pools" class="nav-link" data-scroll-target="#new-layers-filters-and-pools">New layers: Filters and Pools</a></li>
  <li><a href="#convolutions-1" id="toc-convolutions-1" class="nav-link" data-scroll-target="#convolutions-1">Convolutions</a>
  <ul class="collapse">
  <li><a href="#number-of-outputs-from-convolutional-layer" id="toc-number-of-outputs-from-convolutional-layer" class="nav-link" data-scroll-target="#number-of-outputs-from-convolutional-layer">Number of outputs from Convolutional Layer</a></li>
  <li><a href="#habits-and-recommendations" id="toc-habits-and-recommendations" class="nav-link" data-scroll-target="#habits-and-recommendations">Habits and Recommendations</a></li>
  </ul></li>
  <li><a href="#data-preparation" id="toc-data-preparation" class="nav-link" data-scroll-target="#data-preparation">Data Preparation</a>
  <ul class="collapse">
  <li><a href="#split-and-downsample" id="toc-split-and-downsample" class="nav-link" data-scroll-target="#split-and-downsample">Split and Downsample</a></li>
  <li><a href="#data-loaders-for-batches" id="toc-data-loaders-for-batches" class="nav-link" data-scroll-target="#data-loaders-for-batches">Data Loaders for Batches</a></li>
  </ul></li>
  <li><a href="#cnn-pytorch-implementation" id="toc-cnn-pytorch-implementation" class="nav-link" data-scroll-target="#cnn-pytorch-implementation">CNN: PyTorch implementation</a></li>
  <li><a href="#cnn-fitting-gpus-and-batch-size" id="toc-cnn-fitting-gpus-and-batch-size" class="nav-link" data-scroll-target="#cnn-fitting-gpus-and-batch-size">CNN: fitting, GPUs and batch size</a>
  <ul class="collapse">
  <li><a href="#save-model" id="toc-save-model" class="nav-link" data-scroll-target="#save-model">Save Model</a></li>
  </ul></li>
  <li><a href="#evaluations-on-test" id="toc-evaluations-on-test" class="nav-link" data-scroll-target="#evaluations-on-test">Evaluations on Test</a></li>
  <li><a href="#a-closer-look-at-layers" id="toc-a-closer-look-at-layers" class="nav-link" data-scroll-target="#a-closer-look-at-layers">A closer look at layers</a>
  <ul class="collapse">
  <li><a href="#filters" id="toc-filters" class="nav-link" data-scroll-target="#filters">Filters</a></li>
  </ul></li>
  <li><a href="#the-last-layer" id="toc-the-last-layer" class="nav-link" data-scroll-target="#the-last-layer">The last layer</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-page-left" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Convolutional Neural Networks</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>

<div>
  <div class="description">
    bringing spatial structure to neural networks
  </div>
</div>


<div class="quarto-title-meta column-page-left">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Thomas Manke </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">November 30, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<div id="get_packages" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Imports</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> psutil, os</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets, transforms</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, random_split, Subset</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchinfo <span class="im">import</span> summary</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, ConfusionMatrixDisplay, classification_report</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lecture_utils.helper <span class="im">import</span> plot_cm, detect_device</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_fit_history(hist, name<span class="op">=</span><span class="st">'loss'</span>, test_score<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> name <span class="kw">not</span> <span class="kw">in</span> hist:</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss"> not found in history"</span>)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    plt.plot(hist[name], label<span class="op">=</span><span class="st">'train'</span>)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>    val_name <span class="op">=</span> <span class="st">'val_'</span> <span class="op">+</span> name</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> val_name <span class="kw">in</span> hist:</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>        plt.plot(hist[val_name], label<span class="op">=</span><span class="st">'valid'</span>)</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> test_score <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>        plt.axhline(test_score, color<span class="op">=</span><span class="st">'green'</span>, linestyle<span class="op">=</span><span class="st">'-.'</span>, label<span class="op">=</span><span class="st">'test'</span>)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(name)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> dataset2images(dataset, classes, SEED<span class="op">=</span><span class="dv">42</span>, n<span class="op">=</span><span class="dv">16</span>):</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Show n random images from a dataset in a 4x4 grid."""</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>    np.random.seed(SEED)</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>    indices <span class="op">=</span> np.random.choice(<span class="bu">len</span>(dataset), n, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">8</span>))</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, idx <span class="kw">in</span> <span class="bu">enumerate</span>(indices):</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>        img, label <span class="op">=</span> dataset[idx]</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> torch.is_tensor(img):</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>            <span class="co"># PyTorch tensor (C,H,W) -&gt; numpy (H,W,C)</span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>            img_np <span class="op">=</span> img.permute(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>).cpu().numpy()</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="bu">isinstance</span>(img, Image.Image):</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>            <span class="co"># PIL Image</span></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>            img_np <span class="op">=</span> np.array(img)</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="bu">isinstance</span>(img, np.ndarray):</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>            <span class="co"># numpy array already OK</span></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>            img_np <span class="op">=</span> img</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>            <span class="cf">raise</span> <span class="pp">TypeError</span>(</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>                <span class="ss">f"Unsupported image type: </span><span class="sc">{</span><span class="bu">type</span>(img)<span class="sc">}</span><span class="ss">. "</span></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Expected torch.Tensor, PIL.Image, or numpy.ndarray."</span></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Plot</span></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>        ax <span class="op">=</span> plt.subplot(<span class="dv">4</span>, <span class="dv">4</span>, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>        ax.imshow(img_np)</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>        ax.set_title(<span class="ss">f"</span><span class="sc">{</span>label<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>classes[label]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>        ax.axis(<span class="st">"off"</span>)</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>process <span class="op">=</span> psutil.Process(os.getpid())</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mem_MB():</span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> process.memory_info().rss <span class="op">/</span> (<span class="dv">1024</span><span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> detect_device()</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'torch-version: '</span>, torch.__version__)</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'device: '</span>, device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>torch-version:  2.7.1
device:  mps</code></pre>
</div>
</div>
<section id="review" class="level2">
<h2 class="anchored" data-anchor-id="review">Review</h2>
<ul>
<li>neural networks: layers of neurons connected by weights</li>
<li>each neuron: linear function (weights/bias) + non-linear activation function</li>
<li>loss optimization: iterations, (stochastic) gradient descent, momentum, ADAM</li>
<li>mathematical solution: <strong>backprogation</strong> of gradients = chain rule on computational graph</li>
<li>engineering challenges:
<ul>
<li>vanishing gradients <span class="math inline">\(\to\)</span> activation functions, weight initialization</li>
<li>overfitting <span class="math inline">\(\to\)</span> test set, regularization</li>
<li>coding complexity <span class="math inline">\(\to\)</span> frameworks</li>
</ul></li>
<li>interpretation challenges:
<ul>
<li>overconfidence and calibration</li>
<li>overparameterization, interpretation</li>
<li>beyond accuracy and other goals</li>
</ul></li>
</ul>
<!--
- MNIST simplicity: training (and test) data were highly structured: fixed size, grey scale, item centered, only single item 
-->
</section>
<section id="another-classical-dataset-cifar-10" class="level2">
<h2 class="anchored" data-anchor-id="another-classical-dataset-cifar-10">Another classical dataset: CIFAR-10</h2>
<p>This is a set of 50k coloured images [32, 32, 3] in 10 categories.</p>
<p>But unlike MNIST they are not as standardized.</p>
<p>Reference: <a href="https://www.cs.toronto.edu/~kriz/cifar.html" target="_blank" rel="noopener">Krizhevsky, Nair, Hinton</a></p>
<div id="cell-pytorch_CIFAR10" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets, transforms</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># can add many (image) transformations here</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># .... resize, rotate, flip, ....</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># minimal transformation: PIL --&gt; tensor</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    transforms.ToTensor(),</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co"># tochvision dataset: list of tuples (tensor, int)</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> datasets.CIFAR10(root<span class="op">=</span><span class="st">'./data'</span>, </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>test_dataset  <span class="op">=</span> datasets.CIFAR10(root<span class="op">=</span><span class="st">'./data'</span>, </span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    train<span class="op">=</span><span class="va">False</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>train_MB <span class="op">=</span> train_dataset.data.nbytes <span class="op">/</span> <span class="dv">1024</span><span class="op">**</span><span class="dv">2</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>test_MB  <span class="op">=</span> test_dataset.data.nbytes <span class="op">/</span>  <span class="dv">1024</span><span class="op">**</span><span class="dv">2</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>cifar_classes <span class="op">=</span> train_dataset.classes</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"classes: </span><span class="sc">{</span>cifar_classes<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"train: shape=</span><span class="sc">{</span>train_dataset<span class="sc">.</span>data<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> size=</span><span class="sc">{</span>train_MB<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"test:  shape=</span><span class="sc">{</span>test_dataset<span class="sc">.</span>data<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> size=</span><span class="sc">{</span>test_MB<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a><span class="co"># plot a selection</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>dataset2images(train_dataset, cifar_classes)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']
train: shape=(50000, 32, 32, 3) size=146.48
test:  shape=(10000, 32, 32, 3) size=29.30</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ANN_005_CNN_files/figure-html/pytorch_cifar10-output-2.png" id="pytorch_cifar10" width="1153" height="1185" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>CIFAR-10 is downloaded to disk (<code>./data/</code>)</li>
<li>RAM footprint can be much larger (<span class="math inline">\(\to\)</span> DataLoader)</li>
<li>transformations: part of data definition; standardized and modularized</li>
</ul>
</div>
</div>
</section>
<section id="data-access" class="level2">
<h2 class="anchored" data-anchor-id="data-access">Data Access</h2>
<p>There are several ways to access pytorch datasets</p>
<div id="dataset_access" class="cell" data-execution_count="3">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># access raw data: untransformed numpy .data and .targets are CIFAR-specific</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>nd <span class="op">=</span> train_dataset.data </span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"train_dataset.data: </span><span class="sc">{</span>nd<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> -&gt; range: </span><span class="sc">{</span>nd<span class="sc">.</span><span class="bu">min</span>()<span class="sc">.</span>item()<span class="sc">}</span><span class="ss"> - </span><span class="sc">{</span>nd<span class="sc">.</span><span class="bu">max</span>()<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"train_dataset.targets: </span><span class="sc">{</span>np<span class="sc">.</span>unique(train_dataset.targets)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co"># access transformed data: using generic methods (__getitem__ and __len__)</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>img, label <span class="op">=</span> train_dataset[<span class="dv">0</span>]   <span class="co"># returns tuple (torch.tensor, integer)</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"img: </span><span class="sc">{</span>img<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> range: </span><span class="sc">{</span>img<span class="sc">.</span><span class="bu">min</span>()<span class="sc">.</span>item()<span class="sc">}</span><span class="ss"> - </span><span class="sc">{</span>img<span class="sc">.</span><span class="bu">max</span>()<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"label: </span><span class="sc">{</span>label<span class="sc">}</span><span class="ss"> -&gt; </span><span class="sc">{</span>cifar_classes[label]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"len(train_dataset): </span><span class="sc">{</span><span class="bu">len</span>(train_dataset)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>train_dataset.data: (50000, 32, 32, 3) -&gt; range: 0 - 255
train_dataset.targets: [0 1 2 3 4 5 6 7 8 9]
img: torch.Size([3, 32, 32]) range: 0.0 - 1.0
label: 6 -&gt; frog
len(train_dataset): 50000</code></pre>
</div>
</div>
</section>
<section id="explore" class="level2">
<h2 class="anchored" data-anchor-id="explore">Explore</h2>
<div id="cell-label_distribution" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>fract <span class="op">=</span> pd.Series(train_dataset.targets).value_counts(normalize<span class="op">=</span><span class="va">True</span>).sort_index()</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>sns.barplot(x<span class="op">=</span>fract.index, y<span class="op">=</span>fract.values)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"CIFAR-10: Label Distribution"</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Image Class Label"</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ANN_005_CNN_files/figure-html/label_distribution-output-1.png" id="label_distribution" width="905" height="702" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-PCA" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>n_sub <span class="op">=</span> <span class="dv">500</span> <span class="co"># define a subset of digits for speed</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co"># flattening a tensor to get [samples x features]</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>X_sub <span class="op">=</span> train_dataset.data[:n_sub].reshape(n_sub, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>y_sub <span class="op">=</span> train_dataset.targets[:n_sub]</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Images X (flattened): '</span>, X_sub.shape)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>X_pca <span class="op">=</span> PCA(n_components <span class="op">=</span> <span class="dv">2</span>).fit_transform(X_sub)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'PCA Representation:   '</span>,X_pca.shape)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> plt.get_cmap(<span class="st">'tab10'</span>)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>plt.scatter( X_pca[:,<span class="dv">0</span>], X_pca[:,<span class="dv">1</span>] , c<span class="op">=</span>y_sub, cmap<span class="op">=</span>cm)</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'CIFAR-10: PCA'</span>)</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Images X (flattened):  (500, 3072)
PCA Representation:    (500, 2)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ANN_005_CNN_files/figure-html/pca-output-2.png" id="pca" width="863" height="674" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Message
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>No apparent class structure (unlike MNIST)</li>
<li>simple feedforward network (MLP) will not be very accurate classifier</li>
<li>higher accuracy on flattened images will be difficult</li>
<li>change data representation and network architecture</li>
</ul>
</div>
</div>
</section>
<section id="discussion-challenges" class="level2">
<h2 class="anchored" data-anchor-id="discussion-challenges">Discussion: Challenges ?</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/confused_cat.jpg" class="img-fluid figure-img"></p>
<figcaption>Confused Cat</figcaption>
</figure>
</div>
<!--
- spatially distributed features
- view point
- illumination
- deformation
- occlusion 
- intraclass variation
--->
</section>
<section id="why-not-add-more-layers" class="level2">
<h2 class="anchored" data-anchor-id="why-not-add-more-layers">Why not add more layers ?</h2>
<ul>
<li>optimization increasingly hard</li>
<li>does not scale to larger images</li>
<li>MLP do not encode spatial structure <span class="math inline">\(\to\)</span> input permutations possible</li>
<li>performance plateau</li>
</ul>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
FC Problem in Numbers
</div>
</div>
<div class="callout-body-container callout-body">
<p>1 input x 1 hidden layer:</p>
<p>[1000 x 1000 x 3 pixels] x [1000 neurons] <span class="math inline">\(\to\)</span> 3 billion parameters</p>
</div>
</div>
</section>
<section id="the-idea" class="level2">
<h2 class="anchored" data-anchor-id="the-idea">The idea</h2>
<ul>
<li>restrict capacity of each layer <span class="math inline">\(\to\)</span> <strong>weight sharing</strong></li>
<li><em>invariance</em> assumption: should not matter where feature is</li>
</ul>
</section>
<section id="convolutions" class="level2">
<h2 class="anchored" data-anchor-id="convolutions">Convolutions</h2>
<section id="d-conv" class="level3">
<h3 class="anchored" data-anchor-id="d-conv">1D Conv</h3>
<p>Convolutions combine two functions by <strong>sliding</strong> one (the kernel <span class="math inline">\(g(x)\)</span>) over the other <span class="math display">\[
(f \ast g)(x) = \sum_{k=-\infty}^{\infty} f[k] \cdot g[x-k]
\]</span></p>
<p>This can be used conveniently for</p>
<ul>
<li>smoothing/averaging</li>
<li>change detection (derivatives)</li>
<li>pattern detection</li>
<li>sharpening</li>
</ul>
<div id="cell-1D_conv" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.signal <span class="im">import</span> convolve</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a signal with edges</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">400</span>)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> np.sin(x) <span class="op">+</span> <span class="fl">0.1</span><span class="op">*</span>np.random.randn(<span class="bu">len</span>(x))  <span class="co"># noisy sinus</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Kernels</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>xk <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">51</span>)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>sigma <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>g1 <span class="op">=</span> np.exp(<span class="op">-</span>(xk<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>(<span class="dv">2</span><span class="op">*</span>sigma<span class="op">**</span><span class="dv">2</span>))<span class="op">;</span> </span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>g1 <span class="op">=</span> g1 <span class="op">/</span> g1.<span class="bu">sum</span>()             <span class="co"># Gaussian for smoothing/averaging</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>g2 <span class="op">=</span> np.array([<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>])         <span class="co"># 1st derivative</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>g3 <span class="op">=</span> np.array([<span class="dv">1</span>, <span class="op">-</span><span class="dv">2</span>, <span class="dv">1</span>])      <span class="co"># 2nd derivative (Laplacian)</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>g4 <span class="op">=</span> np.array([<span class="op">-</span><span class="dv">1</span>, <span class="dv">2</span>, <span class="op">-</span><span class="dv">1</span>])     <span class="co"># High-pass filter (sharpening)</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Convolve</span></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>fs <span class="op">=</span> convolve(f, g1, mode<span class="op">=</span><span class="st">'same'</span>) <span class="co"># smoothed signal</span></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>f1 <span class="op">=</span> convolve(fs, g2, mode<span class="op">=</span><span class="st">'same'</span>) <span class="co"># 1st derivative</span></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>f1s <span class="op">=</span> convolve(f1, g1, mode<span class="op">=</span><span class="st">'same'</span>) <span class="co"># smoothed 1st derivativ</span></span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>f2 <span class="op">=</span> convolve(f1s, g3, mode<span class="op">=</span><span class="st">'same'</span>) <span class="co"># 2nd derivative</span></span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a><span class="co"># remove boundary effects</span></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>pad <span class="op">=</span> <span class="dv">81</span></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> x[pad:<span class="op">-</span>pad]</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> f[pad:<span class="op">-</span>pad]</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>fs <span class="op">=</span> fs[pad:<span class="op">-</span>pad]</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>f1 <span class="op">=</span> f1[pad:<span class="op">-</span>pad]</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>f2 <span class="op">=</span> f2[pad:<span class="op">-</span>pad]</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot: </span></span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a><span class="co"># kernels are scaled arbitrarly for visibility</span></span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>fsize <span class="op">=</span> <span class="dv">14</span></span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>plt.plot(x, f)</span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Original Data"</span>, fontsize<span class="op">=</span>fsize)</span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a>plt.plot(x, fs)</span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a>plt.bar(xk<span class="op">-</span><span class="dv">1</span>, g1<span class="op">*</span><span class="dv">20</span>, color<span class="op">=</span><span class="st">"orange"</span>, width<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Smoothing/Averaging: fs = f * G  </span><span class="ch">\n</span><span class="st"> Gaussian Kernel $G </span><span class="ch">\\</span><span class="st">propto </span><span class="ch">\\</span><span class="st">exp{(-x^2)}$"</span>, fontsize<span class="op">=</span>fsize)</span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">3</span>)</span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true" tabindex="-1"></a>plt.plot(x, f1)<span class="op">;</span> </span>
<span id="cb10-47"><a href="#cb10-47" aria-hidden="true" tabindex="-1"></a>plt.bar(x[[<span class="dv">99</span>,<span class="dv">100</span>]], g2<span class="op">/</span><span class="dv">20</span>, color<span class="op">=</span><span class="st">"orange"</span>,width<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb10-48"><a href="#cb10-48" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Change Detection: f1 = fs * D </span><span class="ch">\n</span><span class="st"> 1st derivative D = [-1, +1]"</span>, fontsize<span class="op">=</span>fsize)</span>
<span id="cb10-49"><a href="#cb10-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-50"><a href="#cb10-50" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">4</span>)</span>
<span id="cb10-51"><a href="#cb10-51" aria-hidden="true" tabindex="-1"></a>plt.plot(x, f2)<span class="op">;</span> </span>
<span id="cb10-52"><a href="#cb10-52" aria-hidden="true" tabindex="-1"></a>plt.bar(x[[<span class="dv">99</span>,<span class="dv">100</span>,<span class="dv">101</span>]], g3<span class="op">/</span><span class="dv">10000</span>, color<span class="op">=</span><span class="st">"orange"</span>,width<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb10-53"><a href="#cb10-53" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Curvature Detection: f2 = (f1 * G) * L </span><span class="ch">\n</span><span class="st"> 2nd derivative L = [1, -2, 1]"</span>, fontsize<span class="op">=</span>fsize)</span>
<span id="cb10-54"><a href="#cb10-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-55"><a href="#cb10-55" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb10-56"><a href="#cb10-56" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="d_conv" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ANN_005_CNN_files/figure-html/d_conv-output-1.png" width="885" height="886" class="figure-img"></p>
<figcaption>Different kernels in 1D</figcaption>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>appropriate convolutions can extract features</li>
<li>many different kernels possible</li>
<li>find different (more suitable) data representations</li>
<li>kernel rules are shift-invariant and independent of data size</li>
<li>controlled by few parameters</li>
</ul>
</div>
</div>
</section>
<section id="d-conv-1" class="level3">
<h3 class="anchored" data-anchor-id="d-conv-1">2D Conv</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/2D_Conv.png" class="img-fluid figure-img"></p>
<figcaption>Convolution in 2D. Source: Anh H. Reynolds: https://anhreynolds.com/blogs/cnn.html</figcaption>
</figure>
</div>
</section>
</section>
<section id="convolutional-neural-networks-cnn" class="level2">
<h2 class="anchored" data-anchor-id="convolutional-neural-networks-cnn">Convolutional Neural Networks (CNN)</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/Vgg16_Elephant.png" class="img-fluid figure-img"></p>
<figcaption>The big picture - and some jargon.</figcaption>
</figure>
</div>
</section>
<section id="new-layers-filters-and-pools" class="level2">
<h2 class="anchored" data-anchor-id="new-layers-filters-and-pools">New layers: Filters and Pools</h2>
<ul>
<li><p><strong>input layer:</strong> image [3 channels (RGB), height, width]</p></li>
<li><p><strong>convolutional layer</strong> (Conv): K <strong>filters</strong> e.g [K,3,3,3]</p>
<ul>
<li>detect pattern (e.g.&nbsp;horizontal, vertical, diagonal lines)</li>
<li>have the same depth as input</li>
<li>several filter per layer: different filters applied to same spatial location in image</li>
</ul></li>
<li><p><strong>pooling filter</strong> (Pool)</p>
<ul>
<li>spatial downsampling, depth stays the same (e.g.&nbsp;max or average)</li>
</ul></li>
<li><p><strong>fully conncted layer</strong> (Dense)</p>
<ul>
<li>connect all previous nodes</li>
</ul></li>
</ul>
<p>Typical structures: Input - Conv/Relu - Conv/Relu - Pool - Conv/Relu - â€¦ - Dense</p>
</section>
<section id="convolutions-1" class="level2">
<h2 class="anchored" data-anchor-id="convolutions-1">Convolutions</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/Convolution.png" class="img-fluid figure-img"></p>
<figcaption>Convolution and Pooling</figcaption>
</figure>
</div>
<section id="number-of-outputs-from-convolutional-layer" class="level3">
<h3 class="anchored" data-anchor-id="number-of-outputs-from-convolutional-layer">Number of outputs from Convolutional Layer</h3>
<ul>
<li><span class="math inline">\(F\)</span> filter size</li>
<li><span class="math inline">\(S\)</span> stride</li>
<li><span class="math inline">\(P\)</span> padding</li>
</ul>
<p><span class="math display">\[
N_{out} = \frac{N_{in} - F + 2P}{S} + 1
\]</span></p>
<p><strong>Notice</strong></p>
<ul>
<li><span class="math inline">\((N_{in} - F + 2P)/S\)</span> has to be integer for this to work properly.</li>
</ul>
</section>
<section id="habits-and-recommendations" class="level3">
<h3 class="anchored" data-anchor-id="habits-and-recommendations">Habits and Recommendations</h3>
<ul>
<li>use input size <span class="math inline">\(L \times L = 2^n\)</span> (e.g.&nbsp;512)</li>
<li>use stride <span class="math inline">\(S=1\)</span></li>
<li>use padding <span class="math inline">\(P= (F-1)/2\)</span> to retain input size â€“&gt; multiple CONV layers</li>
<li>pooling: <span class="math inline">\(F=2 S=2\)</span> (size reduction: <span class="math inline">\(L \times L --&gt; L/2 \times L/2\)</span> !!! - aggressive reduction</li>
</ul>
</section>
</section>
<section id="data-preparation" class="level2">
<h2 class="anchored" data-anchor-id="data-preparation">Data Preparation</h2>
<p>The data preparation invokes the usual steps:</p>
<ul>
<li>splitting data sets into train, validation, test</li>
<li>optionally: downsample for speed</li>
<li>definition of batches</li>
</ul>
<section id="split-and-downsample" class="level3">
<h3 class="anchored" data-anchor-id="split-and-downsample">Split and Downsample</h3>
<div id="split_and_downsample" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Subset</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>SEED <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>FRACT <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>TRAIN_VAL<span class="op">=</span><span class="fl">0.8</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="co"># get current sizes</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>train_indices <span class="op">=</span> np.arange(<span class="bu">len</span>(train_dataset)) </span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>train_labels  <span class="op">=</span> np.array(train_dataset.targets)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>test_indices  <span class="op">=</span> np.arange(<span class="bu">len</span>(test_dataset))  </span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>test_labels   <span class="op">=</span> np.array(test_dataset.targets)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="co"># subsample FRACT </span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>train_pool_idx, _ <span class="op">=</span> train_test_split(</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>    train_indices, train_size<span class="op">=</span>FRACT, stratify<span class="op">=</span>train_labels, random_state<span class="op">=</span>SEED</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>test_idx, _ <span class="op">=</span> train_test_split(</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>    test_indices, train_size<span class="op">=</span>FRACT, stratify<span class="op">=</span>test_labels, random_state<span class="op">=</span>SEED</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a><span class="co"># split train -&gt; train + val</span></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>y_pool <span class="op">=</span> train_labels[train_pool_idx]</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>train_idx, val_idx <span class="op">=</span> train_test_split(</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>    train_pool_idx, train_size<span class="op">=</span>TRAIN_VAL, stratify<span class="op">=</span>y_pool, random_state<span class="op">=</span>SEED</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>train_ds <span class="op">=</span> Subset(train_dataset, train_idx)</span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>val_ds   <span class="op">=</span> Subset(train_dataset, val_idx)</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>test_ds  <span class="op">=</span> Subset(test_dataset,  test_idx)</span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"train: </span><span class="sc">{</span>train_idx<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, val: </span><span class="sc">{</span>val_idx<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, test: </span><span class="sc">{</span>test_idx<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>train: (4000,), val: (1000,), test: (1000,)</code></pre>
</div>
</div>
</section>
<section id="data-loaders-for-batches" class="level3">
<h3 class="anchored" data-anchor-id="data-loaders-for-batches">Data Loaders for Batches</h3>
<p>DataLoaders provide efficient access to batches during training and evaluation</p>
<div id="data_loaders" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># shuffle = True for randomized optimization and gradients calculation</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(train_ds, batch_size<span class="op">=</span>BATCH_SIZE, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># shuffle = False for fixed and consistent evaluation and metrics</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>test_loader  <span class="op">=</span> DataLoader(test_ds, batch_size<span class="op">=</span>BATCH_SIZE, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>val_loader   <span class="op">=</span> DataLoader(val_ds, batch_size<span class="op">=</span>BATCH_SIZE, shuffle<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
<section id="cnn-pytorch-implementation" class="level2">
<h2 class="anchored" data-anchor-id="cnn-pytorch-implementation">CNN: PyTorch implementation</h2>
<div id="cnn_model" class="cell" data-execution_count="9">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchinfo <span class="im">import</span> summary</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of classes</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>nc <span class="op">=</span> <span class="bu">len</span>(cifar_classes)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>X_train, y_train <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(train_loader))</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'input_shape:      '</span>, X_train.shape)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'number of classes:'</span>, nc)</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CNN_Model(nn.Module):</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_classes<span class="op">=</span>nc):</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> nn.Conv2d(<span class="dv">3</span>, <span class="dv">32</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pool1 <span class="op">=</span> nn.MaxPool2d(<span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.flatten <span class="op">=</span> nn.Flatten()</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(<span class="dv">32</span> <span class="op">*</span> <span class="dv">16</span> <span class="op">*</span> <span class="dv">16</span>, <span class="dv">128</span>)</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc2 <span class="op">=</span> nn.Linear(<span class="dv">128</span>, num_classes)</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.relu(<span class="va">self</span>.conv1(x))</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.pool1(x)</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.flatten(x)</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.relu(<span class="va">self</span>.fc1(x))</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.fc2(x)</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> CNN_Model().to(device)</span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(summary(model, input_data<span class="op">=</span>X_train, device<span class="op">=</span>device))</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>loss_function <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.Adam(model.parameters())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>input_shape:       torch.Size([64, 3, 32, 32])
number of classes: 10
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
CNN_Model                                [64, 10]                  --
â”œâ”€Conv2d: 1-1                            [64, 32, 32, 32]          896
â”œâ”€MaxPool2d: 1-2                         [64, 32, 16, 16]          --
â”œâ”€Flatten: 1-3                           [64, 8192]                --
â”œâ”€Linear: 1-4                            [64, 128]                 1,048,704
â”œâ”€Linear: 1-5                            [64, 10]                  1,290
==========================================================================================
Total params: 1,050,890
Trainable params: 1,050,890
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 125.92
==========================================================================================
Input size (MB): 0.79
Forward/backward pass size (MB): 16.85
Params size (MB): 4.20
Estimated Total Size (MB): 21.84
==========================================================================================</code></pre>
</div>
</div>
<p><strong>Notice</strong></p>
<ul>
<li>memory and compute in early layers, parameters in last layer</li>
<li>numbers can more than double when the gradients are calculated + caching</li>
<li>maintain also multiple images (batch normalization)</li>
</ul>
</section>
<section id="cnn-fitting-gpus-and-batch-size" class="level2">
<h2 class="anchored" data-anchor-id="cnn-fitting-gpus-and-batch-size">CNN: fitting, GPUs and batch size</h2>
<p>The following cell will fit the model. This will take some time - especially without dedicated hardware (e.g.&nbsp;GPU) or further optimization (improved algorithm).</p>
<div id="train_model" class="cell" data-execution_count="10">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>num_epochs <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> {<span class="st">'loss'</span>: [], <span class="st">'val_loss'</span>: []}</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> xb, yb <span class="kw">in</span> train_loader:</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>        xb, yb <span class="op">=</span> xb.to(device), yb.to(device)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> model(xb)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_function(logits, yb)</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">+=</span> loss.item()</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>    train_loss <span class="op">=</span> total_loss <span class="op">/</span> <span class="bu">len</span>(train_loader.dataset)</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>    history[<span class="st">'loss'</span>].append(train_loss)</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Validation</span></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>    val_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> xb, yb <span class="kw">in</span> val_loader:</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>            xb, yb <span class="op">=</span> xb.to(device), yb.to(device)</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>            logits <span class="op">=</span> model(xb)</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_function(logits, yb)</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>            val_loss <span class="op">+=</span> loss.item()</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>    val_loss <span class="op">=</span> val_loss <span class="op">/</span> <span class="bu">len</span>(val_loader.dataset)</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>    history[<span class="st">'val_loss'</span>].append(val_loss)</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">: train_loss=</span><span class="sc">{</span>train_loss<span class="sc">:.4f}</span><span class="ss">, val_loss=</span><span class="sc">{</span>val_loss<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1: train_loss=0.0323, val_loss=0.0290
Epoch 2: train_loss=0.0272, val_loss=0.0275
Epoch 3: train_loss=0.0246, val_loss=0.0265
Epoch 4: train_loss=0.0226, val_loss=0.0244
Epoch 5: train_loss=0.0209, val_loss=0.0235</code></pre>
</div>
</div>
<section id="save-model" class="level3">
<h3 class="anchored" data-anchor-id="save-model">Save Model</h3>
<p>Since training is expensive we usually want to safe the model and history. In real application this would also be done during training.</p>
<div id="save_model" class="cell" data-execution_count="11">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>outdir <span class="op">=</span> <span class="st">"output"</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>os.makedirs(outdir, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>torch.save(model.state_dict(), <span class="ss">f'</span><span class="sc">{</span>outdir<span class="sc">}</span><span class="ss">/cifar_model.pt'</span>)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>torch.save(history, <span class="ss">f"</span><span class="sc">{</span>outdir<span class="sc">}</span><span class="ss">/cifar_history.pt"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
CIFAR-Demo
</div>
</div>
<div class="callout-body-container callout-body">
<p><a href="https://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html" target="_blank" rel="noopener">CNN with Javascript. Animation from Karpathy.</a></p>
</div>
</div>
</section>
</section>
<section id="evaluations-on-test" class="level2">
<h2 class="anchored" data-anchor-id="evaluations-on-test">Evaluations on Test</h2>
<div id="test_evaluation" class="cell" data-execution_count="12">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate on test</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>all_logits <span class="op">=</span> []</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>all_true <span class="op">=</span> []</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> xb, yb <span class="kw">in</span> test_loader:</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>        xb, yb <span class="op">=</span> xb.to(device), yb.to(device)</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> model(xb)</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_function(logits, yb)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># collect total_loss, predicted logits and true labels yb</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">+=</span> loss.item()</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>        all_logits.append(logits.cpu())</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>        all_true.append(yb.cpu())</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>test_loss <span class="op">=</span> total_loss <span class="op">/</span> <span class="bu">len</span>(test_loader.dataset) <span class="co"># mean test loss</span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>all_logits <span class="op">=</span> torch.cat(all_logits)</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>all_true <span class="op">=</span> torch.cat(all_true)</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>plot_fit_history(history, <span class="st">'loss'</span>, test_loss)</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>all_preds <span class="op">=</span> all_logits.argmax(dim<span class="op">=</span><span class="dv">1</span>).detach().cpu()</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(all_true.numpy(), all_preds.numpy())</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>disp <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix<span class="op">=</span>cm)</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>disp.plot(cmap<span class="op">=</span><span class="st">'Blues'</span>)</span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ANN_005_CNN_files/figure-html/test_evaluation-output-1.png" id="test_evaluation-1" width="946" height="670" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ANN_005_CNN_files/figure-html/test_evaluation-output-2.png" id="test_evaluation-2" width="774" height="670" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>Discussion:</strong> What could be further improvements?</p>
</section>
<section id="a-closer-look-at-layers" class="level2">
<h2 class="anchored" data-anchor-id="a-closer-look-at-layers">A closer look at layers</h2>
<p>Motivation: Understand prediction in terms of layered â€œconceptsâ€</p>
<div id="model_summary" class="cell" data-execution_count="13">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(summary(model, input_data<span class="op">=</span>X_train, device<span class="op">=</span>device))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
CNN_Model                                [64, 10]                  --
â”œâ”€Conv2d: 1-1                            [64, 32, 32, 32]          896
â”œâ”€MaxPool2d: 1-2                         [64, 32, 16, 16]          --
â”œâ”€Flatten: 1-3                           [64, 8192]                --
â”œâ”€Linear: 1-4                            [64, 128]                 1,048,704
â”œâ”€Linear: 1-5                            [64, 10]                  1,290
==========================================================================================
Total params: 1,050,890
Trainable params: 1,050,890
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 125.92
==========================================================================================
Input size (MB): 0.79
Forward/backward pass size (MB): 16.85
Params size (MB): 4.20
Estimated Total Size (MB): 21.84
==========================================================================================</code></pre>
</div>
</div>
<section id="filters" class="level3">
<h3 class="anchored" data-anchor-id="filters">Filters</h3>
<div id="cell-filters" class="cell" data-execution_count="14">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the weights of the first conv layer (shape: [out_channels, in_channels, H, W])</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>W <span class="op">=</span> model.conv1.weight.data.cpu().numpy()  <span class="co"># shape: (32, 3, 3, 3)</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'W.shape: '</span>,W.shape)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">8</span>))</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>nr, nc <span class="op">=</span> (<span class="dv">5</span>, <span class="dv">5</span>)  <span class="co"># number of rows and columns</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(nr <span class="op">*</span> nc):</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Each filter: shape [3, 3, 3] (in_channels, H, W)</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Transpose to (H, W, C) for imshow</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> W[i].transpose(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>)</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Normalize to [0, 1] for visualization</span></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> (img <span class="op">-</span> img.<span class="bu">min</span>()) <span class="op">/</span> (img.<span class="bu">max</span>() <span class="op">-</span> img.<span class="bu">min</span>() <span class="op">+</span> <span class="fl">1e-5</span>)</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> fig.add_subplot(nr, nc, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>    ax.imshow(img)</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f'filter: </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>    ax.axis(<span class="st">'off'</span>)</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>W.shape:  (32, 3, 3, 3)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ANN_005_CNN_files/figure-html/filters-output-2.png" id="filters" width="1729" height="986" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>Notice:</strong> Maximal activation for all RGB channels=1 (black) and minimal activation for all RGB channels = 0 (white)</p>
</section>
</section>
<section id="the-last-layer" class="level2">
<h2 class="anchored" data-anchor-id="the-last-layer">The last layer</h2>
<p>The goal of the added convolutional layers is to obtain a better representation of the image data by representing spatial features (edges etc.). If this is successful then we would expect better separation properties in the penultimate layer (last before output layer).</p>
<div id="cell-last_layer_PCA" class="cell" data-execution_count="15">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> TSNE</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Get representations from the penultimate (last hidden) layer in PyTorch</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="co"># We'll use torch.no_grad() and a hook or simply modify the model to return features</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Example assumes model: features = model.fc1 output after relu, before final fc2</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_last_layer_features(model, dataloader, device, n_samples<span class="op">=</span><span class="dv">500</span>):</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>    features <span class="op">=</span> []</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> []</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>        count <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> xb, yb <span class="kw">in</span> dataloader:</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>            xb, yb <span class="op">=</span> xb.to(device), yb.to(device)</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> F.relu(model.conv1(xb))</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> model.pool1(x)</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> model.flatten(x)</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> F.relu(model.fc1(x))</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Forward up to penultimate layer</span></span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>            features.append(x.cpu())</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>            labels.append(yb.cpu())</span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>            count <span class="op">+=</span> xb.size(<span class="dv">0</span>)</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> count <span class="op">&gt;=</span> n_samples:</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span></span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>    features <span class="op">=</span> torch.cat(features)[:n_samples]</span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> torch.cat(labels)[:n_samples]</span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> features.numpy(), labels.numpy()</span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Get features for train set (or a subset)</span></span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a>X_lay, y <span class="op">=</span> get_last_layer_features(model, train_loader, device, n_samples<span class="op">=</span><span class="dv">500</span>)</span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Also get original input (flattened)</span></span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a>X_orig <span class="op">=</span> []</span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>count <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> xb, yb <span class="kw">in</span> train_loader:</span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a>    X_orig.append(xb.cpu().reshape(xb.size(<span class="dv">0</span>), <span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a>    count <span class="op">+=</span> xb.size(<span class="dv">0</span>)</span>
<span id="cb24-40"><a href="#cb24-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> count <span class="op">&gt;=</span> <span class="dv">500</span>:</span>
<span id="cb24-41"><a href="#cb24-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb24-42"><a href="#cb24-42" aria-hidden="true" tabindex="-1"></a>X_orig <span class="op">=</span> torch.cat(X_orig)[:<span class="dv">500</span>].numpy()</span>
<span id="cb24-43"><a href="#cb24-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-44"><a href="#cb24-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'X shapes: '</span>, X_orig.shape, X_lay.shape)</span>
<span id="cb24-45"><a href="#cb24-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-46"><a href="#cb24-46" aria-hidden="true" tabindex="-1"></a><span class="co"># PCA or t-SNE</span></span>
<span id="cb24-47"><a href="#cb24-47" aria-hidden="true" tabindex="-1"></a>X_pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>).fit_transform(X_orig)</span>
<span id="cb24-48"><a href="#cb24-48" aria-hidden="true" tabindex="-1"></a>X_lay_pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>).fit_transform(X_lay)</span>
<span id="cb24-49"><a href="#cb24-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'PCA Shapes: '</span>, X_pca.shape, X_lay_pca.shape)</span>
<span id="cb24-50"><a href="#cb24-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-51"><a href="#cb24-51" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">4</span>))</span>
<span id="cb24-52"><a href="#cb24-52" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> plt.get_cmap(<span class="st">'tab10'</span>)</span>
<span id="cb24-53"><a href="#cb24-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-54"><a href="#cb24-54" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb24-55"><a href="#cb24-55" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_pca[:, <span class="dv">0</span>], X_pca[:, <span class="dv">1</span>], c<span class="op">=</span>y, cmap<span class="op">=</span>cm)</span>
<span id="cb24-56"><a href="#cb24-56" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'PCA: X orig.'</span>)</span>
<span id="cb24-57"><a href="#cb24-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-58"><a href="#cb24-58" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb24-59"><a href="#cb24-59" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_lay_pca[:, <span class="dv">0</span>], X_lay_pca[:, <span class="dv">1</span>], c<span class="op">=</span>y, cmap<span class="op">=</span>cm)</span>
<span id="cb24-60"><a href="#cb24-60" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'PCA - X transformed'</span>)</span>
<span id="cb24-61"><a href="#cb24-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-62"><a href="#cb24-62" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb24-63"><a href="#cb24-63" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>X shapes:  (500, 3072) (500, 128)
PCA Shapes:  (500, 2) (500, 2)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ANN_005_CNN_files/figure-html/last_layer_pca-output-2.png" id="last_layer_pca" width="1006" height="558" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Summary
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>MLP: pass 1D vectors from layer to layer</li>
<li>CNN: match network to spatial structure (pass 2D images)</li>
<li>goal: â€˜betterâ€™ representation of input data</li>
<li>Lower layers: Primitive â€œconceptsâ€<br>
</li>
<li>Deeper layers: Higher order â€œconceptsâ€</li>
</ul>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/cs231n/cs231n.github.io/raw/master/assets/cnn/convnet.jpeg" class="img-fluid figure-img"></p>
<figcaption>Example from VGGNet. Image from A. Karpathy</figcaption>
</figure>
</div>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "î§‹";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb26" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> Convolutional Neural Networks</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="an">jupyter:</span><span class="co"> pytorch</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="an">draft:</span><span class="co"> false</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="an">eval:</span><span class="co"> true</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> bringing spatial structure to neural networks</span></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: get_packages</span></span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: Imports</span></span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> psutil, os</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets, transforms</span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, random_split, Subset</span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchinfo <span class="im">import</span> summary</span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, ConfusionMatrixDisplay, classification_report</span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lecture_utils.helper <span class="im">import</span> plot_cm, detect_device</span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_fit_history(hist, name<span class="op">=</span><span class="st">'loss'</span>, test_score<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> name <span class="kw">not</span> <span class="kw">in</span> hist:</span>
<span id="cb26-34"><a href="#cb26-34" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss"> not found in history"</span>)</span>
<span id="cb26-35"><a href="#cb26-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span></span>
<span id="cb26-36"><a href="#cb26-36" aria-hidden="true" tabindex="-1"></a>    plt.plot(hist[name], label<span class="op">=</span><span class="st">'train'</span>)</span>
<span id="cb26-37"><a href="#cb26-37" aria-hidden="true" tabindex="-1"></a>    val_name <span class="op">=</span> <span class="st">'val_'</span> <span class="op">+</span> name</span>
<span id="cb26-38"><a href="#cb26-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> val_name <span class="kw">in</span> hist:</span>
<span id="cb26-39"><a href="#cb26-39" aria-hidden="true" tabindex="-1"></a>        plt.plot(hist[val_name], label<span class="op">=</span><span class="st">'valid'</span>)</span>
<span id="cb26-40"><a href="#cb26-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> test_score <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb26-41"><a href="#cb26-41" aria-hidden="true" tabindex="-1"></a>        plt.axhline(test_score, color<span class="op">=</span><span class="st">'green'</span>, linestyle<span class="op">=</span><span class="st">'-.'</span>, label<span class="op">=</span><span class="st">'test'</span>)</span>
<span id="cb26-42"><a href="#cb26-42" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb26-43"><a href="#cb26-43" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(name)</span>
<span id="cb26-44"><a href="#cb26-44" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb26-45"><a href="#cb26-45" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb26-46"><a href="#cb26-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-47"><a href="#cb26-47" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> dataset2images(dataset, classes, SEED<span class="op">=</span><span class="dv">42</span>, n<span class="op">=</span><span class="dv">16</span>):</span>
<span id="cb26-48"><a href="#cb26-48" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Show n random images from a dataset in a 4x4 grid."""</span></span>
<span id="cb26-49"><a href="#cb26-49" aria-hidden="true" tabindex="-1"></a>    np.random.seed(SEED)</span>
<span id="cb26-50"><a href="#cb26-50" aria-hidden="true" tabindex="-1"></a>    indices <span class="op">=</span> np.random.choice(<span class="bu">len</span>(dataset), n, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb26-51"><a href="#cb26-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-52"><a href="#cb26-52" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">8</span>))</span>
<span id="cb26-53"><a href="#cb26-53" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, idx <span class="kw">in</span> <span class="bu">enumerate</span>(indices):</span>
<span id="cb26-54"><a href="#cb26-54" aria-hidden="true" tabindex="-1"></a>        img, label <span class="op">=</span> dataset[idx]</span>
<span id="cb26-55"><a href="#cb26-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-56"><a href="#cb26-56" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> torch.is_tensor(img):</span>
<span id="cb26-57"><a href="#cb26-57" aria-hidden="true" tabindex="-1"></a>            <span class="co"># PyTorch tensor (C,H,W) -&gt; numpy (H,W,C)</span></span>
<span id="cb26-58"><a href="#cb26-58" aria-hidden="true" tabindex="-1"></a>            img_np <span class="op">=</span> img.permute(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>).cpu().numpy()</span>
<span id="cb26-59"><a href="#cb26-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-60"><a href="#cb26-60" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="bu">isinstance</span>(img, Image.Image):</span>
<span id="cb26-61"><a href="#cb26-61" aria-hidden="true" tabindex="-1"></a>            <span class="co"># PIL Image</span></span>
<span id="cb26-62"><a href="#cb26-62" aria-hidden="true" tabindex="-1"></a>            img_np <span class="op">=</span> np.array(img)</span>
<span id="cb26-63"><a href="#cb26-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-64"><a href="#cb26-64" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="bu">isinstance</span>(img, np.ndarray):</span>
<span id="cb26-65"><a href="#cb26-65" aria-hidden="true" tabindex="-1"></a>            <span class="co"># numpy array already OK</span></span>
<span id="cb26-66"><a href="#cb26-66" aria-hidden="true" tabindex="-1"></a>            img_np <span class="op">=</span> img</span>
<span id="cb26-67"><a href="#cb26-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-68"><a href="#cb26-68" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb26-69"><a href="#cb26-69" aria-hidden="true" tabindex="-1"></a>            <span class="cf">raise</span> <span class="pp">TypeError</span>(</span>
<span id="cb26-70"><a href="#cb26-70" aria-hidden="true" tabindex="-1"></a>                <span class="ss">f"Unsupported image type: </span><span class="sc">{</span><span class="bu">type</span>(img)<span class="sc">}</span><span class="ss">. "</span></span>
<span id="cb26-71"><a href="#cb26-71" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Expected torch.Tensor, PIL.Image, or numpy.ndarray."</span></span>
<span id="cb26-72"><a href="#cb26-72" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb26-73"><a href="#cb26-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-74"><a href="#cb26-74" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Plot</span></span>
<span id="cb26-75"><a href="#cb26-75" aria-hidden="true" tabindex="-1"></a>        ax <span class="op">=</span> plt.subplot(<span class="dv">4</span>, <span class="dv">4</span>, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb26-76"><a href="#cb26-76" aria-hidden="true" tabindex="-1"></a>        ax.imshow(img_np)</span>
<span id="cb26-77"><a href="#cb26-77" aria-hidden="true" tabindex="-1"></a>        ax.set_title(<span class="ss">f"</span><span class="sc">{</span>label<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>classes[label]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-78"><a href="#cb26-78" aria-hidden="true" tabindex="-1"></a>        ax.axis(<span class="st">"off"</span>)</span>
<span id="cb26-79"><a href="#cb26-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-80"><a href="#cb26-80" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb26-81"><a href="#cb26-81" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb26-82"><a href="#cb26-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-83"><a href="#cb26-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-84"><a href="#cb26-84" aria-hidden="true" tabindex="-1"></a>process <span class="op">=</span> psutil.Process(os.getpid())</span>
<span id="cb26-85"><a href="#cb26-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-86"><a href="#cb26-86" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mem_MB():</span>
<span id="cb26-87"><a href="#cb26-87" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> process.memory_info().rss <span class="op">/</span> (<span class="dv">1024</span><span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb26-88"><a href="#cb26-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-89"><a href="#cb26-89" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> detect_device()</span>
<span id="cb26-90"><a href="#cb26-90" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb26-91"><a href="#cb26-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-92"><a href="#cb26-92" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'torch-version: '</span>, torch.__version__)</span>
<span id="cb26-93"><a href="#cb26-93" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'device: '</span>, device)</span>
<span id="cb26-94"><a href="#cb26-94" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-95"><a href="#cb26-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-96"><a href="#cb26-96" aria-hidden="true" tabindex="-1"></a><span class="fu">## Review</span></span>
<span id="cb26-97"><a href="#cb26-97" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>neural networks: layers of neurons connected by weights</span>
<span id="cb26-98"><a href="#cb26-98" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>each neuron: linear function (weights/bias) + non-linear activation function</span>
<span id="cb26-99"><a href="#cb26-99" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>loss optimization: iterations, (stochastic) gradient descent, momentum, ADAM</span>
<span id="cb26-100"><a href="#cb26-100" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>mathematical solution: **backprogation** of gradients = chain rule on computational graph</span>
<span id="cb26-101"><a href="#cb26-101" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>engineering challenges: </span>
<span id="cb26-102"><a href="#cb26-102" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>vanishing gradients $\to$ activation functions, weight initialization</span>
<span id="cb26-103"><a href="#cb26-103" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>overfitting $\to$ test set, regularization</span>
<span id="cb26-104"><a href="#cb26-104" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>coding complexity $\to$ frameworks</span>
<span id="cb26-105"><a href="#cb26-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-106"><a href="#cb26-106" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>interpretation challenges:</span>
<span id="cb26-107"><a href="#cb26-107" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>overconfidence and calibration</span>
<span id="cb26-108"><a href="#cb26-108" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>overparameterization, interpretation</span>
<span id="cb26-109"><a href="#cb26-109" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>beyond accuracy and other goals</span>
<span id="cb26-110"><a href="#cb26-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-111"><a href="#cb26-111" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--</span></span>
<span id="cb26-112"><a href="#cb26-112" aria-hidden="true" tabindex="-1"></a><span class="co">- MNIST simplicity: training (and test) data were highly structured: fixed size, grey scale, item centered, only single item </span></span>
<span id="cb26-113"><a href="#cb26-113" aria-hidden="true" tabindex="-1"></a><span class="co">--&gt;</span></span>
<span id="cb26-114"><a href="#cb26-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-115"><a href="#cb26-115" aria-hidden="true" tabindex="-1"></a><span class="fu">## Another classical dataset: CIFAR-10</span></span>
<span id="cb26-116"><a href="#cb26-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-117"><a href="#cb26-117" aria-hidden="true" tabindex="-1"></a>This is a set of 50k coloured images <span class="co">[</span><span class="ot">32, 32, 3</span><span class="co">]</span> in 10 categories.</span>
<span id="cb26-118"><a href="#cb26-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-119"><a href="#cb26-119" aria-hidden="true" tabindex="-1"></a>But unlike MNIST they are not as standardized.</span>
<span id="cb26-120"><a href="#cb26-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-121"><a href="#cb26-121" aria-hidden="true" tabindex="-1"></a>Reference: <span class="co">[</span><span class="ot">Krizhevsky, Nair, Hinton</span><span class="co">](https://www.cs.toronto.edu/~kriz/cifar.html)</span>{target="_blank" rel="noopener"}</span>
<span id="cb26-122"><a href="#cb26-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-125"><a href="#cb26-125" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-126"><a href="#cb26-126" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: pytorch_CIFAR10</span></span>
<span id="cb26-127"><a href="#cb26-127" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb26-128"><a href="#cb26-128" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets, transforms</span>
<span id="cb26-129"><a href="#cb26-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-130"><a href="#cb26-130" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb26-131"><a href="#cb26-131" aria-hidden="true" tabindex="-1"></a>    <span class="co"># can add many (image) transformations here</span></span>
<span id="cb26-132"><a href="#cb26-132" aria-hidden="true" tabindex="-1"></a>    <span class="co"># .... resize, rotate, flip, ....</span></span>
<span id="cb26-133"><a href="#cb26-133" aria-hidden="true" tabindex="-1"></a>    <span class="co"># minimal transformation: PIL --&gt; tensor</span></span>
<span id="cb26-134"><a href="#cb26-134" aria-hidden="true" tabindex="-1"></a>    transforms.ToTensor(),</span>
<span id="cb26-135"><a href="#cb26-135" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb26-136"><a href="#cb26-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-137"><a href="#cb26-137" aria-hidden="true" tabindex="-1"></a><span class="co"># tochvision dataset: list of tuples (tensor, int)</span></span>
<span id="cb26-138"><a href="#cb26-138" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> datasets.CIFAR10(root<span class="op">=</span><span class="st">'./data'</span>, </span>
<span id="cb26-139"><a href="#cb26-139" aria-hidden="true" tabindex="-1"></a>    train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb26-140"><a href="#cb26-140" aria-hidden="true" tabindex="-1"></a>test_dataset  <span class="op">=</span> datasets.CIFAR10(root<span class="op">=</span><span class="st">'./data'</span>, </span>
<span id="cb26-141"><a href="#cb26-141" aria-hidden="true" tabindex="-1"></a>    train<span class="op">=</span><span class="va">False</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb26-142"><a href="#cb26-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-143"><a href="#cb26-143" aria-hidden="true" tabindex="-1"></a>train_MB <span class="op">=</span> train_dataset.data.nbytes <span class="op">/</span> <span class="dv">1024</span><span class="op">**</span><span class="dv">2</span></span>
<span id="cb26-144"><a href="#cb26-144" aria-hidden="true" tabindex="-1"></a>test_MB  <span class="op">=</span> test_dataset.data.nbytes <span class="op">/</span>  <span class="dv">1024</span><span class="op">**</span><span class="dv">2</span></span>
<span id="cb26-145"><a href="#cb26-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-146"><a href="#cb26-146" aria-hidden="true" tabindex="-1"></a>cifar_classes <span class="op">=</span> train_dataset.classes</span>
<span id="cb26-147"><a href="#cb26-147" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"classes: </span><span class="sc">{</span>cifar_classes<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-148"><a href="#cb26-148" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"train: shape=</span><span class="sc">{</span>train_dataset<span class="sc">.</span>data<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> size=</span><span class="sc">{</span>train_MB<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb26-149"><a href="#cb26-149" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"test:  shape=</span><span class="sc">{</span>test_dataset<span class="sc">.</span>data<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> size=</span><span class="sc">{</span>test_MB<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb26-150"><a href="#cb26-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-151"><a href="#cb26-151" aria-hidden="true" tabindex="-1"></a><span class="co"># plot a selection</span></span>
<span id="cb26-152"><a href="#cb26-152" aria-hidden="true" tabindex="-1"></a>dataset2images(train_dataset, cifar_classes)</span>
<span id="cb26-153"><a href="#cb26-153" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-154"><a href="#cb26-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-155"><a href="#cb26-155" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb26-156"><a href="#cb26-156" aria-hidden="true" tabindex="-1"></a><span class="fu">### Note</span></span>
<span id="cb26-157"><a href="#cb26-157" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>CIFAR-10 is downloaded to disk (<span class="in">`./data/`</span>)</span>
<span id="cb26-158"><a href="#cb26-158" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>RAM footprint can be much larger ($\to$ DataLoader)</span>
<span id="cb26-159"><a href="#cb26-159" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>transformations: part of data definition; standardized and modularized</span>
<span id="cb26-160"><a href="#cb26-160" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-161"><a href="#cb26-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-162"><a href="#cb26-162" aria-hidden="true" tabindex="-1"></a><span class="fu">## Data Access</span></span>
<span id="cb26-163"><a href="#cb26-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-164"><a href="#cb26-164" aria-hidden="true" tabindex="-1"></a>There are several ways to access pytorch datasets</span>
<span id="cb26-165"><a href="#cb26-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-168"><a href="#cb26-168" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-169"><a href="#cb26-169" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: dataset_access</span></span>
<span id="cb26-170"><a href="#cb26-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-171"><a href="#cb26-171" aria-hidden="true" tabindex="-1"></a><span class="co"># access raw data: untransformed numpy .data and .targets are CIFAR-specific</span></span>
<span id="cb26-172"><a href="#cb26-172" aria-hidden="true" tabindex="-1"></a>nd <span class="op">=</span> train_dataset.data </span>
<span id="cb26-173"><a href="#cb26-173" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"train_dataset.data: </span><span class="sc">{</span>nd<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> -&gt; range: </span><span class="sc">{</span>nd<span class="sc">.</span><span class="bu">min</span>()<span class="sc">.</span>item()<span class="sc">}</span><span class="ss"> - </span><span class="sc">{</span>nd<span class="sc">.</span><span class="bu">max</span>()<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-174"><a href="#cb26-174" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"train_dataset.targets: </span><span class="sc">{</span>np<span class="sc">.</span>unique(train_dataset.targets)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-175"><a href="#cb26-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-176"><a href="#cb26-176" aria-hidden="true" tabindex="-1"></a><span class="co"># access transformed data: using generic methods (__getitem__ and __len__)</span></span>
<span id="cb26-177"><a href="#cb26-177" aria-hidden="true" tabindex="-1"></a>img, label <span class="op">=</span> train_dataset[<span class="dv">0</span>]   <span class="co"># returns tuple (torch.tensor, integer)</span></span>
<span id="cb26-178"><a href="#cb26-178" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"img: </span><span class="sc">{</span>img<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> range: </span><span class="sc">{</span>img<span class="sc">.</span><span class="bu">min</span>()<span class="sc">.</span>item()<span class="sc">}</span><span class="ss"> - </span><span class="sc">{</span>img<span class="sc">.</span><span class="bu">max</span>()<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-179"><a href="#cb26-179" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"label: </span><span class="sc">{</span>label<span class="sc">}</span><span class="ss"> -&gt; </span><span class="sc">{</span>cifar_classes[label]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-180"><a href="#cb26-180" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"len(train_dataset): </span><span class="sc">{</span><span class="bu">len</span>(train_dataset)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-181"><a href="#cb26-181" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-182"><a href="#cb26-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-183"><a href="#cb26-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-184"><a href="#cb26-184" aria-hidden="true" tabindex="-1"></a><span class="fu">## Explore</span></span>
<span id="cb26-185"><a href="#cb26-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-188"><a href="#cb26-188" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-189"><a href="#cb26-189" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: label_distribution</span></span>
<span id="cb26-190"><a href="#cb26-190" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb26-191"><a href="#cb26-191" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb26-192"><a href="#cb26-192" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb26-193"><a href="#cb26-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-194"><a href="#cb26-194" aria-hidden="true" tabindex="-1"></a>fract <span class="op">=</span> pd.Series(train_dataset.targets).value_counts(normalize<span class="op">=</span><span class="va">True</span>).sort_index()</span>
<span id="cb26-195"><a href="#cb26-195" aria-hidden="true" tabindex="-1"></a>sns.barplot(x<span class="op">=</span>fract.index, y<span class="op">=</span>fract.values)</span>
<span id="cb26-196"><a href="#cb26-196" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"CIFAR-10: Label Distribution"</span>)</span>
<span id="cb26-197"><a href="#cb26-197" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Image Class Label"</span>)</span>
<span id="cb26-198"><a href="#cb26-198" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-199"><a href="#cb26-199" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-200"><a href="#cb26-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-203"><a href="#cb26-203" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-204"><a href="#cb26-204" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: PCA</span></span>
<span id="cb26-205"><a href="#cb26-205" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb26-206"><a href="#cb26-206" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb26-207"><a href="#cb26-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-208"><a href="#cb26-208" aria-hidden="true" tabindex="-1"></a>n_sub <span class="op">=</span> <span class="dv">500</span> <span class="co"># define a subset of digits for speed</span></span>
<span id="cb26-209"><a href="#cb26-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-210"><a href="#cb26-210" aria-hidden="true" tabindex="-1"></a><span class="co"># flattening a tensor to get [samples x features]</span></span>
<span id="cb26-211"><a href="#cb26-211" aria-hidden="true" tabindex="-1"></a>X_sub <span class="op">=</span> train_dataset.data[:n_sub].reshape(n_sub, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb26-212"><a href="#cb26-212" aria-hidden="true" tabindex="-1"></a>y_sub <span class="op">=</span> train_dataset.targets[:n_sub]</span>
<span id="cb26-213"><a href="#cb26-213" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Images X (flattened): '</span>, X_sub.shape)</span>
<span id="cb26-214"><a href="#cb26-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-215"><a href="#cb26-215" aria-hidden="true" tabindex="-1"></a>X_pca <span class="op">=</span> PCA(n_components <span class="op">=</span> <span class="dv">2</span>).fit_transform(X_sub)</span>
<span id="cb26-216"><a href="#cb26-216" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'PCA Representation:   '</span>,X_pca.shape)</span>
<span id="cb26-217"><a href="#cb26-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-218"><a href="#cb26-218" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> plt.get_cmap(<span class="st">'tab10'</span>)</span>
<span id="cb26-219"><a href="#cb26-219" aria-hidden="true" tabindex="-1"></a>plt.scatter( X_pca[:,<span class="dv">0</span>], X_pca[:,<span class="dv">1</span>] , c<span class="op">=</span>y_sub, cmap<span class="op">=</span>cm)</span>
<span id="cb26-220"><a href="#cb26-220" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'CIFAR-10: PCA'</span>)</span>
<span id="cb26-221"><a href="#cb26-221" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb26-222"><a href="#cb26-222" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-223"><a href="#cb26-223" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-224"><a href="#cb26-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-225"><a href="#cb26-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-226"><a href="#cb26-226" aria-hidden="true" tabindex="-1"></a>::: callout-note</span>
<span id="cb26-227"><a href="#cb26-227" aria-hidden="true" tabindex="-1"></a><span class="fu">### Message</span></span>
<span id="cb26-228"><a href="#cb26-228" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>No apparent class structure (unlike MNIST)</span>
<span id="cb26-229"><a href="#cb26-229" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>simple feedforward network (MLP) will not be very accurate classifier</span>
<span id="cb26-230"><a href="#cb26-230" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>higher accuracy on flattened images will be difficult </span>
<span id="cb26-231"><a href="#cb26-231" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>change data representation and network architecture</span>
<span id="cb26-232"><a href="#cb26-232" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-233"><a href="#cb26-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-234"><a href="#cb26-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-235"><a href="#cb26-235" aria-hidden="true" tabindex="-1"></a><span class="fu">## Discussion: Challenges ?</span></span>
<span id="cb26-236"><a href="#cb26-236" aria-hidden="true" tabindex="-1"></a><span class="al">![Confused Cat](images/confused_cat.jpg)</span></span>
<span id="cb26-237"><a href="#cb26-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-238"><a href="#cb26-238" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--</span></span>
<span id="cb26-239"><a href="#cb26-239" aria-hidden="true" tabindex="-1"></a><span class="co">- spatially distributed features</span></span>
<span id="cb26-240"><a href="#cb26-240" aria-hidden="true" tabindex="-1"></a><span class="co">- view point</span></span>
<span id="cb26-241"><a href="#cb26-241" aria-hidden="true" tabindex="-1"></a><span class="co">- illumination</span></span>
<span id="cb26-242"><a href="#cb26-242" aria-hidden="true" tabindex="-1"></a><span class="co">- deformation</span></span>
<span id="cb26-243"><a href="#cb26-243" aria-hidden="true" tabindex="-1"></a><span class="co">- occlusion </span></span>
<span id="cb26-244"><a href="#cb26-244" aria-hidden="true" tabindex="-1"></a><span class="co">- intraclass variation</span></span>
<span id="cb26-245"><a href="#cb26-245" aria-hidden="true" tabindex="-1"></a><span class="co">---&gt;</span></span>
<span id="cb26-246"><a href="#cb26-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-247"><a href="#cb26-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-248"><a href="#cb26-248" aria-hidden="true" tabindex="-1"></a><span class="fu">## Why not add more layers ?</span></span>
<span id="cb26-249"><a href="#cb26-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-250"><a href="#cb26-250" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>optimization increasingly hard</span>
<span id="cb26-251"><a href="#cb26-251" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>does not scale to larger images</span>
<span id="cb26-252"><a href="#cb26-252" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>MLP do not encode spatial structure $\to$ input permutations possible</span>
<span id="cb26-253"><a href="#cb26-253" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>performance plateau</span>
<span id="cb26-254"><a href="#cb26-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-255"><a href="#cb26-255" aria-hidden="true" tabindex="-1"></a>::: {.callout-caution}</span>
<span id="cb26-256"><a href="#cb26-256" aria-hidden="true" tabindex="-1"></a><span class="fu">### FC Problem in Numbers</span></span>
<span id="cb26-257"><a href="#cb26-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-258"><a href="#cb26-258" aria-hidden="true" tabindex="-1"></a>1 input x 1 hidden layer: </span>
<span id="cb26-259"><a href="#cb26-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-260"><a href="#cb26-260" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">1000 x 1000 x 3 pixels</span><span class="co">]</span> x <span class="co">[</span><span class="ot">1000 neurons</span><span class="co">]</span> $\to$ 3 billion parameters</span>
<span id="cb26-261"><a href="#cb26-261" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-262"><a href="#cb26-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-263"><a href="#cb26-263" aria-hidden="true" tabindex="-1"></a><span class="fu">## The idea</span></span>
<span id="cb26-264"><a href="#cb26-264" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>restrict capacity of each layer $\to$ **weight sharing**</span>
<span id="cb26-265"><a href="#cb26-265" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>*invariance* assumption: should not matter where feature is</span>
<span id="cb26-266"><a href="#cb26-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-267"><a href="#cb26-267" aria-hidden="true" tabindex="-1"></a><span class="fu">## Convolutions</span></span>
<span id="cb26-268"><a href="#cb26-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-269"><a href="#cb26-269" aria-hidden="true" tabindex="-1"></a><span class="fu">### 1D Conv</span></span>
<span id="cb26-270"><a href="#cb26-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-271"><a href="#cb26-271" aria-hidden="true" tabindex="-1"></a>Convolutions combine two functions by **sliding** one (the kernel $g(x)$) over the other</span>
<span id="cb26-272"><a href="#cb26-272" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-273"><a href="#cb26-273" aria-hidden="true" tabindex="-1"></a>(f \ast g)(x) = \sum_{k=-\infty}^{\infty} f<span class="co">[</span><span class="ot">k</span><span class="co">]</span> \cdot g<span class="co">[</span><span class="ot">x-k</span><span class="co">]</span></span>
<span id="cb26-274"><a href="#cb26-274" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-275"><a href="#cb26-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-276"><a href="#cb26-276" aria-hidden="true" tabindex="-1"></a>This can be used conveniently for</span>
<span id="cb26-277"><a href="#cb26-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-278"><a href="#cb26-278" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>smoothing/averaging</span>
<span id="cb26-279"><a href="#cb26-279" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>change detection (derivatives) </span>
<span id="cb26-280"><a href="#cb26-280" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>pattern detection</span>
<span id="cb26-281"><a href="#cb26-281" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>sharpening</span>
<span id="cb26-282"><a href="#cb26-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-283"><a href="#cb26-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-286"><a href="#cb26-286" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-287"><a href="#cb26-287" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: 1D_conv</span></span>
<span id="cb26-288"><a href="#cb26-288" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Different kernels in 1D</span></span>
<span id="cb26-289"><a href="#cb26-289" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb26-290"><a href="#cb26-290" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb26-291"><a href="#cb26-291" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb26-292"><a href="#cb26-292" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.signal <span class="im">import</span> convolve</span>
<span id="cb26-293"><a href="#cb26-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-294"><a href="#cb26-294" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a signal with edges</span></span>
<span id="cb26-295"><a href="#cb26-295" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">400</span>)</span>
<span id="cb26-296"><a href="#cb26-296" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> np.sin(x) <span class="op">+</span> <span class="fl">0.1</span><span class="op">*</span>np.random.randn(<span class="bu">len</span>(x))  <span class="co"># noisy sinus</span></span>
<span id="cb26-297"><a href="#cb26-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-298"><a href="#cb26-298" aria-hidden="true" tabindex="-1"></a><span class="co"># Kernels</span></span>
<span id="cb26-299"><a href="#cb26-299" aria-hidden="true" tabindex="-1"></a>xk <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">51</span>)</span>
<span id="cb26-300"><a href="#cb26-300" aria-hidden="true" tabindex="-1"></a>sigma <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb26-301"><a href="#cb26-301" aria-hidden="true" tabindex="-1"></a>g1 <span class="op">=</span> np.exp(<span class="op">-</span>(xk<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>(<span class="dv">2</span><span class="op">*</span>sigma<span class="op">**</span><span class="dv">2</span>))<span class="op">;</span> </span>
<span id="cb26-302"><a href="#cb26-302" aria-hidden="true" tabindex="-1"></a>g1 <span class="op">=</span> g1 <span class="op">/</span> g1.<span class="bu">sum</span>()             <span class="co"># Gaussian for smoothing/averaging</span></span>
<span id="cb26-303"><a href="#cb26-303" aria-hidden="true" tabindex="-1"></a>g2 <span class="op">=</span> np.array([<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>])         <span class="co"># 1st derivative</span></span>
<span id="cb26-304"><a href="#cb26-304" aria-hidden="true" tabindex="-1"></a>g3 <span class="op">=</span> np.array([<span class="dv">1</span>, <span class="op">-</span><span class="dv">2</span>, <span class="dv">1</span>])      <span class="co"># 2nd derivative (Laplacian)</span></span>
<span id="cb26-305"><a href="#cb26-305" aria-hidden="true" tabindex="-1"></a>g4 <span class="op">=</span> np.array([<span class="op">-</span><span class="dv">1</span>, <span class="dv">2</span>, <span class="op">-</span><span class="dv">1</span>])     <span class="co"># High-pass filter (sharpening)</span></span>
<span id="cb26-306"><a href="#cb26-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-307"><a href="#cb26-307" aria-hidden="true" tabindex="-1"></a><span class="co"># Convolve</span></span>
<span id="cb26-308"><a href="#cb26-308" aria-hidden="true" tabindex="-1"></a>fs <span class="op">=</span> convolve(f, g1, mode<span class="op">=</span><span class="st">'same'</span>) <span class="co"># smoothed signal</span></span>
<span id="cb26-309"><a href="#cb26-309" aria-hidden="true" tabindex="-1"></a>f1 <span class="op">=</span> convolve(fs, g2, mode<span class="op">=</span><span class="st">'same'</span>) <span class="co"># 1st derivative</span></span>
<span id="cb26-310"><a href="#cb26-310" aria-hidden="true" tabindex="-1"></a>f1s <span class="op">=</span> convolve(f1, g1, mode<span class="op">=</span><span class="st">'same'</span>) <span class="co"># smoothed 1st derivativ</span></span>
<span id="cb26-311"><a href="#cb26-311" aria-hidden="true" tabindex="-1"></a>f2 <span class="op">=</span> convolve(f1s, g3, mode<span class="op">=</span><span class="st">'same'</span>) <span class="co"># 2nd derivative</span></span>
<span id="cb26-312"><a href="#cb26-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-313"><a href="#cb26-313" aria-hidden="true" tabindex="-1"></a><span class="co"># remove boundary effects</span></span>
<span id="cb26-314"><a href="#cb26-314" aria-hidden="true" tabindex="-1"></a>pad <span class="op">=</span> <span class="dv">81</span></span>
<span id="cb26-315"><a href="#cb26-315" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> x[pad:<span class="op">-</span>pad]</span>
<span id="cb26-316"><a href="#cb26-316" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> f[pad:<span class="op">-</span>pad]</span>
<span id="cb26-317"><a href="#cb26-317" aria-hidden="true" tabindex="-1"></a>fs <span class="op">=</span> fs[pad:<span class="op">-</span>pad]</span>
<span id="cb26-318"><a href="#cb26-318" aria-hidden="true" tabindex="-1"></a>f1 <span class="op">=</span> f1[pad:<span class="op">-</span>pad]</span>
<span id="cb26-319"><a href="#cb26-319" aria-hidden="true" tabindex="-1"></a>f2 <span class="op">=</span> f2[pad:<span class="op">-</span>pad]</span>
<span id="cb26-320"><a href="#cb26-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-321"><a href="#cb26-321" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot: </span></span>
<span id="cb26-322"><a href="#cb26-322" aria-hidden="true" tabindex="-1"></a><span class="co"># kernels are scaled arbitrarly for visibility</span></span>
<span id="cb26-323"><a href="#cb26-323" aria-hidden="true" tabindex="-1"></a>fsize <span class="op">=</span> <span class="dv">14</span></span>
<span id="cb26-324"><a href="#cb26-324" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb26-325"><a href="#cb26-325" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb26-326"><a href="#cb26-326" aria-hidden="true" tabindex="-1"></a>plt.plot(x, f)</span>
<span id="cb26-327"><a href="#cb26-327" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Original Data"</span>, fontsize<span class="op">=</span>fsize)</span>
<span id="cb26-328"><a href="#cb26-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-329"><a href="#cb26-329" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb26-330"><a href="#cb26-330" aria-hidden="true" tabindex="-1"></a>plt.plot(x, fs)</span>
<span id="cb26-331"><a href="#cb26-331" aria-hidden="true" tabindex="-1"></a>plt.bar(xk<span class="op">-</span><span class="dv">1</span>, g1<span class="op">*</span><span class="dv">20</span>, color<span class="op">=</span><span class="st">"orange"</span>, width<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb26-332"><a href="#cb26-332" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Smoothing/Averaging: fs = f * G  </span><span class="ch">\n</span><span class="st"> Gaussian Kernel $G </span><span class="ch">\\</span><span class="st">propto </span><span class="ch">\\</span><span class="st">exp{(-x^2)}$"</span>, fontsize<span class="op">=</span>fsize)</span>
<span id="cb26-333"><a href="#cb26-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-334"><a href="#cb26-334" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">3</span>)</span>
<span id="cb26-335"><a href="#cb26-335" aria-hidden="true" tabindex="-1"></a>plt.plot(x, f1)<span class="op">;</span> </span>
<span id="cb26-336"><a href="#cb26-336" aria-hidden="true" tabindex="-1"></a>plt.bar(x[[<span class="dv">99</span>,<span class="dv">100</span>]], g2<span class="op">/</span><span class="dv">20</span>, color<span class="op">=</span><span class="st">"orange"</span>,width<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb26-337"><a href="#cb26-337" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Change Detection: f1 = fs * D </span><span class="ch">\n</span><span class="st"> 1st derivative D = [-1, +1]"</span>, fontsize<span class="op">=</span>fsize)</span>
<span id="cb26-338"><a href="#cb26-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-339"><a href="#cb26-339" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">4</span>)</span>
<span id="cb26-340"><a href="#cb26-340" aria-hidden="true" tabindex="-1"></a>plt.plot(x, f2)<span class="op">;</span> </span>
<span id="cb26-341"><a href="#cb26-341" aria-hidden="true" tabindex="-1"></a>plt.bar(x[[<span class="dv">99</span>,<span class="dv">100</span>,<span class="dv">101</span>]], g3<span class="op">/</span><span class="dv">10000</span>, color<span class="op">=</span><span class="st">"orange"</span>,width<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb26-342"><a href="#cb26-342" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Curvature Detection: f2 = (f1 * G) * L </span><span class="ch">\n</span><span class="st"> 2nd derivative L = [1, -2, 1]"</span>, fontsize<span class="op">=</span>fsize)</span>
<span id="cb26-343"><a href="#cb26-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-344"><a href="#cb26-344" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb26-345"><a href="#cb26-345" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-346"><a href="#cb26-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-347"><a href="#cb26-347" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-348"><a href="#cb26-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-349"><a href="#cb26-349" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb26-350"><a href="#cb26-350" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>appropriate convolutions can extract features</span>
<span id="cb26-351"><a href="#cb26-351" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>many different kernels possible</span>
<span id="cb26-352"><a href="#cb26-352" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>find different (more suitable) data representations</span>
<span id="cb26-353"><a href="#cb26-353" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>kernel rules are shift-invariant and independent of data size</span>
<span id="cb26-354"><a href="#cb26-354" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>controlled by few parameters</span>
<span id="cb26-355"><a href="#cb26-355" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-356"><a href="#cb26-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-357"><a href="#cb26-357" aria-hidden="true" tabindex="-1"></a><span class="fu">### 2D Conv</span></span>
<span id="cb26-358"><a href="#cb26-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-359"><a href="#cb26-359" aria-hidden="true" tabindex="-1"></a><span class="al">![Convolution in 2D. Source: Anh H. Reynolds: https://anhreynolds.com/blogs/cnn.html](images/2D_Conv.png)</span></span>
<span id="cb26-360"><a href="#cb26-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-361"><a href="#cb26-361" aria-hidden="true" tabindex="-1"></a><span class="fu">## Convolutional Neural Networks (CNN)</span></span>
<span id="cb26-362"><a href="#cb26-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-363"><a href="#cb26-363" aria-hidden="true" tabindex="-1"></a><span class="al">![The big picture - and some jargon.](images/Vgg16_Elephant.png)</span></span>
<span id="cb26-364"><a href="#cb26-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-365"><a href="#cb26-365" aria-hidden="true" tabindex="-1"></a><span class="fu">## New layers: Filters and Pools</span></span>
<span id="cb26-366"><a href="#cb26-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-367"><a href="#cb26-367" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**input layer:** image <span class="co">[</span><span class="ot">3 channels (RGB), height, width</span><span class="co">]</span></span>
<span id="cb26-368"><a href="#cb26-368" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**convolutional layer** (Conv): K **filters** e.g <span class="co">[</span><span class="ot">K,3,3,3</span><span class="co">]</span></span>
<span id="cb26-369"><a href="#cb26-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-370"><a href="#cb26-370" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>detect pattern (e.g. horizontal, vertical, diagonal lines)</span>
<span id="cb26-371"><a href="#cb26-371" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>have the same depth as input</span>
<span id="cb26-372"><a href="#cb26-372" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>several filter per layer: different filters applied to same spatial location in image</span>
<span id="cb26-373"><a href="#cb26-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-374"><a href="#cb26-374" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**pooling filter** (Pool)</span>
<span id="cb26-375"><a href="#cb26-375" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>spatial downsampling, depth stays the same (e.g. max or average)</span>
<span id="cb26-376"><a href="#cb26-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-377"><a href="#cb26-377" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**fully conncted layer** (Dense)</span>
<span id="cb26-378"><a href="#cb26-378" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>connect all previous nodes</span>
<span id="cb26-379"><a href="#cb26-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-380"><a href="#cb26-380" aria-hidden="true" tabindex="-1"></a>Typical structures: Input - Conv/Relu - Conv/Relu - Pool - Conv/Relu - ... - Dense</span>
<span id="cb26-381"><a href="#cb26-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-382"><a href="#cb26-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-383"><a href="#cb26-383" aria-hidden="true" tabindex="-1"></a><span class="fu">## Convolutions</span></span>
<span id="cb26-384"><a href="#cb26-384" aria-hidden="true" tabindex="-1"></a><span class="al">![Convolution and Pooling](images/Convolution.png)</span></span>
<span id="cb26-385"><a href="#cb26-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-386"><a href="#cb26-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-387"><a href="#cb26-387" aria-hidden="true" tabindex="-1"></a><span class="fu">### Number of outputs from Convolutional Layer</span></span>
<span id="cb26-388"><a href="#cb26-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-389"><a href="#cb26-389" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$F$  filter size</span>
<span id="cb26-390"><a href="#cb26-390" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$S$  stride</span>
<span id="cb26-391"><a href="#cb26-391" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$P$  padding</span>
<span id="cb26-392"><a href="#cb26-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-393"><a href="#cb26-393" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-394"><a href="#cb26-394" aria-hidden="true" tabindex="-1"></a>N_{out} = \frac{N_{in} - F + 2P}{S} + 1</span>
<span id="cb26-395"><a href="#cb26-395" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb26-396"><a href="#cb26-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-397"><a href="#cb26-397" aria-hidden="true" tabindex="-1"></a>**Notice**</span>
<span id="cb26-398"><a href="#cb26-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-399"><a href="#cb26-399" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$(N_{in} - F + 2P)/S$ has to be integer for this to work properly.</span>
<span id="cb26-400"><a href="#cb26-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-401"><a href="#cb26-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-402"><a href="#cb26-402" aria-hidden="true" tabindex="-1"></a><span class="fu">### Habits and Recommendations</span></span>
<span id="cb26-403"><a href="#cb26-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-404"><a href="#cb26-404" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>use input size $L \times L = 2^n$ (e.g. 512)</span>
<span id="cb26-405"><a href="#cb26-405" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>use stride $S=1$</span>
<span id="cb26-406"><a href="#cb26-406" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>use padding $P= (F-1)/2$ to retain input size --&gt; multiple CONV layers</span>
<span id="cb26-407"><a href="#cb26-407" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>pooling: $F=2 S=2$ (size reduction: $L \times L --&gt; L/2 \times L/2$ !!! - aggressive reduction</span>
<span id="cb26-408"><a href="#cb26-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-409"><a href="#cb26-409" aria-hidden="true" tabindex="-1"></a><span class="fu">## Data Preparation</span></span>
<span id="cb26-410"><a href="#cb26-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-411"><a href="#cb26-411" aria-hidden="true" tabindex="-1"></a>The data preparation invokes the usual steps: </span>
<span id="cb26-412"><a href="#cb26-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-413"><a href="#cb26-413" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>splitting data sets into train, validation, test</span>
<span id="cb26-414"><a href="#cb26-414" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>optionally: downsample for speed</span>
<span id="cb26-415"><a href="#cb26-415" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>definition of batches</span>
<span id="cb26-416"><a href="#cb26-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-417"><a href="#cb26-417" aria-hidden="true" tabindex="-1"></a><span class="fu">### Split and Downsample</span></span>
<span id="cb26-418"><a href="#cb26-418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-421"><a href="#cb26-421" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-422"><a href="#cb26-422" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: split_and_downsample</span></span>
<span id="cb26-423"><a href="#cb26-423" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb26-424"><a href="#cb26-424" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb26-425"><a href="#cb26-425" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Subset</span>
<span id="cb26-426"><a href="#cb26-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-427"><a href="#cb26-427" aria-hidden="true" tabindex="-1"></a>SEED <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb26-428"><a href="#cb26-428" aria-hidden="true" tabindex="-1"></a>FRACT <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb26-429"><a href="#cb26-429" aria-hidden="true" tabindex="-1"></a>TRAIN_VAL<span class="op">=</span><span class="fl">0.8</span></span>
<span id="cb26-430"><a href="#cb26-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-431"><a href="#cb26-431" aria-hidden="true" tabindex="-1"></a><span class="co"># get current sizes</span></span>
<span id="cb26-432"><a href="#cb26-432" aria-hidden="true" tabindex="-1"></a>train_indices <span class="op">=</span> np.arange(<span class="bu">len</span>(train_dataset)) </span>
<span id="cb26-433"><a href="#cb26-433" aria-hidden="true" tabindex="-1"></a>train_labels  <span class="op">=</span> np.array(train_dataset.targets)</span>
<span id="cb26-434"><a href="#cb26-434" aria-hidden="true" tabindex="-1"></a>test_indices  <span class="op">=</span> np.arange(<span class="bu">len</span>(test_dataset))  </span>
<span id="cb26-435"><a href="#cb26-435" aria-hidden="true" tabindex="-1"></a>test_labels   <span class="op">=</span> np.array(test_dataset.targets)</span>
<span id="cb26-436"><a href="#cb26-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-437"><a href="#cb26-437" aria-hidden="true" tabindex="-1"></a><span class="co"># subsample FRACT </span></span>
<span id="cb26-438"><a href="#cb26-438" aria-hidden="true" tabindex="-1"></a>train_pool_idx, _ <span class="op">=</span> train_test_split(</span>
<span id="cb26-439"><a href="#cb26-439" aria-hidden="true" tabindex="-1"></a>    train_indices, train_size<span class="op">=</span>FRACT, stratify<span class="op">=</span>train_labels, random_state<span class="op">=</span>SEED</span>
<span id="cb26-440"><a href="#cb26-440" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb26-441"><a href="#cb26-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-442"><a href="#cb26-442" aria-hidden="true" tabindex="-1"></a>test_idx, _ <span class="op">=</span> train_test_split(</span>
<span id="cb26-443"><a href="#cb26-443" aria-hidden="true" tabindex="-1"></a>    test_indices, train_size<span class="op">=</span>FRACT, stratify<span class="op">=</span>test_labels, random_state<span class="op">=</span>SEED</span>
<span id="cb26-444"><a href="#cb26-444" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb26-445"><a href="#cb26-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-446"><a href="#cb26-446" aria-hidden="true" tabindex="-1"></a><span class="co"># split train -&gt; train + val</span></span>
<span id="cb26-447"><a href="#cb26-447" aria-hidden="true" tabindex="-1"></a>y_pool <span class="op">=</span> train_labels[train_pool_idx]</span>
<span id="cb26-448"><a href="#cb26-448" aria-hidden="true" tabindex="-1"></a>train_idx, val_idx <span class="op">=</span> train_test_split(</span>
<span id="cb26-449"><a href="#cb26-449" aria-hidden="true" tabindex="-1"></a>    train_pool_idx, train_size<span class="op">=</span>TRAIN_VAL, stratify<span class="op">=</span>y_pool, random_state<span class="op">=</span>SEED</span>
<span id="cb26-450"><a href="#cb26-450" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb26-451"><a href="#cb26-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-452"><a href="#cb26-452" aria-hidden="true" tabindex="-1"></a>train_ds <span class="op">=</span> Subset(train_dataset, train_idx)</span>
<span id="cb26-453"><a href="#cb26-453" aria-hidden="true" tabindex="-1"></a>val_ds   <span class="op">=</span> Subset(train_dataset, val_idx)</span>
<span id="cb26-454"><a href="#cb26-454" aria-hidden="true" tabindex="-1"></a>test_ds  <span class="op">=</span> Subset(test_dataset,  test_idx)</span>
<span id="cb26-455"><a href="#cb26-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-456"><a href="#cb26-456" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"train: </span><span class="sc">{</span>train_idx<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, val: </span><span class="sc">{</span>val_idx<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, test: </span><span class="sc">{</span>test_idx<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-457"><a href="#cb26-457" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-458"><a href="#cb26-458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-459"><a href="#cb26-459" aria-hidden="true" tabindex="-1"></a><span class="fu">### Data Loaders for Batches</span></span>
<span id="cb26-460"><a href="#cb26-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-461"><a href="#cb26-461" aria-hidden="true" tabindex="-1"></a>DataLoaders provide efficient access to batches during training and evaluation</span>
<span id="cb26-464"><a href="#cb26-464" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-465"><a href="#cb26-465" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: data_loaders</span></span>
<span id="cb26-466"><a href="#cb26-466" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb26-467"><a href="#cb26-467" aria-hidden="true" tabindex="-1"></a><span class="co"># shuffle = True for randomized optimization and gradients calculation</span></span>
<span id="cb26-468"><a href="#cb26-468" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(train_ds, batch_size<span class="op">=</span>BATCH_SIZE, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb26-469"><a href="#cb26-469" aria-hidden="true" tabindex="-1"></a><span class="co"># shuffle = False for fixed and consistent evaluation and metrics</span></span>
<span id="cb26-470"><a href="#cb26-470" aria-hidden="true" tabindex="-1"></a>test_loader  <span class="op">=</span> DataLoader(test_ds, batch_size<span class="op">=</span>BATCH_SIZE, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb26-471"><a href="#cb26-471" aria-hidden="true" tabindex="-1"></a>val_loader   <span class="op">=</span> DataLoader(val_ds, batch_size<span class="op">=</span>BATCH_SIZE, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb26-472"><a href="#cb26-472" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-473"><a href="#cb26-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-474"><a href="#cb26-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-475"><a href="#cb26-475" aria-hidden="true" tabindex="-1"></a><span class="fu">## CNN: PyTorch implementation</span></span>
<span id="cb26-476"><a href="#cb26-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-479"><a href="#cb26-479" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-480"><a href="#cb26-480" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: CNN_Model</span></span>
<span id="cb26-481"><a href="#cb26-481" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb26-482"><a href="#cb26-482" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb26-483"><a href="#cb26-483" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb26-484"><a href="#cb26-484" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchinfo <span class="im">import</span> summary</span>
<span id="cb26-485"><a href="#cb26-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-486"><a href="#cb26-486" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of classes</span></span>
<span id="cb26-487"><a href="#cb26-487" aria-hidden="true" tabindex="-1"></a>nc <span class="op">=</span> <span class="bu">len</span>(cifar_classes)</span>
<span id="cb26-488"><a href="#cb26-488" aria-hidden="true" tabindex="-1"></a>X_train, y_train <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(train_loader))</span>
<span id="cb26-489"><a href="#cb26-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-490"><a href="#cb26-490" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'input_shape:      '</span>, X_train.shape)</span>
<span id="cb26-491"><a href="#cb26-491" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'number of classes:'</span>, nc)</span>
<span id="cb26-492"><a href="#cb26-492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-493"><a href="#cb26-493" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CNN_Model(nn.Module):</span>
<span id="cb26-494"><a href="#cb26-494" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_classes<span class="op">=</span>nc):</span>
<span id="cb26-495"><a href="#cb26-495" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb26-496"><a href="#cb26-496" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> nn.Conv2d(<span class="dv">3</span>, <span class="dv">32</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb26-497"><a href="#cb26-497" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pool1 <span class="op">=</span> nn.MaxPool2d(<span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb26-498"><a href="#cb26-498" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.flatten <span class="op">=</span> nn.Flatten()</span>
<span id="cb26-499"><a href="#cb26-499" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(<span class="dv">32</span> <span class="op">*</span> <span class="dv">16</span> <span class="op">*</span> <span class="dv">16</span>, <span class="dv">128</span>)</span>
<span id="cb26-500"><a href="#cb26-500" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc2 <span class="op">=</span> nn.Linear(<span class="dv">128</span>, num_classes)</span>
<span id="cb26-501"><a href="#cb26-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-502"><a href="#cb26-502" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb26-503"><a href="#cb26-503" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.relu(<span class="va">self</span>.conv1(x))</span>
<span id="cb26-504"><a href="#cb26-504" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.pool1(x)</span>
<span id="cb26-505"><a href="#cb26-505" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.flatten(x)</span>
<span id="cb26-506"><a href="#cb26-506" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.relu(<span class="va">self</span>.fc1(x))</span>
<span id="cb26-507"><a href="#cb26-507" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.fc2(x)</span>
<span id="cb26-508"><a href="#cb26-508" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb26-509"><a href="#cb26-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-510"><a href="#cb26-510" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> CNN_Model().to(device)</span>
<span id="cb26-511"><a href="#cb26-511" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(summary(model, input_data<span class="op">=</span>X_train, device<span class="op">=</span>device))</span>
<span id="cb26-512"><a href="#cb26-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-513"><a href="#cb26-513" aria-hidden="true" tabindex="-1"></a>loss_function <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb26-514"><a href="#cb26-514" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.Adam(model.parameters())</span>
<span id="cb26-515"><a href="#cb26-515" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-516"><a href="#cb26-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-517"><a href="#cb26-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-518"><a href="#cb26-518" aria-hidden="true" tabindex="-1"></a>**Notice**</span>
<span id="cb26-519"><a href="#cb26-519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-520"><a href="#cb26-520" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>memory and compute in early layers, parameters in last layer</span>
<span id="cb26-521"><a href="#cb26-521" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>numbers can more than double when the gradients are calculated + caching </span>
<span id="cb26-522"><a href="#cb26-522" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>maintain also multiple images (batch normalization)</span>
<span id="cb26-523"><a href="#cb26-523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-524"><a href="#cb26-524" aria-hidden="true" tabindex="-1"></a><span class="fu">## CNN: fitting, GPUs and batch size</span></span>
<span id="cb26-525"><a href="#cb26-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-526"><a href="#cb26-526" aria-hidden="true" tabindex="-1"></a>The following cell will fit the model. This will take some time - especially without dedicated hardware (e.g. GPU) or further optimization (improved algorithm).</span>
<span id="cb26-527"><a href="#cb26-527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-530"><a href="#cb26-530" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-531"><a href="#cb26-531" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: train_model</span></span>
<span id="cb26-532"><a href="#cb26-532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-533"><a href="#cb26-533" aria-hidden="true" tabindex="-1"></a>num_epochs <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb26-534"><a href="#cb26-534" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> {<span class="st">'loss'</span>: [], <span class="st">'val_loss'</span>: []}</span>
<span id="cb26-535"><a href="#cb26-535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-536"><a href="#cb26-536" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb26-537"><a href="#cb26-537" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb26-538"><a href="#cb26-538" aria-hidden="true" tabindex="-1"></a>    total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb26-539"><a href="#cb26-539" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> xb, yb <span class="kw">in</span> train_loader:</span>
<span id="cb26-540"><a href="#cb26-540" aria-hidden="true" tabindex="-1"></a>        xb, yb <span class="op">=</span> xb.to(device), yb.to(device)</span>
<span id="cb26-541"><a href="#cb26-541" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb26-542"><a href="#cb26-542" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> model(xb)</span>
<span id="cb26-543"><a href="#cb26-543" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_function(logits, yb)</span>
<span id="cb26-544"><a href="#cb26-544" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb26-545"><a href="#cb26-545" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb26-546"><a href="#cb26-546" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">+=</span> loss.item()</span>
<span id="cb26-547"><a href="#cb26-547" aria-hidden="true" tabindex="-1"></a>    train_loss <span class="op">=</span> total_loss <span class="op">/</span> <span class="bu">len</span>(train_loader.dataset)</span>
<span id="cb26-548"><a href="#cb26-548" aria-hidden="true" tabindex="-1"></a>    history[<span class="st">'loss'</span>].append(train_loss)</span>
<span id="cb26-549"><a href="#cb26-549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-550"><a href="#cb26-550" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Validation</span></span>
<span id="cb26-551"><a href="#cb26-551" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb26-552"><a href="#cb26-552" aria-hidden="true" tabindex="-1"></a>    val_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb26-553"><a href="#cb26-553" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb26-554"><a href="#cb26-554" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> xb, yb <span class="kw">in</span> val_loader:</span>
<span id="cb26-555"><a href="#cb26-555" aria-hidden="true" tabindex="-1"></a>            xb, yb <span class="op">=</span> xb.to(device), yb.to(device)</span>
<span id="cb26-556"><a href="#cb26-556" aria-hidden="true" tabindex="-1"></a>            logits <span class="op">=</span> model(xb)</span>
<span id="cb26-557"><a href="#cb26-557" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_function(logits, yb)</span>
<span id="cb26-558"><a href="#cb26-558" aria-hidden="true" tabindex="-1"></a>            val_loss <span class="op">+=</span> loss.item()</span>
<span id="cb26-559"><a href="#cb26-559" aria-hidden="true" tabindex="-1"></a>    val_loss <span class="op">=</span> val_loss <span class="op">/</span> <span class="bu">len</span>(val_loader.dataset)</span>
<span id="cb26-560"><a href="#cb26-560" aria-hidden="true" tabindex="-1"></a>    history[<span class="st">'val_loss'</span>].append(val_loss)</span>
<span id="cb26-561"><a href="#cb26-561" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">: train_loss=</span><span class="sc">{</span>train_loss<span class="sc">:.4f}</span><span class="ss">, val_loss=</span><span class="sc">{</span>val_loss<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb26-562"><a href="#cb26-562" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-563"><a href="#cb26-563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-564"><a href="#cb26-564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-565"><a href="#cb26-565" aria-hidden="true" tabindex="-1"></a><span class="fu">### Save Model</span></span>
<span id="cb26-566"><a href="#cb26-566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-567"><a href="#cb26-567" aria-hidden="true" tabindex="-1"></a>Since training is expensive we usually want to safe</span>
<span id="cb26-568"><a href="#cb26-568" aria-hidden="true" tabindex="-1"></a>the model and history. </span>
<span id="cb26-569"><a href="#cb26-569" aria-hidden="true" tabindex="-1"></a>In real application this would also be done during training.</span>
<span id="cb26-572"><a href="#cb26-572" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-573"><a href="#cb26-573" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: save_model</span></span>
<span id="cb26-574"><a href="#cb26-574" aria-hidden="true" tabindex="-1"></a>outdir <span class="op">=</span> <span class="st">"output"</span></span>
<span id="cb26-575"><a href="#cb26-575" aria-hidden="true" tabindex="-1"></a>os.makedirs(outdir, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb26-576"><a href="#cb26-576" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-577"><a href="#cb26-577" aria-hidden="true" tabindex="-1"></a>torch.save(model.state_dict(), <span class="ss">f'</span><span class="sc">{</span>outdir<span class="sc">}</span><span class="ss">/cifar_model.pt'</span>)</span>
<span id="cb26-578"><a href="#cb26-578" aria-hidden="true" tabindex="-1"></a>torch.save(history, <span class="ss">f"</span><span class="sc">{</span>outdir<span class="sc">}</span><span class="ss">/cifar_history.pt"</span>)</span>
<span id="cb26-579"><a href="#cb26-579" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-580"><a href="#cb26-580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-581"><a href="#cb26-581" aria-hidden="true" tabindex="-1"></a>::: {.callout}</span>
<span id="cb26-582"><a href="#cb26-582" aria-hidden="true" tabindex="-1"></a><span class="fu">### CIFAR-Demo</span></span>
<span id="cb26-583"><a href="#cb26-583" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">CNN with Javascript. Animation from Karpathy.</span><span class="co">](https://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html)</span>{target="_blank" rel="noopener"}</span>
<span id="cb26-584"><a href="#cb26-584" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-585"><a href="#cb26-585" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-586"><a href="#cb26-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-587"><a href="#cb26-587" aria-hidden="true" tabindex="-1"></a><span class="fu">## Evaluations on Test</span></span>
<span id="cb26-588"><a href="#cb26-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-591"><a href="#cb26-591" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-592"><a href="#cb26-592" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: test_evaluation</span></span>
<span id="cb26-593"><a href="#cb26-593" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb26-594"><a href="#cb26-594" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate on test</span></span>
<span id="cb26-595"><a href="#cb26-595" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb26-596"><a href="#cb26-596" aria-hidden="true" tabindex="-1"></a>total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb26-597"><a href="#cb26-597" aria-hidden="true" tabindex="-1"></a>all_logits <span class="op">=</span> []</span>
<span id="cb26-598"><a href="#cb26-598" aria-hidden="true" tabindex="-1"></a>all_true <span class="op">=</span> []</span>
<span id="cb26-599"><a href="#cb26-599" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb26-600"><a href="#cb26-600" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> xb, yb <span class="kw">in</span> test_loader:</span>
<span id="cb26-601"><a href="#cb26-601" aria-hidden="true" tabindex="-1"></a>        xb, yb <span class="op">=</span> xb.to(device), yb.to(device)</span>
<span id="cb26-602"><a href="#cb26-602" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> model(xb)</span>
<span id="cb26-603"><a href="#cb26-603" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_function(logits, yb)</span>
<span id="cb26-604"><a href="#cb26-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-605"><a href="#cb26-605" aria-hidden="true" tabindex="-1"></a>        <span class="co"># collect total_loss, predicted logits and true labels yb</span></span>
<span id="cb26-606"><a href="#cb26-606" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">+=</span> loss.item()</span>
<span id="cb26-607"><a href="#cb26-607" aria-hidden="true" tabindex="-1"></a>        all_logits.append(logits.cpu())</span>
<span id="cb26-608"><a href="#cb26-608" aria-hidden="true" tabindex="-1"></a>        all_true.append(yb.cpu())</span>
<span id="cb26-609"><a href="#cb26-609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-610"><a href="#cb26-610" aria-hidden="true" tabindex="-1"></a>test_loss <span class="op">=</span> total_loss <span class="op">/</span> <span class="bu">len</span>(test_loader.dataset) <span class="co"># mean test loss</span></span>
<span id="cb26-611"><a href="#cb26-611" aria-hidden="true" tabindex="-1"></a>all_logits <span class="op">=</span> torch.cat(all_logits)</span>
<span id="cb26-612"><a href="#cb26-612" aria-hidden="true" tabindex="-1"></a>all_true <span class="op">=</span> torch.cat(all_true)</span>
<span id="cb26-613"><a href="#cb26-613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-614"><a href="#cb26-614" aria-hidden="true" tabindex="-1"></a>plot_fit_history(history, <span class="st">'loss'</span>, test_loss)</span>
<span id="cb26-615"><a href="#cb26-615" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-616"><a href="#cb26-616" aria-hidden="true" tabindex="-1"></a>all_preds <span class="op">=</span> all_logits.argmax(dim<span class="op">=</span><span class="dv">1</span>).detach().cpu()</span>
<span id="cb26-617"><a href="#cb26-617" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(all_true.numpy(), all_preds.numpy())</span>
<span id="cb26-618"><a href="#cb26-618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-619"><a href="#cb26-619" aria-hidden="true" tabindex="-1"></a>disp <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix<span class="op">=</span>cm)</span>
<span id="cb26-620"><a href="#cb26-620" aria-hidden="true" tabindex="-1"></a>disp.plot(cmap<span class="op">=</span><span class="st">'Blues'</span>)</span>
<span id="cb26-621"><a href="#cb26-621" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-622"><a href="#cb26-622" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-623"><a href="#cb26-623" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-624"><a href="#cb26-624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-625"><a href="#cb26-625" aria-hidden="true" tabindex="-1"></a>**Discussion:** What could be further improvements?</span>
<span id="cb26-626"><a href="#cb26-626" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-627"><a href="#cb26-627" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-628"><a href="#cb26-628" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-629"><a href="#cb26-629" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-630"><a href="#cb26-630" aria-hidden="true" tabindex="-1"></a><span class="fu">## A closer look at layers</span></span>
<span id="cb26-631"><a href="#cb26-631" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-632"><a href="#cb26-632" aria-hidden="true" tabindex="-1"></a>Motivation: Understand prediction in terms of layered "concepts"</span>
<span id="cb26-633"><a href="#cb26-633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-636"><a href="#cb26-636" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-637"><a href="#cb26-637" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: model_summary</span></span>
<span id="cb26-638"><a href="#cb26-638" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(summary(model, input_data<span class="op">=</span>X_train, device<span class="op">=</span>device))</span>
<span id="cb26-639"><a href="#cb26-639" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-640"><a href="#cb26-640" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-641"><a href="#cb26-641" aria-hidden="true" tabindex="-1"></a><span class="fu">### Filters</span></span>
<span id="cb26-642"><a href="#cb26-642" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-645"><a href="#cb26-645" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-646"><a href="#cb26-646" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: filters</span></span>
<span id="cb26-647"><a href="#cb26-647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-648"><a href="#cb26-648" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the weights of the first conv layer (shape: [out_channels, in_channels, H, W])</span></span>
<span id="cb26-649"><a href="#cb26-649" aria-hidden="true" tabindex="-1"></a>W <span class="op">=</span> model.conv1.weight.data.cpu().numpy()  <span class="co"># shape: (32, 3, 3, 3)</span></span>
<span id="cb26-650"><a href="#cb26-650" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'W.shape: '</span>,W.shape)</span>
<span id="cb26-651"><a href="#cb26-651" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">8</span>))</span>
<span id="cb26-652"><a href="#cb26-652" aria-hidden="true" tabindex="-1"></a>nr, nc <span class="op">=</span> (<span class="dv">5</span>, <span class="dv">5</span>)  <span class="co"># number of rows and columns</span></span>
<span id="cb26-653"><a href="#cb26-653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-654"><a href="#cb26-654" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(nr <span class="op">*</span> nc):</span>
<span id="cb26-655"><a href="#cb26-655" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Each filter: shape [3, 3, 3] (in_channels, H, W)</span></span>
<span id="cb26-656"><a href="#cb26-656" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Transpose to (H, W, C) for imshow</span></span>
<span id="cb26-657"><a href="#cb26-657" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> W[i].transpose(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>)</span>
<span id="cb26-658"><a href="#cb26-658" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Normalize to [0, 1] for visualization</span></span>
<span id="cb26-659"><a href="#cb26-659" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> (img <span class="op">-</span> img.<span class="bu">min</span>()) <span class="op">/</span> (img.<span class="bu">max</span>() <span class="op">-</span> img.<span class="bu">min</span>() <span class="op">+</span> <span class="fl">1e-5</span>)</span>
<span id="cb26-660"><a href="#cb26-660" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> fig.add_subplot(nr, nc, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb26-661"><a href="#cb26-661" aria-hidden="true" tabindex="-1"></a>    ax.imshow(img)</span>
<span id="cb26-662"><a href="#cb26-662" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f'filter: </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb26-663"><a href="#cb26-663" aria-hidden="true" tabindex="-1"></a>    ax.axis(<span class="st">'off'</span>)</span>
<span id="cb26-664"><a href="#cb26-664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-665"><a href="#cb26-665" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-666"><a href="#cb26-666" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-667"><a href="#cb26-667" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-668"><a href="#cb26-668" aria-hidden="true" tabindex="-1"></a>**Notice:** Maximal activation for all RGB channels=1 (black) and minimal activation for all RGB channels = 0 (white)</span>
<span id="cb26-669"><a href="#cb26-669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-670"><a href="#cb26-670" aria-hidden="true" tabindex="-1"></a><span class="fu">## The last layer</span></span>
<span id="cb26-671"><a href="#cb26-671" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-672"><a href="#cb26-672" aria-hidden="true" tabindex="-1"></a>The goal of the added convolutional layers is to obtain a better representation of the image data by representing spatial features (edges etc.). If this is successful then we would expect better separation properties in the penultimate layer (last before output layer).</span>
<span id="cb26-673"><a href="#cb26-673" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-674"><a href="#cb26-674" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-677"><a href="#cb26-677" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-678"><a href="#cb26-678" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: last_layer_PCA</span></span>
<span id="cb26-679"><a href="#cb26-679" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb26-680"><a href="#cb26-680" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb26-681"><a href="#cb26-681" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> TSNE</span>
<span id="cb26-682"><a href="#cb26-682" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-683"><a href="#cb26-683" aria-hidden="true" tabindex="-1"></a><span class="co"># Get representations from the penultimate (last hidden) layer in PyTorch</span></span>
<span id="cb26-684"><a href="#cb26-684" aria-hidden="true" tabindex="-1"></a><span class="co"># We'll use torch.no_grad() and a hook or simply modify the model to return features</span></span>
<span id="cb26-685"><a href="#cb26-685" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-686"><a href="#cb26-686" aria-hidden="true" tabindex="-1"></a><span class="co"># Example assumes model: features = model.fc1 output after relu, before final fc2</span></span>
<span id="cb26-687"><a href="#cb26-687" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-688"><a href="#cb26-688" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_last_layer_features(model, dataloader, device, n_samples<span class="op">=</span><span class="dv">500</span>):</span>
<span id="cb26-689"><a href="#cb26-689" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb26-690"><a href="#cb26-690" aria-hidden="true" tabindex="-1"></a>    features <span class="op">=</span> []</span>
<span id="cb26-691"><a href="#cb26-691" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> []</span>
<span id="cb26-692"><a href="#cb26-692" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb26-693"><a href="#cb26-693" aria-hidden="true" tabindex="-1"></a>        count <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb26-694"><a href="#cb26-694" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> xb, yb <span class="kw">in</span> dataloader:</span>
<span id="cb26-695"><a href="#cb26-695" aria-hidden="true" tabindex="-1"></a>            xb, yb <span class="op">=</span> xb.to(device), yb.to(device)</span>
<span id="cb26-696"><a href="#cb26-696" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> F.relu(model.conv1(xb))</span>
<span id="cb26-697"><a href="#cb26-697" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> model.pool1(x)</span>
<span id="cb26-698"><a href="#cb26-698" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> model.flatten(x)</span>
<span id="cb26-699"><a href="#cb26-699" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> F.relu(model.fc1(x))</span>
<span id="cb26-700"><a href="#cb26-700" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Forward up to penultimate layer</span></span>
<span id="cb26-701"><a href="#cb26-701" aria-hidden="true" tabindex="-1"></a>            features.append(x.cpu())</span>
<span id="cb26-702"><a href="#cb26-702" aria-hidden="true" tabindex="-1"></a>            labels.append(yb.cpu())</span>
<span id="cb26-703"><a href="#cb26-703" aria-hidden="true" tabindex="-1"></a>            count <span class="op">+=</span> xb.size(<span class="dv">0</span>)</span>
<span id="cb26-704"><a href="#cb26-704" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> count <span class="op">&gt;=</span> n_samples:</span>
<span id="cb26-705"><a href="#cb26-705" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span></span>
<span id="cb26-706"><a href="#cb26-706" aria-hidden="true" tabindex="-1"></a>    features <span class="op">=</span> torch.cat(features)[:n_samples]</span>
<span id="cb26-707"><a href="#cb26-707" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> torch.cat(labels)[:n_samples]</span>
<span id="cb26-708"><a href="#cb26-708" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> features.numpy(), labels.numpy()</span>
<span id="cb26-709"><a href="#cb26-709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-710"><a href="#cb26-710" aria-hidden="true" tabindex="-1"></a><span class="co"># Get features for train set (or a subset)</span></span>
<span id="cb26-711"><a href="#cb26-711" aria-hidden="true" tabindex="-1"></a>X_lay, y <span class="op">=</span> get_last_layer_features(model, train_loader, device, n_samples<span class="op">=</span><span class="dv">500</span>)</span>
<span id="cb26-712"><a href="#cb26-712" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-713"><a href="#cb26-713" aria-hidden="true" tabindex="-1"></a><span class="co"># Also get original input (flattened)</span></span>
<span id="cb26-714"><a href="#cb26-714" aria-hidden="true" tabindex="-1"></a>X_orig <span class="op">=</span> []</span>
<span id="cb26-715"><a href="#cb26-715" aria-hidden="true" tabindex="-1"></a>count <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb26-716"><a href="#cb26-716" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> xb, yb <span class="kw">in</span> train_loader:</span>
<span id="cb26-717"><a href="#cb26-717" aria-hidden="true" tabindex="-1"></a>    X_orig.append(xb.cpu().reshape(xb.size(<span class="dv">0</span>), <span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb26-718"><a href="#cb26-718" aria-hidden="true" tabindex="-1"></a>    count <span class="op">+=</span> xb.size(<span class="dv">0</span>)</span>
<span id="cb26-719"><a href="#cb26-719" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> count <span class="op">&gt;=</span> <span class="dv">500</span>:</span>
<span id="cb26-720"><a href="#cb26-720" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb26-721"><a href="#cb26-721" aria-hidden="true" tabindex="-1"></a>X_orig <span class="op">=</span> torch.cat(X_orig)[:<span class="dv">500</span>].numpy()</span>
<span id="cb26-722"><a href="#cb26-722" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-723"><a href="#cb26-723" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'X shapes: '</span>, X_orig.shape, X_lay.shape)</span>
<span id="cb26-724"><a href="#cb26-724" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-725"><a href="#cb26-725" aria-hidden="true" tabindex="-1"></a><span class="co"># PCA or t-SNE</span></span>
<span id="cb26-726"><a href="#cb26-726" aria-hidden="true" tabindex="-1"></a>X_pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>).fit_transform(X_orig)</span>
<span id="cb26-727"><a href="#cb26-727" aria-hidden="true" tabindex="-1"></a>X_lay_pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>).fit_transform(X_lay)</span>
<span id="cb26-728"><a href="#cb26-728" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'PCA Shapes: '</span>, X_pca.shape, X_lay_pca.shape)</span>
<span id="cb26-729"><a href="#cb26-729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-730"><a href="#cb26-730" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">4</span>))</span>
<span id="cb26-731"><a href="#cb26-731" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> plt.get_cmap(<span class="st">'tab10'</span>)</span>
<span id="cb26-732"><a href="#cb26-732" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-733"><a href="#cb26-733" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb26-734"><a href="#cb26-734" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_pca[:, <span class="dv">0</span>], X_pca[:, <span class="dv">1</span>], c<span class="op">=</span>y, cmap<span class="op">=</span>cm)</span>
<span id="cb26-735"><a href="#cb26-735" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'PCA: X orig.'</span>)</span>
<span id="cb26-736"><a href="#cb26-736" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-737"><a href="#cb26-737" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb26-738"><a href="#cb26-738" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_lay_pca[:, <span class="dv">0</span>], X_lay_pca[:, <span class="dv">1</span>], c<span class="op">=</span>y, cmap<span class="op">=</span>cm)</span>
<span id="cb26-739"><a href="#cb26-739" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'PCA - X transformed'</span>)</span>
<span id="cb26-740"><a href="#cb26-740" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-741"><a href="#cb26-741" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb26-742"><a href="#cb26-742" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-743"><a href="#cb26-743" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-744"><a href="#cb26-744" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-745"><a href="#cb26-745" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-746"><a href="#cb26-746" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-747"><a href="#cb26-747" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-748"><a href="#cb26-748" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-749"><a href="#cb26-749" aria-hidden="true" tabindex="-1"></a>::: {.callout-important}</span>
<span id="cb26-750"><a href="#cb26-750" aria-hidden="true" tabindex="-1"></a><span class="fu">## Summary</span></span>
<span id="cb26-751"><a href="#cb26-751" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>MLP: pass 1D vectors from layer to layer</span>
<span id="cb26-752"><a href="#cb26-752" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>CNN: match network to spatial structure (pass 2D images)</span>
<span id="cb26-753"><a href="#cb26-753" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>goal: 'better' representation of input data</span>
<span id="cb26-754"><a href="#cb26-754" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Lower layers: Primitive "concepts"  </span>
<span id="cb26-755"><a href="#cb26-755" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Deeper layers: Higher order "concepts" </span>
<span id="cb26-756"><a href="#cb26-756" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-757"><a href="#cb26-757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-758"><a href="#cb26-758" aria-hidden="true" tabindex="-1"></a><span class="al">![Example from VGGNet. Image from A. Karpathy](https://github.com/cs231n/cs231n.github.io/raw/master/assets/cnn/convnet.jpeg)</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Made with Quatro</p>
</div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="../../general/about.html">
<p>About</p>
</a>
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/thomasmanke/blog">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>